{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score\n",
    "def calc_results_simple(X, y, train_index, test_index, clf):\n",
    "    X, y = X.to_numpy(), y.to_numpy(dtype=np.int64)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred  = clf.predict(X_test)\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    recall_0 =  recall_score(y_test, y_pred, pos_label=0)\n",
    "    recall_1 =  recall_score(y_test, y_pred, pos_label=1)\n",
    "    prec_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "    prec_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "    return np.array([[acc, recall_0, prec_0, recall_1, prec_1 ,auc]])\n",
    "\n",
    "#cross_validation\n",
    "def run_cross_val(X, y, params, n_folds=5, random_seed=42):\n",
    "    res = np.empty(shape=[0, 6])\n",
    "    clf = XGBClassifier(**params, n_jobs=8)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        res = np.append(res, calc_results_simple(X, y, train_index, test_index, clf), axis=0)\n",
    "    return res, clf\n",
    "\n",
    "def print_score_comparison(raw_score, emb_score, target_feature=\"RFS\",\n",
    "                           header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"balanced_accuracy\"].mean(), emb_score[\"balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_0\"].mean(), emb_score[\"precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_0\"].mean(), emb_score[\"recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_1\"].mean(), emb_score[\"precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_1\"].mean(), emb_score[\"recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"auc\"].mean(), emb_score[\"auc\"].mean()))\n",
    "\n",
    "def find_misclassified_patients(df, clf, X, y):\n",
    "    y_test = y.to_numpy()\n",
    "    X_test = X.to_numpy()\n",
    "    miss = np.where(y_test != clf.predict(X_test))\n",
    "    return df.iloc[miss][\"patient_ID\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "def calc_overlap(a, b):\n",
    "    intr = np.intersect1d(a, b)\n",
    "    union = np.union1d(a, b)\n",
    "    return intr, (len(intr) / len(union))\n",
    "\n",
    "def print_overlap(model1, model2, intr, perc):\n",
    "    print(\"{0} patients misclassified by {1} and {2} - {3:.1%} overlap\\n\".format(len(intr) ,model1, model2, perc))\n",
    "\n",
    "def write_misclassified(file_name, ls):\n",
    "    with open(\"datasets/\" + file_name + \".txt\", \"w\") as f:\n",
    "        for p in ls:\n",
    "            f.write(str(p) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300, 400, 500, 600, 700],\n",
    "              'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def param_tuning(X, y, n_folds=5, param_comb=25, scoring='roc_auc', jobs=12):\n",
    "    xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    rand_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring=scoring, n_jobs=jobs,\n",
    "                                   cv=skf.split(X, y), verbose=3, random_state=42)\n",
    "\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    rand_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    print(\"Best Score: {:.3%}\".format(rand_search.best_score_))\n",
    "    print(rand_search.best_params_)\n",
    "    return rand_search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ge_df = pd.read_csv(\"datasets/merged-combat15.csv\")\n",
    "outcome_df = pd.read_csv(\"datasets/combat15outcomes.csv\")\n",
    "pos_outcome_df = outcome_df[[\"patient_ID\", \"posOutcome\"]].dropna(axis=0, subset=[\"posOutcome\"])\n",
    "pos_outcome_df.posOutcome = pos_outcome_df.posOutcome.astype(int)\n",
    "ge_outcome_df = pd.merge(pos_outcome_df, ge_df, on=\"patient_ID\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome         0         1         2         3         4  \\\n0       22449           0  0.004935 -0.067173 -0.081524 -0.074297  0.133399   \n1       22450           0 -0.107115 -0.066373 -0.186839 -0.073233 -0.008075   \n2       22451           0 -0.066539  0.002395 -0.151372 -0.038813  0.174195   \n3       22452           0 -0.214922 -0.091833 -0.104011 -0.064794  0.010849   \n4       22453           1  0.035155 -0.040247 -0.083622 -0.007588  0.112287   \n\n          5         6         7  ...      2208          2209      2210  \\\n0 -0.146837 -0.039405  0.084736  ... -0.000005 -5.316138e-07 -0.000005   \n1 -0.106068 -0.164270 -0.014010  ...  0.000007 -1.119379e-05 -0.000002   \n2  0.008670  0.011472 -0.045705  ... -0.000008  8.546053e-06  0.000005   \n3 -0.079871  0.034703 -0.017574  ... -0.000007 -1.035770e-05  0.000001   \n4 -0.065557 -0.020941  0.039357  ... -0.000011 -1.192846e-05 -0.000001   \n\n           2211      2212      2213      2214      2215          2216  \\\n0  6.259005e-07  0.000009 -0.000009 -0.000002 -0.000003 -4.132974e-07   \n1  5.344275e-06 -0.000012 -0.000002  0.000006 -0.000005  2.132956e-06   \n2  1.459251e-05  0.000009  0.000002 -0.000002  0.000001  1.236459e-06   \n3  4.595439e-08  0.000003 -0.000002  0.000003 -0.000003 -3.997437e-06   \n4  1.611686e-06 -0.000004  0.000014  0.000004 -0.000003 -4.503628e-06   \n\n           2217  \n0  6.042526e-07  \n1 -4.973269e-07  \n2 -1.160475e-06  \n3 -1.386818e-06  \n4 -1.632821e-06  \n\n[5 rows x 2220 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2208</th>\n      <th>2209</th>\n      <th>2210</th>\n      <th>2211</th>\n      <th>2212</th>\n      <th>2213</th>\n      <th>2214</th>\n      <th>2215</th>\n      <th>2216</th>\n      <th>2217</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>0.004935</td>\n      <td>-0.067173</td>\n      <td>-0.081524</td>\n      <td>-0.074297</td>\n      <td>0.133399</td>\n      <td>-0.146837</td>\n      <td>-0.039405</td>\n      <td>0.084736</td>\n      <td>...</td>\n      <td>-0.000005</td>\n      <td>-5.316138e-07</td>\n      <td>-0.000005</td>\n      <td>6.259005e-07</td>\n      <td>0.000009</td>\n      <td>-0.000009</td>\n      <td>-0.000002</td>\n      <td>-0.000003</td>\n      <td>-4.132974e-07</td>\n      <td>6.042526e-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>-0.107115</td>\n      <td>-0.066373</td>\n      <td>-0.186839</td>\n      <td>-0.073233</td>\n      <td>-0.008075</td>\n      <td>-0.106068</td>\n      <td>-0.164270</td>\n      <td>-0.014010</td>\n      <td>...</td>\n      <td>0.000007</td>\n      <td>-1.119379e-05</td>\n      <td>-0.000002</td>\n      <td>5.344275e-06</td>\n      <td>-0.000012</td>\n      <td>-0.000002</td>\n      <td>0.000006</td>\n      <td>-0.000005</td>\n      <td>2.132956e-06</td>\n      <td>-4.973269e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>-0.066539</td>\n      <td>0.002395</td>\n      <td>-0.151372</td>\n      <td>-0.038813</td>\n      <td>0.174195</td>\n      <td>0.008670</td>\n      <td>0.011472</td>\n      <td>-0.045705</td>\n      <td>...</td>\n      <td>-0.000008</td>\n      <td>8.546053e-06</td>\n      <td>0.000005</td>\n      <td>1.459251e-05</td>\n      <td>0.000009</td>\n      <td>0.000002</td>\n      <td>-0.000002</td>\n      <td>0.000001</td>\n      <td>1.236459e-06</td>\n      <td>-1.160475e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>-0.214922</td>\n      <td>-0.091833</td>\n      <td>-0.104011</td>\n      <td>-0.064794</td>\n      <td>0.010849</td>\n      <td>-0.079871</td>\n      <td>0.034703</td>\n      <td>-0.017574</td>\n      <td>...</td>\n      <td>-0.000007</td>\n      <td>-1.035770e-05</td>\n      <td>0.000001</td>\n      <td>4.595439e-08</td>\n      <td>0.000003</td>\n      <td>-0.000002</td>\n      <td>0.000003</td>\n      <td>-0.000003</td>\n      <td>-3.997437e-06</td>\n      <td>-1.386818e-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>0.035155</td>\n      <td>-0.040247</td>\n      <td>-0.083622</td>\n      <td>-0.007588</td>\n      <td>0.112287</td>\n      <td>-0.065557</td>\n      <td>-0.020941</td>\n      <td>0.039357</td>\n      <td>...</td>\n      <td>-0.000011</td>\n      <td>-1.192846e-05</td>\n      <td>-0.000001</td>\n      <td>1.611686e-06</td>\n      <td>-0.000004</td>\n      <td>0.000014</td>\n      <td>0.000004</td>\n      <td>-0.000003</td>\n      <td>-4.503628e-06</td>\n      <td>-1.632821e-06</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2220 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_moses50_df = pd.read_csv(\"datasets/embedding-vectors/property_vector_moses50_withoutpatientsdata_2021-01-09.csv\", sep=\"\\t\")\n",
    "pos_outcome_moses50_emb_df = pd.merge(pos_outcome_df, emb_moses50_df, on=\"patient_ID\")\n",
    "X_moses50_emb, y_moses50_emb = pos_outcome_moses50_emb_df[pos_outcome_moses50_emb_df.columns.difference([\"patient_ID\", \"posOutcome\"])], pos_outcome_moses50_emb_df[\"posOutcome\"]\n",
    "pos_outcome_moses50_emb_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[08:45:02] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[08:45:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 44 minutes and 7.99 seconds.\n",
      "Best Score: 73.853%\n",
      "{'subsample': 0.8, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 5, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed: 40.0min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses50 = param_tuning(X_moses50_emb, y_moses50_emb, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "outcome_moses50_params = {'subsample': 0.8,\n",
    " 'n_estimators': 600,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 5,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:01:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:01:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:02:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:02:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:03:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.663773  0.451273     0.687119  0.876273     0.726522   \nstd             0.017982  0.028740     0.032991  0.015369     0.012190   \nmin             0.643458  0.427711     0.645455  0.859206     0.714715   \n25%             0.656339  0.433735     0.672727  0.869565     0.720721   \n50%             0.660686  0.443114     0.675676  0.869565     0.725076   \n75%             0.666143  0.451807     0.720000  0.884477     0.725146   \nmax             0.692238  0.500000     0.721739  0.898551     0.746951   \n\n            auc  \ncount  5.000000  \nmean   0.738526  \nstd    0.027625  \nmin    0.703667  \n25%    0.713812  \n50%    0.753645  \n75%    0.758534  \nmax    0.762972  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.663773</td>\n      <td>0.451273</td>\n      <td>0.687119</td>\n      <td>0.876273</td>\n      <td>0.726522</td>\n      <td>0.738526</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.017982</td>\n      <td>0.028740</td>\n      <td>0.032991</td>\n      <td>0.015369</td>\n      <td>0.012190</td>\n      <td>0.027625</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.643458</td>\n      <td>0.427711</td>\n      <td>0.645455</td>\n      <td>0.859206</td>\n      <td>0.714715</td>\n      <td>0.703667</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.656339</td>\n      <td>0.433735</td>\n      <td>0.672727</td>\n      <td>0.869565</td>\n      <td>0.720721</td>\n      <td>0.713812</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.660686</td>\n      <td>0.443114</td>\n      <td>0.675676</td>\n      <td>0.869565</td>\n      <td>0.725076</td>\n      <td>0.753645</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.666143</td>\n      <td>0.451807</td>\n      <td>0.720000</td>\n      <td>0.884477</td>\n      <td>0.725146</td>\n      <td>0.758534</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.692238</td>\n      <td>0.500000</td>\n      <td>0.721739</td>\n      <td>0.898551</td>\n      <td>0.746951</td>\n      <td>0.762972</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_moses50_scores, clf_moses50 = run_cross_val(X_moses50_emb, y_moses50_emb, outcome_moses50_params)\n",
    "outcome_moses50_df = pd.DataFrame(data=outcome_moses50_scores, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "outcome_moses50_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome         0         1         2         3         4  \\\n0       22449           0  0.274354  0.036449  0.077523 -0.137187 -0.007095   \n1       22450           0 -0.145367  0.023137 -0.086416 -0.021058 -0.166154   \n2       22451           0  0.047539  0.047250 -0.089892 -0.065981 -0.059450   \n3       22452           0 -0.236918  0.019434 -0.056465 -0.119143 -0.057772   \n4       22453           1  0.070666 -0.002817  0.018118 -0.066882  0.061491   \n\n          5         6         7  ...          2226      2227      2228  \\\n0  0.216389 -0.088171  0.001713  ... -1.569298e-05  0.000007  0.000058   \n1  0.133504 -0.013096  0.133711  ... -6.102851e-06  0.000003  0.000002   \n2 -0.005819 -0.056733  0.200612  ...  8.083307e-07  0.000037  0.000011   \n3  0.194564 -0.086927  0.072039  ...  9.679478e-06  0.000018  0.000018   \n4  0.251767 -0.078890  0.099405  ...  5.460626e-06  0.000016 -0.000011   \n\n           2229      2230          2231          2232      2233      2234  \\\n0  2.834218e-05  0.000008  3.252772e-07 -6.143507e-05  0.000020  0.000019   \n1 -1.542109e-05  0.000011  5.416132e-06  1.445249e-05  0.000002 -0.000004   \n2 -6.268849e-07  0.000027  1.037695e-05  1.657085e-05  0.000005  0.000002   \n3 -4.960172e-06 -0.000020  1.572499e-05  8.709695e-07 -0.000002 -0.000010   \n4  1.934010e-05 -0.000007 -1.187702e-05 -3.165962e-06 -0.000002  0.000010   \n\n       2235  \n0  0.000008  \n1  0.000002  \n2 -0.000005  \n3 -0.000002  \n4  0.000013  \n\n[5 rows x 2238 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2226</th>\n      <th>2227</th>\n      <th>2228</th>\n      <th>2229</th>\n      <th>2230</th>\n      <th>2231</th>\n      <th>2232</th>\n      <th>2233</th>\n      <th>2234</th>\n      <th>2235</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>0.274354</td>\n      <td>0.036449</td>\n      <td>0.077523</td>\n      <td>-0.137187</td>\n      <td>-0.007095</td>\n      <td>0.216389</td>\n      <td>-0.088171</td>\n      <td>0.001713</td>\n      <td>...</td>\n      <td>-1.569298e-05</td>\n      <td>0.000007</td>\n      <td>0.000058</td>\n      <td>2.834218e-05</td>\n      <td>0.000008</td>\n      <td>3.252772e-07</td>\n      <td>-6.143507e-05</td>\n      <td>0.000020</td>\n      <td>0.000019</td>\n      <td>0.000008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>-0.145367</td>\n      <td>0.023137</td>\n      <td>-0.086416</td>\n      <td>-0.021058</td>\n      <td>-0.166154</td>\n      <td>0.133504</td>\n      <td>-0.013096</td>\n      <td>0.133711</td>\n      <td>...</td>\n      <td>-6.102851e-06</td>\n      <td>0.000003</td>\n      <td>0.000002</td>\n      <td>-1.542109e-05</td>\n      <td>0.000011</td>\n      <td>5.416132e-06</td>\n      <td>1.445249e-05</td>\n      <td>0.000002</td>\n      <td>-0.000004</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>0.047539</td>\n      <td>0.047250</td>\n      <td>-0.089892</td>\n      <td>-0.065981</td>\n      <td>-0.059450</td>\n      <td>-0.005819</td>\n      <td>-0.056733</td>\n      <td>0.200612</td>\n      <td>...</td>\n      <td>8.083307e-07</td>\n      <td>0.000037</td>\n      <td>0.000011</td>\n      <td>-6.268849e-07</td>\n      <td>0.000027</td>\n      <td>1.037695e-05</td>\n      <td>1.657085e-05</td>\n      <td>0.000005</td>\n      <td>0.000002</td>\n      <td>-0.000005</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>-0.236918</td>\n      <td>0.019434</td>\n      <td>-0.056465</td>\n      <td>-0.119143</td>\n      <td>-0.057772</td>\n      <td>0.194564</td>\n      <td>-0.086927</td>\n      <td>0.072039</td>\n      <td>...</td>\n      <td>9.679478e-06</td>\n      <td>0.000018</td>\n      <td>0.000018</td>\n      <td>-4.960172e-06</td>\n      <td>-0.000020</td>\n      <td>1.572499e-05</td>\n      <td>8.709695e-07</td>\n      <td>-0.000002</td>\n      <td>-0.000010</td>\n      <td>-0.000002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>0.070666</td>\n      <td>-0.002817</td>\n      <td>0.018118</td>\n      <td>-0.066882</td>\n      <td>0.061491</td>\n      <td>0.251767</td>\n      <td>-0.078890</td>\n      <td>0.099405</td>\n      <td>...</td>\n      <td>5.460626e-06</td>\n      <td>0.000016</td>\n      <td>-0.000011</td>\n      <td>1.934010e-05</td>\n      <td>-0.000007</td>\n      <td>-1.187702e-05</td>\n      <td>-3.165962e-06</td>\n      <td>-0.000002</td>\n      <td>0.000010</td>\n      <td>0.000013</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2238 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_xg50_df = pd.read_csv(\"datasets/embedding-vectors/property_vector_xgb50_withoutpatientsdata_2021-01-09.csv\", sep=\"\\t\")\n",
    "pos_outcome_xg50_emb_df = pd.merge(pos_outcome_df, emb_xg50_df, on=\"patient_ID\")\n",
    "X_xg50_emb, y_xg50_emb = pos_outcome_xg50_emb_df[pos_outcome_xg50_emb_df.columns.difference([\"patient_ID\", \"posOutcome\"])], pos_outcome_xg50_emb_df[\"posOutcome\"]\n",
    "pos_outcome_xg50_emb_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[09:49:07] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:49:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 44 minutes and 48.97 seconds.\n",
      "Best Score: 75.437%\n",
      "{'subsample': 0.8, 'n_estimators': 400, 'min_child_weight': 2, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0.5, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed: 42.5min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_xg50 = param_tuning(X_xg50_emb, y_xg50_emb, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "outcome_xg50_params = {'subsample': 0.8,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 2,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 0.5,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:56:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:56:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:56:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:57:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:57:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.669084  0.466994     0.684265  0.871174     0.731261   \nstd             0.039660  0.058133     0.063254  0.023423     0.026726   \nmin             0.617895  0.395210     0.600000  0.840580     0.696697   \n25%             0.653691  0.433735     0.672566  0.865942     0.720238   \n50%             0.661887  0.457831     0.672897  0.869565     0.726444   \n75%             0.687795  0.506024     0.700000  0.873646     0.745342   \nmax             0.724153  0.542169     0.775862  0.906137     0.767584   \n\n            auc  \ncount  5.000000  \nmean   0.754367  \nstd    0.034789  \nmin    0.698299  \n25%    0.750098  \n50%    0.763249  \n75%    0.768334  \nmax    0.791853  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.669084</td>\n      <td>0.466994</td>\n      <td>0.684265</td>\n      <td>0.871174</td>\n      <td>0.731261</td>\n      <td>0.754367</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.039660</td>\n      <td>0.058133</td>\n      <td>0.063254</td>\n      <td>0.023423</td>\n      <td>0.026726</td>\n      <td>0.034789</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.617895</td>\n      <td>0.395210</td>\n      <td>0.600000</td>\n      <td>0.840580</td>\n      <td>0.696697</td>\n      <td>0.698299</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.653691</td>\n      <td>0.433735</td>\n      <td>0.672566</td>\n      <td>0.865942</td>\n      <td>0.720238</td>\n      <td>0.750098</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.661887</td>\n      <td>0.457831</td>\n      <td>0.672897</td>\n      <td>0.869565</td>\n      <td>0.726444</td>\n      <td>0.763249</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.687795</td>\n      <td>0.506024</td>\n      <td>0.700000</td>\n      <td>0.873646</td>\n      <td>0.745342</td>\n      <td>0.768334</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.724153</td>\n      <td>0.542169</td>\n      <td>0.775862</td>\n      <td>0.906137</td>\n      <td>0.767584</td>\n      <td>0.791853</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_xg50_scores, clf_xg50 = run_cross_val(X_xg50_emb, y_xg50_emb, outcome_xg50_params)\n",
    "outcome_xg50_df = pd.DataFrame(data=outcome_xg50_scores, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "outcome_xg50_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMoses50\t\tXgb50\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t66.377%\t\t\t66.908%\n",
      "\n",
      "precision_0:\t\t68.712%\t\t\t68.427%\n",
      "\n",
      "recall_0:\t\t45.127%\t\t\t46.699%\n",
      "\n",
      "precision_1:\t\t72.652%\t\t\t73.126%\n",
      "\n",
      "recall_1:\t\t87.627%\t\t\t87.117%\n",
      "\n",
      "auc:\t\t\t73.853%\t\t\t75.437%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(outcome_moses50_df, outcome_xg50_df, target_feature=\"posOutcome\", header_1=\"Moses50\", header_2=\"Xgb50\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome         0         1         2         3         4  \\\n0       22449           0  0.004935 -0.067173 -0.081524 -0.074297  0.133399   \n1       22450           0 -0.107115 -0.066373 -0.186839 -0.073233 -0.008075   \n2       22451           0 -0.066539  0.002395 -0.151372 -0.038813  0.174195   \n3       22452           0 -0.214922 -0.091833 -0.104011 -0.064794  0.010849   \n4       22453           1  0.035155 -0.040247 -0.083622 -0.007588  0.112287   \n\n          5         6         7  ...      2208          2209      2210  \\\n0 -0.146837 -0.039405  0.084736  ... -0.000005 -5.316138e-07 -0.000005   \n1 -0.106068 -0.164270 -0.014010  ...  0.000007 -1.119379e-05 -0.000002   \n2  0.008670  0.011472 -0.045705  ... -0.000008  8.546053e-06  0.000005   \n3 -0.079871  0.034703 -0.017574  ... -0.000007 -1.035770e-05  0.000001   \n4 -0.065557 -0.020941  0.039357  ... -0.000011 -1.192846e-05 -0.000001   \n\n           2211      2212      2213      2214      2215          2216  \\\n0  6.259005e-07  0.000009 -0.000009 -0.000002 -0.000003 -4.132974e-07   \n1  5.344275e-06 -0.000012 -0.000002  0.000006 -0.000005  2.132956e-06   \n2  1.459251e-05  0.000009  0.000002 -0.000002  0.000001  1.236459e-06   \n3  4.595439e-08  0.000003 -0.000002  0.000003 -0.000003 -3.997437e-06   \n4  1.611686e-06 -0.000004  0.000014  0.000004 -0.000003 -4.503628e-06   \n\n           2217  \n0  6.042526e-07  \n1 -4.973269e-07  \n2 -1.160475e-06  \n3 -1.386818e-06  \n4 -1.632821e-06  \n\n[5 rows x 2220 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2208</th>\n      <th>2209</th>\n      <th>2210</th>\n      <th>2211</th>\n      <th>2212</th>\n      <th>2213</th>\n      <th>2214</th>\n      <th>2215</th>\n      <th>2216</th>\n      <th>2217</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>0.004935</td>\n      <td>-0.067173</td>\n      <td>-0.081524</td>\n      <td>-0.074297</td>\n      <td>0.133399</td>\n      <td>-0.146837</td>\n      <td>-0.039405</td>\n      <td>0.084736</td>\n      <td>...</td>\n      <td>-0.000005</td>\n      <td>-5.316138e-07</td>\n      <td>-0.000005</td>\n      <td>6.259005e-07</td>\n      <td>0.000009</td>\n      <td>-0.000009</td>\n      <td>-0.000002</td>\n      <td>-0.000003</td>\n      <td>-4.132974e-07</td>\n      <td>6.042526e-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>-0.107115</td>\n      <td>-0.066373</td>\n      <td>-0.186839</td>\n      <td>-0.073233</td>\n      <td>-0.008075</td>\n      <td>-0.106068</td>\n      <td>-0.164270</td>\n      <td>-0.014010</td>\n      <td>...</td>\n      <td>0.000007</td>\n      <td>-1.119379e-05</td>\n      <td>-0.000002</td>\n      <td>5.344275e-06</td>\n      <td>-0.000012</td>\n      <td>-0.000002</td>\n      <td>0.000006</td>\n      <td>-0.000005</td>\n      <td>2.132956e-06</td>\n      <td>-4.973269e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>-0.066539</td>\n      <td>0.002395</td>\n      <td>-0.151372</td>\n      <td>-0.038813</td>\n      <td>0.174195</td>\n      <td>0.008670</td>\n      <td>0.011472</td>\n      <td>-0.045705</td>\n      <td>...</td>\n      <td>-0.000008</td>\n      <td>8.546053e-06</td>\n      <td>0.000005</td>\n      <td>1.459251e-05</td>\n      <td>0.000009</td>\n      <td>0.000002</td>\n      <td>-0.000002</td>\n      <td>0.000001</td>\n      <td>1.236459e-06</td>\n      <td>-1.160475e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>-0.214922</td>\n      <td>-0.091833</td>\n      <td>-0.104011</td>\n      <td>-0.064794</td>\n      <td>0.010849</td>\n      <td>-0.079871</td>\n      <td>0.034703</td>\n      <td>-0.017574</td>\n      <td>...</td>\n      <td>-0.000007</td>\n      <td>-1.035770e-05</td>\n      <td>0.000001</td>\n      <td>4.595439e-08</td>\n      <td>0.000003</td>\n      <td>-0.000002</td>\n      <td>0.000003</td>\n      <td>-0.000003</td>\n      <td>-3.997437e-06</td>\n      <td>-1.386818e-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>0.035155</td>\n      <td>-0.040247</td>\n      <td>-0.083622</td>\n      <td>-0.007588</td>\n      <td>0.112287</td>\n      <td>-0.065557</td>\n      <td>-0.020941</td>\n      <td>0.039357</td>\n      <td>...</td>\n      <td>-0.000011</td>\n      <td>-1.192846e-05</td>\n      <td>-0.000001</td>\n      <td>1.611686e-06</td>\n      <td>-0.000004</td>\n      <td>0.000014</td>\n      <td>0.000004</td>\n      <td>-0.000003</td>\n      <td>-4.503628e-06</td>\n      <td>-1.632821e-06</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2220 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with patient data(pd)\n",
    "emb_moses50_all_df = pd.read_csv(\"datasets/embedding-vectors/property_vector_moses50-all_2021-01-09.csv\", sep=\"\\t\")\n",
    "pos_outcome_emb_all_df = pd.merge(pos_outcome_df, emb_moses50_df, on=\"patient_ID\")\n",
    "X_moses50_all_emb, y_moses50_all_emb = pos_outcome_emb_all_df[pos_outcome_emb_all_df.columns.difference([\"patient_ID\", \"posOutcome\"])], pos_outcome_emb_all_df[\"posOutcome\"]\n",
    "pos_outcome_emb_all_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:30:56] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 1 hours 0 minutes and 36.21 seconds.\n",
      "Best Score: 73.853%\n",
      "{'subsample': 0.8, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 5, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=8)]: Done 125 out of 125 | elapsed: 56.5min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses50_all = param_tuning(X_moses50_all_emb, y_moses50_all_emb, jobs=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "moses50_all_params = {'subsample': 0.8,\n",
    " 'n_estimators': 600,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 5,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:51:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:53:47] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:55:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:57:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:59:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.663773  0.451273     0.687119  0.876273     0.726522   \nstd             0.017982  0.028740     0.032991  0.015369     0.012190   \nmin             0.643458  0.427711     0.645455  0.859206     0.714715   \n25%             0.656339  0.433735     0.672727  0.869565     0.720721   \n50%             0.660686  0.443114     0.675676  0.869565     0.725076   \n75%             0.666143  0.451807     0.720000  0.884477     0.725146   \nmax             0.692238  0.500000     0.721739  0.898551     0.746951   \n\n            auc  \ncount  5.000000  \nmean   0.738526  \nstd    0.027625  \nmin    0.703667  \n25%    0.713812  \n50%    0.753645  \n75%    0.758534  \nmax    0.762972  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.663773</td>\n      <td>0.451273</td>\n      <td>0.687119</td>\n      <td>0.876273</td>\n      <td>0.726522</td>\n      <td>0.738526</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.017982</td>\n      <td>0.028740</td>\n      <td>0.032991</td>\n      <td>0.015369</td>\n      <td>0.012190</td>\n      <td>0.027625</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.643458</td>\n      <td>0.427711</td>\n      <td>0.645455</td>\n      <td>0.859206</td>\n      <td>0.714715</td>\n      <td>0.703667</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.656339</td>\n      <td>0.433735</td>\n      <td>0.672727</td>\n      <td>0.869565</td>\n      <td>0.720721</td>\n      <td>0.713812</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.660686</td>\n      <td>0.443114</td>\n      <td>0.675676</td>\n      <td>0.869565</td>\n      <td>0.725076</td>\n      <td>0.753645</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.666143</td>\n      <td>0.451807</td>\n      <td>0.720000</td>\n      <td>0.884477</td>\n      <td>0.725146</td>\n      <td>0.758534</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.692238</td>\n      <td>0.500000</td>\n      <td>0.721739</td>\n      <td>0.898551</td>\n      <td>0.746951</td>\n      <td>0.762972</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moses50_all_scores, clf_moses50_all = run_cross_val(X_moses50_emb, y_moses50_all_emb, moses50_all_params)\n",
    "moses50_all_scores_df = pd.DataFrame(data=moses50_all_scores, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "moses50_all_scores_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome         0         1         2         3         4  \\\n0       22449           0  0.197541 -0.094160 -0.004222 -0.176551 -0.052261   \n1       22450           0 -0.133166 -0.011311 -0.049556  0.034698 -0.169372   \n2       22451           0  0.049879 -0.117226 -0.051329 -0.003347 -0.112412   \n3       22452           0 -0.195680 -0.004821 -0.015542 -0.054139 -0.168551   \n4       22453           1  0.031236 -0.004747 -0.012087 -0.098707 -0.029835   \n\n          5         6         7  ...          2225          2226  \\\n0 -0.063544 -0.156669  0.059774  ... -1.676209e-06 -4.591032e-07   \n1 -0.006558 -0.127243  0.101508  ... -7.076830e-07  1.614170e-05   \n2  0.043881 -0.036681 -0.029698  ...  1.436614e-05 -7.751890e-06   \n3  0.080153 -0.140853  0.111006  ... -4.741827e-06  5.878677e-06   \n4  0.023160 -0.196286  0.149748  ...  1.097292e-05 -1.188961e-08   \n\n           2227      2228      2229      2230      2231          2232  \\\n0 -6.689761e-08  0.000003  0.000011  0.000004 -0.000016 -2.599262e-07   \n1 -8.300375e-06 -0.000004  0.000002  0.000004 -0.000008 -6.256857e-06   \n2 -4.470416e-07  0.000005 -0.000010 -0.000021 -0.000003  6.783345e-06   \n3  6.551436e-06 -0.000006 -0.000005  0.000004 -0.000003  1.941135e-06   \n4  5.684494e-06 -0.000002  0.000009  0.000004  0.000006 -4.144589e-06   \n\n           2233      2234  \n0  1.383866e-06  0.000002  \n1 -1.734795e-06  0.000005  \n2  5.289614e-07  0.000003  \n3 -3.067090e-06  0.000001  \n4  3.423140e-06  0.000002  \n\n[5 rows x 2237 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2225</th>\n      <th>2226</th>\n      <th>2227</th>\n      <th>2228</th>\n      <th>2229</th>\n      <th>2230</th>\n      <th>2231</th>\n      <th>2232</th>\n      <th>2233</th>\n      <th>2234</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>0.197541</td>\n      <td>-0.094160</td>\n      <td>-0.004222</td>\n      <td>-0.176551</td>\n      <td>-0.052261</td>\n      <td>-0.063544</td>\n      <td>-0.156669</td>\n      <td>0.059774</td>\n      <td>...</td>\n      <td>-1.676209e-06</td>\n      <td>-4.591032e-07</td>\n      <td>-6.689761e-08</td>\n      <td>0.000003</td>\n      <td>0.000011</td>\n      <td>0.000004</td>\n      <td>-0.000016</td>\n      <td>-2.599262e-07</td>\n      <td>1.383866e-06</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>-0.133166</td>\n      <td>-0.011311</td>\n      <td>-0.049556</td>\n      <td>0.034698</td>\n      <td>-0.169372</td>\n      <td>-0.006558</td>\n      <td>-0.127243</td>\n      <td>0.101508</td>\n      <td>...</td>\n      <td>-7.076830e-07</td>\n      <td>1.614170e-05</td>\n      <td>-8.300375e-06</td>\n      <td>-0.000004</td>\n      <td>0.000002</td>\n      <td>0.000004</td>\n      <td>-0.000008</td>\n      <td>-6.256857e-06</td>\n      <td>-1.734795e-06</td>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>0.049879</td>\n      <td>-0.117226</td>\n      <td>-0.051329</td>\n      <td>-0.003347</td>\n      <td>-0.112412</td>\n      <td>0.043881</td>\n      <td>-0.036681</td>\n      <td>-0.029698</td>\n      <td>...</td>\n      <td>1.436614e-05</td>\n      <td>-7.751890e-06</td>\n      <td>-4.470416e-07</td>\n      <td>0.000005</td>\n      <td>-0.000010</td>\n      <td>-0.000021</td>\n      <td>-0.000003</td>\n      <td>6.783345e-06</td>\n      <td>5.289614e-07</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>-0.195680</td>\n      <td>-0.004821</td>\n      <td>-0.015542</td>\n      <td>-0.054139</td>\n      <td>-0.168551</td>\n      <td>0.080153</td>\n      <td>-0.140853</td>\n      <td>0.111006</td>\n      <td>...</td>\n      <td>-4.741827e-06</td>\n      <td>5.878677e-06</td>\n      <td>6.551436e-06</td>\n      <td>-0.000006</td>\n      <td>-0.000005</td>\n      <td>0.000004</td>\n      <td>-0.000003</td>\n      <td>1.941135e-06</td>\n      <td>-3.067090e-06</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>0.031236</td>\n      <td>-0.004747</td>\n      <td>-0.012087</td>\n      <td>-0.098707</td>\n      <td>-0.029835</td>\n      <td>0.023160</td>\n      <td>-0.196286</td>\n      <td>0.149748</td>\n      <td>...</td>\n      <td>1.097292e-05</td>\n      <td>-1.188961e-08</td>\n      <td>5.684494e-06</td>\n      <td>-0.000002</td>\n      <td>0.000009</td>\n      <td>0.000004</td>\n      <td>0.000006</td>\n      <td>-4.144589e-06</td>\n      <td>3.423140e-06</td>\n      <td>0.000002</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2237 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_xg50_all_df = pd.read_csv(\"datasets/embedding-vectors/property_vector_xgb50-all_2021-01-11.csv\", sep=\"\\t\")\n",
    "xg50_pos_outcome_df = pd.merge(pos_outcome_df, emb_xg50_all_df, on=\"patient_ID\")\n",
    "X_xg50_all_emb, y_xg50_all_emb = xg50_pos_outcome_df[xg50_pos_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])], xg50_pos_outcome_df[\"posOutcome\"]\n",
    "xg50_pos_outcome_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  6.2min\n"
     ]
    }
   ],
   "source": [
    "rand_search_xg50_all = param_tuning(X_xg50_all_emb, y_xg50_all_emb, jobs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "xg50_all_params = {'subsample': 0.8,\n",
    " 'n_estimators': 600,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 5,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:01:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:01:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.673925  0.473039     0.692726  0.874810     0.734574   \nstd             0.034857  0.063115     0.046416  0.016747     0.024699   \nmin             0.627029  0.377246     0.649485  0.859206     0.699422   \n25%             0.649482  0.439759     0.651786  0.865942     0.719033   \n50%             0.688995  0.512048     0.696721  0.869565     0.746875   \n75%             0.690807  0.512048     0.702479  0.876812     0.747664   \nmax             0.713312  0.524096     0.763158  0.902527     0.759878   \n\n            auc  \ncount  5.000000  \nmean   0.763098  \nstd    0.020166  \nmin    0.740758  \n25%    0.742899  \n50%    0.769301  \n75%    0.778025  \nmax    0.784508  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.673925</td>\n      <td>0.473039</td>\n      <td>0.692726</td>\n      <td>0.874810</td>\n      <td>0.734574</td>\n      <td>0.763098</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.034857</td>\n      <td>0.063115</td>\n      <td>0.046416</td>\n      <td>0.016747</td>\n      <td>0.024699</td>\n      <td>0.020166</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.627029</td>\n      <td>0.377246</td>\n      <td>0.649485</td>\n      <td>0.859206</td>\n      <td>0.699422</td>\n      <td>0.740758</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.649482</td>\n      <td>0.439759</td>\n      <td>0.651786</td>\n      <td>0.865942</td>\n      <td>0.719033</td>\n      <td>0.742899</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.688995</td>\n      <td>0.512048</td>\n      <td>0.696721</td>\n      <td>0.869565</td>\n      <td>0.746875</td>\n      <td>0.769301</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.690807</td>\n      <td>0.512048</td>\n      <td>0.702479</td>\n      <td>0.876812</td>\n      <td>0.747664</td>\n      <td>0.778025</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.713312</td>\n      <td>0.524096</td>\n      <td>0.763158</td>\n      <td>0.902527</td>\n      <td>0.759878</td>\n      <td>0.784508</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg50_all_scores, clf_xg50_all = run_cross_val(X_xg50_all_emb, y_xg50_all_emb, xg50_all_params)\n",
    "xg50_all_scores_df = pd.DataFrame(data=xg50_all_scores, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "xg50_all_scores_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMoses All Emb\t\tXgboost All Emb\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t66.377%\t\t\t67.392%\n",
      "\n",
      "precision_0:\t\t68.712%\t\t\t69.273%\n",
      "\n",
      "recall_0:\t\t45.127%\t\t\t47.304%\n",
      "\n",
      "precision_1:\t\t72.652%\t\t\t73.457%\n",
      "\n",
      "recall_1:\t\t87.627%\t\t\t87.481%\n",
      "\n",
      "auc:\t\t\t73.853%\t\t\t76.310%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(moses50_all_scores_df, xg50_all_scores_df, target_feature=\"posOutcome\",\n",
    "                       header_1=\"Moses All Emb\", header_2=\"Xgboost All Emb\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMoses W/o Patient Data\t\tMoses All Emb\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t66.377%\t\t\t66.377%\n",
      "\n",
      "precision_0:\t\t68.712%\t\t\t68.712%\n",
      "\n",
      "recall_0:\t\t45.127%\t\t\t45.127%\n",
      "\n",
      "precision_1:\t\t72.652%\t\t\t72.652%\n",
      "\n",
      "recall_1:\t\t87.627%\t\t\t87.627%\n",
      "\n",
      "auc:\t\t\t73.853%\t\t\t73.853%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(outcome_moses50_df, moses50_all_scores_df, target_feature=\"posOutcome\",\n",
    "                       header_1=\"Moses W/o Patient Data\", header_2=\"Moses All Emb\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tXgboost W/o Patient Data\t\tXgboost All Emb\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t66.908%\t\t\t67.392%\n",
      "\n",
      "precision_0:\t\t68.427%\t\t\t69.273%\n",
      "\n",
      "recall_0:\t\t46.699%\t\t\t47.304%\n",
      "\n",
      "precision_1:\t\t73.126%\t\t\t73.457%\n",
      "\n",
      "recall_1:\t\t87.117%\t\t\t87.481%\n",
      "\n",
      "auc:\t\t\t75.437%\t\t\t76.310%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(outcome_xg50_df, xg50_all_scores_df, target_feature=\"posOutcome\",\n",
    "                       header_1=\"Xgboost W/o Patient Data\", header_2=\"Xgboost All Emb\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome         0         1         2         3         4  \\\n0       22449           0 -0.061200 -0.011763 -0.097050 -0.144627 -0.004909   \n1       22450           0  0.032036 -0.042084 -0.165602 -0.071555 -0.089342   \n2       22451           0  0.005751  0.074967 -0.126259  0.061286 -0.012363   \n3       22452           0  0.132013 -0.048426 -0.161120 -0.063450 -0.062068   \n4       22453           1 -0.047700 -0.046430 -0.065408 -0.000439 -0.028872   \n\n          5         6         7  ...      2225      2226          2227  \\\n0  0.069013 -0.145238  0.037271  ... -0.000003 -0.000001  5.244921e-06   \n1 -0.099114 -0.162727 -0.097703  ...  0.000007 -0.000003  1.976495e-05   \n2  0.023697 -0.199545  0.043533  ... -0.000011 -0.000006  6.491019e-07   \n3 -0.011423 -0.104246 -0.029692  ... -0.000011 -0.000005 -2.715835e-06   \n4 -0.016403 -0.205440  0.005162  ... -0.000023  0.000003 -6.232265e-06   \n\n       2228      2229      2230      2231          2232          2233  \\\n0 -0.000011  0.000003 -0.000004  0.000014  4.997154e-07 -4.934000e-06   \n1 -0.000013  0.000006  0.000009  0.000003  8.917825e-06 -7.999823e-07   \n2  0.000019 -0.000001  0.000010  0.000003  1.434503e-06 -3.332053e-06   \n3 -0.000004  0.000014  0.000012  0.000003  1.636455e-06 -1.169340e-06   \n4 -0.000006 -0.000006  0.000005  0.000007  5.138666e-06 -2.546916e-06   \n\n           2234  \n0  2.056817e-06  \n1  2.685009e-07  \n2  7.659706e-06  \n3 -8.510721e-06  \n4  8.562460e-07  \n\n[5 rows x 2237 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2225</th>\n      <th>2226</th>\n      <th>2227</th>\n      <th>2228</th>\n      <th>2229</th>\n      <th>2230</th>\n      <th>2231</th>\n      <th>2232</th>\n      <th>2233</th>\n      <th>2234</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>-0.061200</td>\n      <td>-0.011763</td>\n      <td>-0.097050</td>\n      <td>-0.144627</td>\n      <td>-0.004909</td>\n      <td>0.069013</td>\n      <td>-0.145238</td>\n      <td>0.037271</td>\n      <td>...</td>\n      <td>-0.000003</td>\n      <td>-0.000001</td>\n      <td>5.244921e-06</td>\n      <td>-0.000011</td>\n      <td>0.000003</td>\n      <td>-0.000004</td>\n      <td>0.000014</td>\n      <td>4.997154e-07</td>\n      <td>-4.934000e-06</td>\n      <td>2.056817e-06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>0.032036</td>\n      <td>-0.042084</td>\n      <td>-0.165602</td>\n      <td>-0.071555</td>\n      <td>-0.089342</td>\n      <td>-0.099114</td>\n      <td>-0.162727</td>\n      <td>-0.097703</td>\n      <td>...</td>\n      <td>0.000007</td>\n      <td>-0.000003</td>\n      <td>1.976495e-05</td>\n      <td>-0.000013</td>\n      <td>0.000006</td>\n      <td>0.000009</td>\n      <td>0.000003</td>\n      <td>8.917825e-06</td>\n      <td>-7.999823e-07</td>\n      <td>2.685009e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>0.005751</td>\n      <td>0.074967</td>\n      <td>-0.126259</td>\n      <td>0.061286</td>\n      <td>-0.012363</td>\n      <td>0.023697</td>\n      <td>-0.199545</td>\n      <td>0.043533</td>\n      <td>...</td>\n      <td>-0.000011</td>\n      <td>-0.000006</td>\n      <td>6.491019e-07</td>\n      <td>0.000019</td>\n      <td>-0.000001</td>\n      <td>0.000010</td>\n      <td>0.000003</td>\n      <td>1.434503e-06</td>\n      <td>-3.332053e-06</td>\n      <td>7.659706e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>0.132013</td>\n      <td>-0.048426</td>\n      <td>-0.161120</td>\n      <td>-0.063450</td>\n      <td>-0.062068</td>\n      <td>-0.011423</td>\n      <td>-0.104246</td>\n      <td>-0.029692</td>\n      <td>...</td>\n      <td>-0.000011</td>\n      <td>-0.000005</td>\n      <td>-2.715835e-06</td>\n      <td>-0.000004</td>\n      <td>0.000014</td>\n      <td>0.000012</td>\n      <td>0.000003</td>\n      <td>1.636455e-06</td>\n      <td>-1.169340e-06</td>\n      <td>-8.510721e-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>-0.047700</td>\n      <td>-0.046430</td>\n      <td>-0.065408</td>\n      <td>-0.000439</td>\n      <td>-0.028872</td>\n      <td>-0.016403</td>\n      <td>-0.205440</td>\n      <td>0.005162</td>\n      <td>...</td>\n      <td>-0.000023</td>\n      <td>0.000003</td>\n      <td>-6.232265e-06</td>\n      <td>-0.000006</td>\n      <td>-0.000006</td>\n      <td>0.000005</td>\n      <td>0.000007</td>\n      <td>5.138666e-06</td>\n      <td>-2.546916e-06</td>\n      <td>8.562460e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2237 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_moses50_moses_norm = pd.read_csv(\"datasets/embedding-vectors/property_vector_normalized_moses50-all_2021-01-09.csv\", sep=\"\\t\")\n",
    "moses50_norm_outcome_df = pd.merge(pos_outcome_df, emb_moses50_moses_norm, on=\"patient_ID\")\n",
    "X_moses50_emb_norm, y_moses50_emb_norm = moses50_norm_outcome_df[moses50_norm_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])],moses50_norm_outcome_df[\"posOutcome\"]\n",
    "\n",
    "moses50_norm_outcome_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[10:40:14] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:40:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 56 minutes and 11.07 seconds.\n",
      "Best Score: 76.151%\n",
      "{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 2, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=12)]: Done 125 out of 125 | elapsed: 54.5min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses50_norm = param_tuning(X_moses50_emb_norm, y_moses50_emb_norm, jobs=12)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:16:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:16:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:16:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:16:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:16:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.678477  0.470572     0.713941  0.886381     0.735895   \nstd             0.026525  0.042283     0.047181  0.021459     0.018217   \nmin             0.640111  0.425150     0.639640  0.855072     0.710843   \n25%             0.663923  0.439759     0.701923  0.876812     0.725664   \n50%             0.684826  0.463855     0.721311  0.888087     0.737463   \n75%             0.700057  0.493976     0.747573  0.905797     0.749254   \nmax             0.703466  0.530120     0.759259  0.906137     0.756250   \n\n            auc  \ncount  5.000000  \nmean   0.761508  \nstd    0.017672  \nmin    0.742573  \n25%    0.742667  \n50%    0.769076  \n75%    0.773289  \nmax    0.779936  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.678477</td>\n      <td>0.470572</td>\n      <td>0.713941</td>\n      <td>0.886381</td>\n      <td>0.735895</td>\n      <td>0.761508</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.026525</td>\n      <td>0.042283</td>\n      <td>0.047181</td>\n      <td>0.021459</td>\n      <td>0.018217</td>\n      <td>0.017672</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.640111</td>\n      <td>0.425150</td>\n      <td>0.639640</td>\n      <td>0.855072</td>\n      <td>0.710843</td>\n      <td>0.742573</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.663923</td>\n      <td>0.439759</td>\n      <td>0.701923</td>\n      <td>0.876812</td>\n      <td>0.725664</td>\n      <td>0.742667</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.684826</td>\n      <td>0.463855</td>\n      <td>0.721311</td>\n      <td>0.888087</td>\n      <td>0.737463</td>\n      <td>0.769076</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.700057</td>\n      <td>0.493976</td>\n      <td>0.747573</td>\n      <td>0.905797</td>\n      <td>0.749254</td>\n      <td>0.773289</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.703466</td>\n      <td>0.530120</td>\n      <td>0.759259</td>\n      <td>0.906137</td>\n      <td>0.756250</td>\n      <td>0.779936</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moses50_norm_params = {'subsample': 0.8,\n",
    " 'n_estimators': 300,\n",
    " 'min_child_weight': 5,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 2,\n",
    " 'colsample_bytree': 0.6}\n",
    "outcome_moses50_norm_scores, clf_moses50_norm = run_cross_val(X_moses50_emb_norm, y_moses50_emb_norm, moses50_norm_params)\n",
    "outcome_moses50_norm_scores_df = pd.DataFrame(data=outcome_moses50_norm_scores,  columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "outcome_moses50_norm_scores_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome         0         1         2         3         4  \\\n0       22449           0 -0.061200 -0.011763 -0.097050 -0.144627 -0.004909   \n1       22450           0  0.032036 -0.042084 -0.165602 -0.071555 -0.089342   \n2       22451           0  0.005751  0.074967 -0.126259  0.061286 -0.012363   \n3       22452           0  0.132013 -0.048426 -0.161120 -0.063450 -0.062068   \n4       22453           1 -0.047700 -0.046430 -0.065408 -0.000439 -0.028872   \n\n          5         6         7  ...      2225      2226          2227  \\\n0  0.069013 -0.145238  0.037271  ... -0.000003 -0.000001  5.244921e-06   \n1 -0.099114 -0.162727 -0.097703  ...  0.000007 -0.000003  1.976495e-05   \n2  0.023697 -0.199545  0.043533  ... -0.000011 -0.000006  6.491019e-07   \n3 -0.011423 -0.104246 -0.029692  ... -0.000011 -0.000005 -2.715835e-06   \n4 -0.016403 -0.205440  0.005162  ... -0.000023  0.000003 -6.232265e-06   \n\n       2228      2229      2230      2231          2232          2233  \\\n0 -0.000011  0.000003 -0.000004  0.000014  4.997154e-07 -4.934000e-06   \n1 -0.000013  0.000006  0.000009  0.000003  8.917825e-06 -7.999823e-07   \n2  0.000019 -0.000001  0.000010  0.000003  1.434503e-06 -3.332053e-06   \n3 -0.000004  0.000014  0.000012  0.000003  1.636455e-06 -1.169340e-06   \n4 -0.000006 -0.000006  0.000005  0.000007  5.138666e-06 -2.546916e-06   \n\n           2234  \n0  2.056817e-06  \n1  2.685009e-07  \n2  7.659706e-06  \n3 -8.510721e-06  \n4  8.562460e-07  \n\n[5 rows x 2237 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>2225</th>\n      <th>2226</th>\n      <th>2227</th>\n      <th>2228</th>\n      <th>2229</th>\n      <th>2230</th>\n      <th>2231</th>\n      <th>2232</th>\n      <th>2233</th>\n      <th>2234</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>-0.061200</td>\n      <td>-0.011763</td>\n      <td>-0.097050</td>\n      <td>-0.144627</td>\n      <td>-0.004909</td>\n      <td>0.069013</td>\n      <td>-0.145238</td>\n      <td>0.037271</td>\n      <td>...</td>\n      <td>-0.000003</td>\n      <td>-0.000001</td>\n      <td>5.244921e-06</td>\n      <td>-0.000011</td>\n      <td>0.000003</td>\n      <td>-0.000004</td>\n      <td>0.000014</td>\n      <td>4.997154e-07</td>\n      <td>-4.934000e-06</td>\n      <td>2.056817e-06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>0.032036</td>\n      <td>-0.042084</td>\n      <td>-0.165602</td>\n      <td>-0.071555</td>\n      <td>-0.089342</td>\n      <td>-0.099114</td>\n      <td>-0.162727</td>\n      <td>-0.097703</td>\n      <td>...</td>\n      <td>0.000007</td>\n      <td>-0.000003</td>\n      <td>1.976495e-05</td>\n      <td>-0.000013</td>\n      <td>0.000006</td>\n      <td>0.000009</td>\n      <td>0.000003</td>\n      <td>8.917825e-06</td>\n      <td>-7.999823e-07</td>\n      <td>2.685009e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>0.005751</td>\n      <td>0.074967</td>\n      <td>-0.126259</td>\n      <td>0.061286</td>\n      <td>-0.012363</td>\n      <td>0.023697</td>\n      <td>-0.199545</td>\n      <td>0.043533</td>\n      <td>...</td>\n      <td>-0.000011</td>\n      <td>-0.000006</td>\n      <td>6.491019e-07</td>\n      <td>0.000019</td>\n      <td>-0.000001</td>\n      <td>0.000010</td>\n      <td>0.000003</td>\n      <td>1.434503e-06</td>\n      <td>-3.332053e-06</td>\n      <td>7.659706e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>0.132013</td>\n      <td>-0.048426</td>\n      <td>-0.161120</td>\n      <td>-0.063450</td>\n      <td>-0.062068</td>\n      <td>-0.011423</td>\n      <td>-0.104246</td>\n      <td>-0.029692</td>\n      <td>...</td>\n      <td>-0.000011</td>\n      <td>-0.000005</td>\n      <td>-2.715835e-06</td>\n      <td>-0.000004</td>\n      <td>0.000014</td>\n      <td>0.000012</td>\n      <td>0.000003</td>\n      <td>1.636455e-06</td>\n      <td>-1.169340e-06</td>\n      <td>-8.510721e-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>-0.047700</td>\n      <td>-0.046430</td>\n      <td>-0.065408</td>\n      <td>-0.000439</td>\n      <td>-0.028872</td>\n      <td>-0.016403</td>\n      <td>-0.205440</td>\n      <td>0.005162</td>\n      <td>...</td>\n      <td>-0.000023</td>\n      <td>0.000003</td>\n      <td>-6.232265e-06</td>\n      <td>-0.000006</td>\n      <td>-0.000006</td>\n      <td>0.000005</td>\n      <td>0.000007</td>\n      <td>5.138666e-06</td>\n      <td>-2.546916e-06</td>\n      <td>8.562460e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2237 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_moses50_moses_norm_v2 = pd.read_csv(\"datasets/embedding-vectors/property_vector_normalized-V2_moses50-all_2021-01-09.csv\", sep=\"\\t\")\n",
    "moses50_norm_outcome_v2_df = pd.merge(pos_outcome_df, emb_moses50_moses_norm_v2, on=\"patient_ID\")\n",
    "X_moses50_emb_norm_v2, y_moses50_emb_norm_v2 = moses50_norm_outcome_v2_df[moses50_norm_outcome_v2_df.columns.difference([\"patient_ID\", \"posOutcome\"])],moses50_norm_outcome_v2_df[\"posOutcome\"]\n",
    "\n",
    "moses50_norm_outcome_v2_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:49:17] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:49:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 56 minutes and 52.13 seconds.\n",
      "Best Score: 76.151%\n",
      "{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 2, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=12)]: Done 125 out of 125 | elapsed: 55.2min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses50_norm_v2 = param_tuning(X_moses50_emb_norm_v2, y_moses50_emb_norm_v2, jobs=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "moses50_norm_v2_params = {'subsample': 0.8,\n",
    " 'n_estimators': 300,\n",
    " 'min_child_weight': 5,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 2,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:22:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:25:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:25:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.678477  0.470572     0.713941  0.886381     0.735895   \nstd             0.026525  0.042283     0.047181  0.021459     0.018217   \nmin             0.640111  0.425150     0.639640  0.855072     0.710843   \n25%             0.663923  0.439759     0.701923  0.876812     0.725664   \n50%             0.684826  0.463855     0.721311  0.888087     0.737463   \n75%             0.700057  0.493976     0.747573  0.905797     0.749254   \nmax             0.703466  0.530120     0.759259  0.906137     0.756250   \n\n            auc  \ncount  5.000000  \nmean   0.761508  \nstd    0.017672  \nmin    0.742573  \n25%    0.742667  \n50%    0.769076  \n75%    0.773289  \nmax    0.779936  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.678477</td>\n      <td>0.470572</td>\n      <td>0.713941</td>\n      <td>0.886381</td>\n      <td>0.735895</td>\n      <td>0.761508</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.026525</td>\n      <td>0.042283</td>\n      <td>0.047181</td>\n      <td>0.021459</td>\n      <td>0.018217</td>\n      <td>0.017672</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.640111</td>\n      <td>0.425150</td>\n      <td>0.639640</td>\n      <td>0.855072</td>\n      <td>0.710843</td>\n      <td>0.742573</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.663923</td>\n      <td>0.439759</td>\n      <td>0.701923</td>\n      <td>0.876812</td>\n      <td>0.725664</td>\n      <td>0.742667</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.684826</td>\n      <td>0.463855</td>\n      <td>0.721311</td>\n      <td>0.888087</td>\n      <td>0.737463</td>\n      <td>0.769076</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.700057</td>\n      <td>0.493976</td>\n      <td>0.747573</td>\n      <td>0.905797</td>\n      <td>0.749254</td>\n      <td>0.773289</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.703466</td>\n      <td>0.530120</td>\n      <td>0.759259</td>\n      <td>0.906137</td>\n      <td>0.756250</td>\n      <td>0.779936</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_moses50_norm_v2_scores, clf_moses50_norm_v2 = run_cross_val(X_moses50_emb_norm, y_moses50_emb_norm, moses50_norm_v2_params)\n",
    "outcome_moses50_norm_v2_scores_df = pd.DataFrame(data=outcome_moses50_norm_v2_scores,  columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "outcome_moses50_norm_v2_scores_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMoses Norm V1\t\tMoses Norm V2\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t67.848%\t\t\t67.848%\n",
      "\n",
      "precision_0:\t\t71.394%\t\t\t71.394%\n",
      "\n",
      "recall_0:\t\t47.057%\t\t\t47.057%\n",
      "\n",
      "precision_1:\t\t73.589%\t\t\t73.589%\n",
      "\n",
      "recall_1:\t\t88.638%\t\t\t88.638%\n",
      "\n",
      "auc:\t\t\t76.151%\t\t\t76.151%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(outcome_moses50_norm_scores_df, outcome_moses50_norm_v2_scores_df,\n",
    "                       target_feature=\"posOutcome\", header_1=\"Moses Norm V1\", header_2=\"Moses Norm V2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "             0                   1                  10                 100  \\\n          self     other      self     other      self     other      self   \n0    -0.061200 -0.061200 -0.011763 -0.011763  0.094227  0.094227  0.005540   \n1     0.032036  0.032036 -0.042084 -0.042084  0.072747  0.072747  0.005865   \n2     0.005751  0.005751  0.074967  0.074967  0.015623  0.015623 -0.011421   \n3     0.132013  0.132013 -0.048426 -0.048426 -0.053173 -0.053173  0.041595   \n4    -0.047700 -0.047700 -0.046430 -0.046430  0.047473  0.047473  0.036165   \n...        ...       ...       ...       ...       ...       ...       ...   \n2208 -0.022632 -0.022632 -0.093210 -0.093210  0.155161  0.155161 -0.007396   \n2209 -0.053661 -0.053661 -0.033823 -0.033823 -0.021585 -0.021585  0.039583   \n2210       NaN       NaN -0.019663 -0.019663  0.045071  0.045071  0.001040   \n2211 -0.083596 -0.083596 -0.004946 -0.004946  0.061202  0.061202  0.031859   \n2212 -0.068149 -0.068149  0.022866  0.022866  0.038338  0.038338 -0.004720   \n\n                    1000            ...       995                 996  \\\n         other      self     other  ...      self     other      self   \n0     0.005540  0.000319  0.000319  ... -0.010020 -0.010020  0.013695   \n1     0.005865  0.003959  0.003959  ... -0.007732 -0.007732  0.006574   \n2    -0.011421 -0.015053 -0.015053  ...  0.010022  0.010022  0.002491   \n3     0.041595  0.004710  0.004710  ...  0.005073  0.005073  0.006257   \n4     0.036165 -0.017594 -0.017594  ... -0.021378 -0.021378 -0.002560   \n...        ...       ...       ...  ...       ...       ...       ...   \n2208 -0.007396  0.005517  0.005517  ...  0.004287  0.004287  0.002754   \n2209  0.039583 -0.015704 -0.015704  ... -0.004854 -0.004854 -0.005991   \n2210  0.001040 -0.018900 -0.018900  ...  0.007928  0.007928  0.016473   \n2211  0.031859 -0.008947 -0.008947  ...  0.008434  0.008434 -0.006127   \n2212 -0.004720  0.014601  0.014601  ... -0.000951 -0.000951  0.036402   \n\n                     997                 998                 999            \n         other      self     other      self     other      self     other  \n0     0.013695 -0.003760 -0.003760 -0.003787 -0.003787  0.006454  0.006454  \n1     0.006574  0.007644  0.007644  0.007729  0.007729 -0.010231 -0.010231  \n2     0.002491  0.021103  0.021103 -0.019438 -0.019438  0.007085  0.007085  \n3     0.006257 -0.005478 -0.005478 -0.016335 -0.016335  0.001481  0.001481  \n4    -0.002560 -0.020363 -0.020363  0.006564  0.006564  0.001492  0.001492  \n...        ...       ...       ...       ...       ...       ...       ...  \n2208  0.002754  0.002424  0.002424  0.001547  0.001547 -0.004010 -0.004010  \n2209 -0.005991  0.012206  0.012206  0.023468  0.023468  0.000368  0.000368  \n2210  0.016473 -0.017683 -0.017683 -0.000785 -0.000785 -0.001125 -0.001125  \n2211 -0.006127 -0.026915 -0.026915 -0.009631 -0.009631  0.022162  0.022162  \n2212  0.036402  0.013903  0.013903 -0.004175 -0.004175  0.021520  0.021520  \n\n[2213 rows x 4470 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">0</th>\n      <th colspan=\"2\" halign=\"left\">1</th>\n      <th colspan=\"2\" halign=\"left\">10</th>\n      <th colspan=\"2\" halign=\"left\">100</th>\n      <th colspan=\"2\" halign=\"left\">1000</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">995</th>\n      <th colspan=\"2\" halign=\"left\">996</th>\n      <th colspan=\"2\" halign=\"left\">997</th>\n      <th colspan=\"2\" halign=\"left\">998</th>\n      <th colspan=\"2\" halign=\"left\">999</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n      <th>...</th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n      <th>self</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.061200</td>\n      <td>-0.061200</td>\n      <td>-0.011763</td>\n      <td>-0.011763</td>\n      <td>0.094227</td>\n      <td>0.094227</td>\n      <td>0.005540</td>\n      <td>0.005540</td>\n      <td>0.000319</td>\n      <td>0.000319</td>\n      <td>...</td>\n      <td>-0.010020</td>\n      <td>-0.010020</td>\n      <td>0.013695</td>\n      <td>0.013695</td>\n      <td>-0.003760</td>\n      <td>-0.003760</td>\n      <td>-0.003787</td>\n      <td>-0.003787</td>\n      <td>0.006454</td>\n      <td>0.006454</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.032036</td>\n      <td>0.032036</td>\n      <td>-0.042084</td>\n      <td>-0.042084</td>\n      <td>0.072747</td>\n      <td>0.072747</td>\n      <td>0.005865</td>\n      <td>0.005865</td>\n      <td>0.003959</td>\n      <td>0.003959</td>\n      <td>...</td>\n      <td>-0.007732</td>\n      <td>-0.007732</td>\n      <td>0.006574</td>\n      <td>0.006574</td>\n      <td>0.007644</td>\n      <td>0.007644</td>\n      <td>0.007729</td>\n      <td>0.007729</td>\n      <td>-0.010231</td>\n      <td>-0.010231</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.005751</td>\n      <td>0.005751</td>\n      <td>0.074967</td>\n      <td>0.074967</td>\n      <td>0.015623</td>\n      <td>0.015623</td>\n      <td>-0.011421</td>\n      <td>-0.011421</td>\n      <td>-0.015053</td>\n      <td>-0.015053</td>\n      <td>...</td>\n      <td>0.010022</td>\n      <td>0.010022</td>\n      <td>0.002491</td>\n      <td>0.002491</td>\n      <td>0.021103</td>\n      <td>0.021103</td>\n      <td>-0.019438</td>\n      <td>-0.019438</td>\n      <td>0.007085</td>\n      <td>0.007085</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.132013</td>\n      <td>0.132013</td>\n      <td>-0.048426</td>\n      <td>-0.048426</td>\n      <td>-0.053173</td>\n      <td>-0.053173</td>\n      <td>0.041595</td>\n      <td>0.041595</td>\n      <td>0.004710</td>\n      <td>0.004710</td>\n      <td>...</td>\n      <td>0.005073</td>\n      <td>0.005073</td>\n      <td>0.006257</td>\n      <td>0.006257</td>\n      <td>-0.005478</td>\n      <td>-0.005478</td>\n      <td>-0.016335</td>\n      <td>-0.016335</td>\n      <td>0.001481</td>\n      <td>0.001481</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.047700</td>\n      <td>-0.047700</td>\n      <td>-0.046430</td>\n      <td>-0.046430</td>\n      <td>0.047473</td>\n      <td>0.047473</td>\n      <td>0.036165</td>\n      <td>0.036165</td>\n      <td>-0.017594</td>\n      <td>-0.017594</td>\n      <td>...</td>\n      <td>-0.021378</td>\n      <td>-0.021378</td>\n      <td>-0.002560</td>\n      <td>-0.002560</td>\n      <td>-0.020363</td>\n      <td>-0.020363</td>\n      <td>0.006564</td>\n      <td>0.006564</td>\n      <td>0.001492</td>\n      <td>0.001492</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>-0.022632</td>\n      <td>-0.022632</td>\n      <td>-0.093210</td>\n      <td>-0.093210</td>\n      <td>0.155161</td>\n      <td>0.155161</td>\n      <td>-0.007396</td>\n      <td>-0.007396</td>\n      <td>0.005517</td>\n      <td>0.005517</td>\n      <td>...</td>\n      <td>0.004287</td>\n      <td>0.004287</td>\n      <td>0.002754</td>\n      <td>0.002754</td>\n      <td>0.002424</td>\n      <td>0.002424</td>\n      <td>0.001547</td>\n      <td>0.001547</td>\n      <td>-0.004010</td>\n      <td>-0.004010</td>\n    </tr>\n    <tr>\n      <th>2209</th>\n      <td>-0.053661</td>\n      <td>-0.053661</td>\n      <td>-0.033823</td>\n      <td>-0.033823</td>\n      <td>-0.021585</td>\n      <td>-0.021585</td>\n      <td>0.039583</td>\n      <td>0.039583</td>\n      <td>-0.015704</td>\n      <td>-0.015704</td>\n      <td>...</td>\n      <td>-0.004854</td>\n      <td>-0.004854</td>\n      <td>-0.005991</td>\n      <td>-0.005991</td>\n      <td>0.012206</td>\n      <td>0.012206</td>\n      <td>0.023468</td>\n      <td>0.023468</td>\n      <td>0.000368</td>\n      <td>0.000368</td>\n    </tr>\n    <tr>\n      <th>2210</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.019663</td>\n      <td>-0.019663</td>\n      <td>0.045071</td>\n      <td>0.045071</td>\n      <td>0.001040</td>\n      <td>0.001040</td>\n      <td>-0.018900</td>\n      <td>-0.018900</td>\n      <td>...</td>\n      <td>0.007928</td>\n      <td>0.007928</td>\n      <td>0.016473</td>\n      <td>0.016473</td>\n      <td>-0.017683</td>\n      <td>-0.017683</td>\n      <td>-0.000785</td>\n      <td>-0.000785</td>\n      <td>-0.001125</td>\n      <td>-0.001125</td>\n    </tr>\n    <tr>\n      <th>2211</th>\n      <td>-0.083596</td>\n      <td>-0.083596</td>\n      <td>-0.004946</td>\n      <td>-0.004946</td>\n      <td>0.061202</td>\n      <td>0.061202</td>\n      <td>0.031859</td>\n      <td>0.031859</td>\n      <td>-0.008947</td>\n      <td>-0.008947</td>\n      <td>...</td>\n      <td>0.008434</td>\n      <td>0.008434</td>\n      <td>-0.006127</td>\n      <td>-0.006127</td>\n      <td>-0.026915</td>\n      <td>-0.026915</td>\n      <td>-0.009631</td>\n      <td>-0.009631</td>\n      <td>0.022162</td>\n      <td>0.022162</td>\n    </tr>\n    <tr>\n      <th>2212</th>\n      <td>-0.068149</td>\n      <td>-0.068149</td>\n      <td>0.022866</td>\n      <td>0.022866</td>\n      <td>0.038338</td>\n      <td>0.038338</td>\n      <td>-0.004720</td>\n      <td>-0.004720</td>\n      <td>0.014601</td>\n      <td>0.014601</td>\n      <td>...</td>\n      <td>-0.000951</td>\n      <td>-0.000951</td>\n      <td>0.036402</td>\n      <td>0.036402</td>\n      <td>0.013903</td>\n      <td>0.013903</td>\n      <td>-0.004175</td>\n      <td>-0.004175</td>\n      <td>0.021520</td>\n      <td>0.021520</td>\n    </tr>\n  </tbody>\n</table>\n<p>2213 rows × 4470 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moses50_emb_norm.compare(X_moses50_emb_norm_v2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(2213, 2235)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}