{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Experiment on concatenating raw expressions with embedding vectors\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score\n",
    "def calc_results_simple(X, y, train_index, test_index, clf):\n",
    "    X, y = X.to_numpy(), y.to_numpy(dtype=np.int64)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred  = clf.predict(X_test)\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    recall_0 =  recall_score(y_test, y_pred, pos_label=0)\n",
    "    recall_1 =  recall_score(y_test, y_pred, pos_label=1)\n",
    "    prec_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "    prec_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "    return np.array([[acc, recall_0, prec_0, recall_1, prec_1 ,auc]])\n",
    "\n",
    "#cross_validation\n",
    "def run_cross_val(X, y, params, n_folds=5, random_seed=42):\n",
    "    res = np.empty(shape=[0, 6])\n",
    "    clf = XGBClassifier(**params, n_jobs=8)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        res = np.append(res, calc_results_simple(X, y, train_index, test_index, clf), axis=0)\n",
    "    return res, clf\n",
    "\n",
    "def print_score_comparison(raw_score, emb_score, target_feature=\"RFS\",\n",
    "                           header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"balanced_accuracy\"].mean(), emb_score[\"balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_0\"].mean(), emb_score[\"precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_0\"].mean(), emb_score[\"recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_1\"].mean(), emb_score[\"precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_1\"].mean(), emb_score[\"recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"auc\"].mean(), emb_score[\"auc\"].mean()))\n",
    "\n",
    "def find_misclassified_patients(df, clf, X, y):\n",
    "    y_test = y.to_numpy()\n",
    "    X_test = X.to_numpy()\n",
    "    miss = np.where(y_test != clf.predict(X_test))\n",
    "    return df.iloc[miss][\"patient_ID\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "def calc_overlap(a, b):\n",
    "    intr = np.intersect1d(a, b)\n",
    "    union = np.union1d(a, b)\n",
    "    return intr, (len(intr) / len(union))\n",
    "\n",
    "def print_overlap(model1, model2, intr, perc):\n",
    "    print(\"{0} patients misclassified by {1} and {2} - {3:.1%} overlap\\n\".format(len(intr) ,model1, model2, perc))\n",
    "\n",
    "def write_misclassified(file_name, ls):\n",
    "    with open(\"datasets/\" + file_name + \".txt\", \"w\") as f:\n",
    "        for p in ls:\n",
    "            f.write(str(p) + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300, 400, 500, 600, 700],\n",
    "              'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def param_tuning(X, y, n_folds=5, param_comb=25, scoring='roc_auc', jobs=12):\n",
    "    xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    rand_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring=scoring, n_jobs=jobs,\n",
    "                                   cv=skf.split(X, y), verbose=3, random_state=42)\n",
    "\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    rand_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    print(\"Best Score: {:.3%}\".format(rand_search.best_score_))\n",
    "    print(rand_search.best_params_)\n",
    "    return rand_search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "ge_df = pd.read_csv(\"datasets/merged-combat15.csv\")\n",
    "outcome_df = pd.read_csv(\"datasets/combat15outcomes.csv\")\n",
    "pos_outcome_df = outcome_df[[\"patient_ID\", \"posOutcome\"]].dropna(axis=0, subset=[\"posOutcome\"])\n",
    "pos_outcome_df.posOutcome = pos_outcome_df.posOutcome.astype(int)\n",
    "ge_outcome_df = pd.merge(pos_outcome_df, ge_df, on=\"patient_ID\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome      CDX4     GLRA1    OR12D3     DSCR4     HOXB8  \\\n0       22449           0  4.393932  4.756301  3.668209  3.813140  3.149279   \n1       22450           0  3.735445  3.453197  3.008127  2.500197  3.025658   \n2       22451           0  3.504602  3.591334  3.487448  2.710443  2.786988   \n3       22452           0  2.862134  3.326514  3.346279  3.676626  4.426359   \n4       22453           1  3.706718  4.106301  3.579494  3.123646  3.254895   \n\n         C9    MTNR1B       MOS  ...          2221          2222  \\\n0  4.091114  3.778200  4.149525  ...  2.983482e-06 -5.667081e-06   \n1  3.265710  2.909130  2.990024  ...  2.859682e-06  7.411624e-07   \n2  3.904477  2.879539  3.585594  ...  1.504380e-06  6.565640e-06   \n3  3.111246  3.447916  3.153298  ...  6.847706e-07  2.294943e-06   \n4  3.480252  3.673946  3.867726  ... -5.978619e-07  6.835914e-08   \n\n           2223          2224          2225          2226          2227  \\\n0 -2.578453e-06  3.233320e-06  3.162931e-06 -1.622541e-07 -2.522139e-06   \n1 -3.327798e-07 -7.720635e-07 -3.062798e-06 -2.325743e-07 -6.893824e-07   \n2  4.819232e-07 -2.377132e-06  7.905603e-07 -1.038275e-06 -9.005510e-07   \n3  9.302902e-07 -7.566930e-07 -5.137400e-07  2.965493e-06  1.247254e-06   \n4 -1.627280e-06 -2.343308e-06 -3.645692e-07 -2.182235e-06  1.108295e-06   \n\n           2228          2229          2230  \n0  7.292363e-07  2.538494e-07  2.798644e-08  \n1 -1.527674e-06  2.051379e-06  3.103411e-07  \n2  9.035374e-07  4.423281e-07  5.704054e-08  \n3  2.925552e-07  9.689832e-07  5.092384e-09  \n4  5.456489e-07  2.321873e-06 -1.789428e-07  \n\n[5 rows x 2283 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>CDX4</th>\n      <th>GLRA1</th>\n      <th>OR12D3</th>\n      <th>DSCR4</th>\n      <th>HOXB8</th>\n      <th>C9</th>\n      <th>MTNR1B</th>\n      <th>MOS</th>\n      <th>...</th>\n      <th>2221</th>\n      <th>2222</th>\n      <th>2223</th>\n      <th>2224</th>\n      <th>2225</th>\n      <th>2226</th>\n      <th>2227</th>\n      <th>2228</th>\n      <th>2229</th>\n      <th>2230</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>4.393932</td>\n      <td>4.756301</td>\n      <td>3.668209</td>\n      <td>3.813140</td>\n      <td>3.149279</td>\n      <td>4.091114</td>\n      <td>3.778200</td>\n      <td>4.149525</td>\n      <td>...</td>\n      <td>2.983482e-06</td>\n      <td>-5.667081e-06</td>\n      <td>-2.578453e-06</td>\n      <td>3.233320e-06</td>\n      <td>3.162931e-06</td>\n      <td>-1.622541e-07</td>\n      <td>-2.522139e-06</td>\n      <td>7.292363e-07</td>\n      <td>2.538494e-07</td>\n      <td>2.798644e-08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>3.735445</td>\n      <td>3.453197</td>\n      <td>3.008127</td>\n      <td>2.500197</td>\n      <td>3.025658</td>\n      <td>3.265710</td>\n      <td>2.909130</td>\n      <td>2.990024</td>\n      <td>...</td>\n      <td>2.859682e-06</td>\n      <td>7.411624e-07</td>\n      <td>-3.327798e-07</td>\n      <td>-7.720635e-07</td>\n      <td>-3.062798e-06</td>\n      <td>-2.325743e-07</td>\n      <td>-6.893824e-07</td>\n      <td>-1.527674e-06</td>\n      <td>2.051379e-06</td>\n      <td>3.103411e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>3.504602</td>\n      <td>3.591334</td>\n      <td>3.487448</td>\n      <td>2.710443</td>\n      <td>2.786988</td>\n      <td>3.904477</td>\n      <td>2.879539</td>\n      <td>3.585594</td>\n      <td>...</td>\n      <td>1.504380e-06</td>\n      <td>6.565640e-06</td>\n      <td>4.819232e-07</td>\n      <td>-2.377132e-06</td>\n      <td>7.905603e-07</td>\n      <td>-1.038275e-06</td>\n      <td>-9.005510e-07</td>\n      <td>9.035374e-07</td>\n      <td>4.423281e-07</td>\n      <td>5.704054e-08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>2.862134</td>\n      <td>3.326514</td>\n      <td>3.346279</td>\n      <td>3.676626</td>\n      <td>4.426359</td>\n      <td>3.111246</td>\n      <td>3.447916</td>\n      <td>3.153298</td>\n      <td>...</td>\n      <td>6.847706e-07</td>\n      <td>2.294943e-06</td>\n      <td>9.302902e-07</td>\n      <td>-7.566930e-07</td>\n      <td>-5.137400e-07</td>\n      <td>2.965493e-06</td>\n      <td>1.247254e-06</td>\n      <td>2.925552e-07</td>\n      <td>9.689832e-07</td>\n      <td>5.092384e-09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>3.706718</td>\n      <td>4.106301</td>\n      <td>3.579494</td>\n      <td>3.123646</td>\n      <td>3.254895</td>\n      <td>3.480252</td>\n      <td>3.673946</td>\n      <td>3.867726</td>\n      <td>...</td>\n      <td>-5.978619e-07</td>\n      <td>6.835914e-08</td>\n      <td>-1.627280e-06</td>\n      <td>-2.343308e-06</td>\n      <td>-3.645692e-07</td>\n      <td>-2.182235e-06</td>\n      <td>1.108295e-06</td>\n      <td>5.456489e-07</td>\n      <td>2.321873e-06</td>\n      <td>-1.789428e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2283 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['patient_ID', 'posOutcome', 'CDX4','GLRA1', 'OR12D3', 'DSCR4', 'HOXB8', 'C9', 'MTNR1B', 'MOS', 'HSD17B3', 'FGF20', 'KCNH4', 'ATP4B', 'CPB2', 'CRYBB1', 'ANGPTL3', 'MYH8', 'GYS2', 'SLC25A21', 'TAS2R7', 'F11', 'GABRA6', 'MYT1L', 'DEFB126', 'RPL18', 'GABRQ', 'ZFP37', 'PIP5K1B', 'MCM5', 'PRKAA1', 'WDR76', 'CHRM4', 'RPS6KC1', 'EIF1AY', 'WNT1', 'SCN3B', 'NLGN4Y', 'MAGEB1', 'NUDC', 'HIGD1A', 'OXCT2', 'GALR2', 'EEF1B2', 'RXRG', 'CALCA', 'TEX13A', 'CST3', 'IGFBP4', 'CRYGA', 'ESR1', 'ZNF750']\n",
    "\n",
    "tmp_df = ge_outcome_df[cols]\n",
    "\n",
    "xgb50_emb_df = pd.read_csv(\"datasets/embedding-vectors/property_vector_xgb50_withoutplnresult_2020-12-23.csv\", sep=\"\\t\")\n",
    "xgb50_outcome_df = pd.merge(tmp_df, xgb50_emb_df, on=\"patient_ID\")\n",
    "X_xgb50_outcome, y_xg50_outcome = xgb50_outcome_df[xgb50_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])], xgb50_outcome_df[\"posOutcome\"]\n",
    "xgb50_outcome_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:38:44] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:38:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 44 minutes and 31.42 seconds.\n",
      "Best Score: 77.879%\n",
      "{'subsample': 0.8, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 5, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed: 40.5min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_xg50 = param_tuning(X_xgb50_outcome, y_xg50_outcome, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "outcome_xg50_params = {'subsample': 0.8,\n",
    " 'n_estimators': 600,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 5,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:06:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:07:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:07:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:08:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:08:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.699896  0.516319     0.726036  0.883472     0.752908   \nstd             0.039918  0.069596     0.054114  0.022830     0.028664   \nmin             0.655081  0.427711     0.655172  0.855072     0.721713   \n25%             0.659704  0.455090     0.702970  0.876812     0.722222   \n50%             0.715514  0.554217     0.730159  0.876812     0.765823   \n75%             0.727562  0.566265     0.738462  0.891697     0.775641   \nmax             0.741616  0.578313     0.803419  0.916968     0.779141   \n\n            auc  \ncount  5.000000  \nmean   0.778792  \nstd    0.025239  \nmin    0.741343  \n25%    0.764364  \n50%    0.792452  \n75%    0.794681  \nmax    0.801118  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.699896</td>\n      <td>0.516319</td>\n      <td>0.726036</td>\n      <td>0.883472</td>\n      <td>0.752908</td>\n      <td>0.778792</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.039918</td>\n      <td>0.069596</td>\n      <td>0.054114</td>\n      <td>0.022830</td>\n      <td>0.028664</td>\n      <td>0.025239</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.655081</td>\n      <td>0.427711</td>\n      <td>0.655172</td>\n      <td>0.855072</td>\n      <td>0.721713</td>\n      <td>0.741343</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.659704</td>\n      <td>0.455090</td>\n      <td>0.702970</td>\n      <td>0.876812</td>\n      <td>0.722222</td>\n      <td>0.764364</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.715514</td>\n      <td>0.554217</td>\n      <td>0.730159</td>\n      <td>0.876812</td>\n      <td>0.765823</td>\n      <td>0.792452</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.727562</td>\n      <td>0.566265</td>\n      <td>0.738462</td>\n      <td>0.891697</td>\n      <td>0.775641</td>\n      <td>0.794681</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.741616</td>\n      <td>0.578313</td>\n      <td>0.803419</td>\n      <td>0.916968</td>\n      <td>0.779141</td>\n      <td>0.801118</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_xg50_scores, clf_xg50 = run_cross_val(X_xgb50_outcome, y_xg50_outcome, outcome_xg50_params)\n",
    "outcome_xg50_df = pd.DataFrame(data=outcome_xg50_scores, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "outcome_xg50_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "   patient_ID  posOutcome      PRND      FRS3      FCN3     DSCR4     BRCA2  \\\n0       22449           0  4.773548  3.792942  3.591425  3.813140  3.842011   \n1       22450           0  4.050956  3.596728  3.603971  2.500197  2.761469   \n2       22451           0  5.213503  3.892048  3.655383  2.710443  2.561722   \n3       22452           0  3.443242  3.713757  3.370449  3.676626  3.947755   \n4       22453           1  4.237601  3.800724  3.259677  3.123646  3.354961   \n\n      CXCL6     LMX1B      DLX5  ...          2223          2224  \\\n0  3.301166  3.155381  4.092754  ...  3.837437e-06  3.315117e-06   \n1  3.679678  3.406322  3.698481  ...  5.243294e-06 -1.819026e-06   \n2  3.748453  3.964545  4.125640  ...  5.728294e-06  7.688957e-09   \n3  2.890541  2.987402  3.919090  ... -4.844169e-06  2.724217e-06   \n4  3.029855  3.116395  3.882619  ...  6.608744e-07  3.468912e-06   \n\n           2225          2226      2227          2228          2229  \\\n0  8.110773e-07  5.140755e-07 -0.000002  4.659053e-07  1.246811e-07   \n1  1.511906e-06 -5.381149e-08  0.000001  1.001947e-06 -2.010190e-06   \n2 -6.358236e-08 -1.185732e-06  0.000002  1.467577e-06  1.072813e-06   \n3  3.021055e-06 -1.983205e-06  0.000001  4.689168e-06  3.073779e-06   \n4  3.783993e-06 -2.091969e-06  0.000002  1.407070e-06  2.260274e-06   \n\n           2230          2231          2232  \n0 -5.459261e-07 -1.940580e-08  1.044367e-06  \n1 -2.846180e-07  5.900286e-07  2.206977e-07  \n2  3.649615e-07  5.383282e-07  6.781582e-07  \n3 -1.868303e-07  2.015108e-08 -2.133324e-07  \n4  7.934927e-07 -3.723606e-07 -4.706951e-07  \n\n[5 rows x 2285 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_ID</th>\n      <th>posOutcome</th>\n      <th>PRND</th>\n      <th>FRS3</th>\n      <th>FCN3</th>\n      <th>DSCR4</th>\n      <th>BRCA2</th>\n      <th>CXCL6</th>\n      <th>LMX1B</th>\n      <th>DLX5</th>\n      <th>...</th>\n      <th>2223</th>\n      <th>2224</th>\n      <th>2225</th>\n      <th>2226</th>\n      <th>2227</th>\n      <th>2228</th>\n      <th>2229</th>\n      <th>2230</th>\n      <th>2231</th>\n      <th>2232</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22449</td>\n      <td>0</td>\n      <td>4.773548</td>\n      <td>3.792942</td>\n      <td>3.591425</td>\n      <td>3.813140</td>\n      <td>3.842011</td>\n      <td>3.301166</td>\n      <td>3.155381</td>\n      <td>4.092754</td>\n      <td>...</td>\n      <td>3.837437e-06</td>\n      <td>3.315117e-06</td>\n      <td>8.110773e-07</td>\n      <td>5.140755e-07</td>\n      <td>-0.000002</td>\n      <td>4.659053e-07</td>\n      <td>1.246811e-07</td>\n      <td>-5.459261e-07</td>\n      <td>-1.940580e-08</td>\n      <td>1.044367e-06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22450</td>\n      <td>0</td>\n      <td>4.050956</td>\n      <td>3.596728</td>\n      <td>3.603971</td>\n      <td>2.500197</td>\n      <td>2.761469</td>\n      <td>3.679678</td>\n      <td>3.406322</td>\n      <td>3.698481</td>\n      <td>...</td>\n      <td>5.243294e-06</td>\n      <td>-1.819026e-06</td>\n      <td>1.511906e-06</td>\n      <td>-5.381149e-08</td>\n      <td>0.000001</td>\n      <td>1.001947e-06</td>\n      <td>-2.010190e-06</td>\n      <td>-2.846180e-07</td>\n      <td>5.900286e-07</td>\n      <td>2.206977e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22451</td>\n      <td>0</td>\n      <td>5.213503</td>\n      <td>3.892048</td>\n      <td>3.655383</td>\n      <td>2.710443</td>\n      <td>2.561722</td>\n      <td>3.748453</td>\n      <td>3.964545</td>\n      <td>4.125640</td>\n      <td>...</td>\n      <td>5.728294e-06</td>\n      <td>7.688957e-09</td>\n      <td>-6.358236e-08</td>\n      <td>-1.185732e-06</td>\n      <td>0.000002</td>\n      <td>1.467577e-06</td>\n      <td>1.072813e-06</td>\n      <td>3.649615e-07</td>\n      <td>5.383282e-07</td>\n      <td>6.781582e-07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22452</td>\n      <td>0</td>\n      <td>3.443242</td>\n      <td>3.713757</td>\n      <td>3.370449</td>\n      <td>3.676626</td>\n      <td>3.947755</td>\n      <td>2.890541</td>\n      <td>2.987402</td>\n      <td>3.919090</td>\n      <td>...</td>\n      <td>-4.844169e-06</td>\n      <td>2.724217e-06</td>\n      <td>3.021055e-06</td>\n      <td>-1.983205e-06</td>\n      <td>0.000001</td>\n      <td>4.689168e-06</td>\n      <td>3.073779e-06</td>\n      <td>-1.868303e-07</td>\n      <td>2.015108e-08</td>\n      <td>-2.133324e-07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22453</td>\n      <td>1</td>\n      <td>4.237601</td>\n      <td>3.800724</td>\n      <td>3.259677</td>\n      <td>3.123646</td>\n      <td>3.354961</td>\n      <td>3.029855</td>\n      <td>3.116395</td>\n      <td>3.882619</td>\n      <td>...</td>\n      <td>6.608744e-07</td>\n      <td>3.468912e-06</td>\n      <td>3.783993e-06</td>\n      <td>-2.091969e-06</td>\n      <td>0.000002</td>\n      <td>1.407070e-06</td>\n      <td>2.260274e-06</td>\n      <td>7.934927e-07</td>\n      <td>-3.723606e-07</td>\n      <td>-4.706951e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2285 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moses_cols = [\"patient_ID\", \"posOutcome\", \"PRND\", \"FRS3\", \"FCN3\", \"DSCR4\", \"BRCA2\", \"CXCL6\", \"LMX1B\", \"DLX5\", \"OMP\", \"ADH6\", \"PGAP1\", \"ART3\", \"BCHE\", \"FGB\", \"IL1RAPL1\", \"FSTL4\", \"ASGR1\", \"ZNF135\", \"DLL3\", \"NPHS2\", \"ANGPT2\", \"GLP2R\", \"GRIA3\", \"HOXB8\", \"MSC\", \"PLA2R1\", \"CYP2F1\", \"TAS2R7\", \"NKX6-1\", \"WNT11\", \"CHST11\", \"CLCA4\", \"ENPEP\", \"PAH\", \"WFDC1\", \"CHGA\", \"SEZ6L\", \"UGT2A3\", \"PRDM16\", \"GALR2\", \"GUCA1A\", \"CASQ1\", \"NOS1AP\", \"CACNA2D3\", \"FHOD3\", \"SRGAP3\", \"TMOD2\", \"ATOH1\", \"SLC6A1\", \"HAS1\"]\n",
    "\n",
    "tmp_df = ge_outcome_df[moses_cols]\n",
    "emb_df = pd.read_csv(\"datasets/embedding-vectors/property_vector_moses50_withoutplnresult_2020-12-23.csv\", sep=\"\\t\")\n",
    "emb_outcome_df = pd.merge(tmp_df, emb_df, on=\"patient_ID\")\n",
    "X_emb_outcome, y_emb_outcome = emb_outcome_df[emb_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])], emb_outcome_df[\"posOutcome\"]\n",
    "emb_outcome_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[12:54:17] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:54:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 42 minutes and 46.71 seconds.\n",
      "Best Score: 76.576%\n",
      "{'subsample': 1.0, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed: 40.1min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses50 = param_tuning(X_emb_outcome, y_emb_outcome, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "outcome_moses50_params = {'subsample': 1.0,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 1,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:52:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:53:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:53:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:53:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:54:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "       balanced_accuracy  recall_0  precision_0  recall_1  precision_1  \\\ncount           5.000000  5.000000     5.000000  5.000000     5.000000   \nmean            0.691251  0.487432     0.735507  0.895069     0.744087   \nstd             0.033616  0.052509     0.053586  0.019852     0.022706   \nmin             0.655496  0.431138     0.679245  0.877256     0.720588   \n25%             0.659409  0.433735     0.699029  0.884058     0.721068   \n50%             0.699275  0.500000     0.733333  0.887681     0.749245   \n75%             0.707089  0.530120     0.747748  0.898551     0.757764   \nmax             0.734983  0.542169     0.818182  0.927798     0.771772   \n\n            auc  \ncount  5.000000  \nmean   0.765764  \nstd    0.019368  \nmin    0.742710  \n25%    0.747031  \n50%    0.774860  \n75%    0.781393  \nmax    0.782827  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>balanced_accuracy</th>\n      <th>recall_0</th>\n      <th>precision_0</th>\n      <th>recall_1</th>\n      <th>precision_1</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.691251</td>\n      <td>0.487432</td>\n      <td>0.735507</td>\n      <td>0.895069</td>\n      <td>0.744087</td>\n      <td>0.765764</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.033616</td>\n      <td>0.052509</td>\n      <td>0.053586</td>\n      <td>0.019852</td>\n      <td>0.022706</td>\n      <td>0.019368</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.655496</td>\n      <td>0.431138</td>\n      <td>0.679245</td>\n      <td>0.877256</td>\n      <td>0.720588</td>\n      <td>0.742710</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.659409</td>\n      <td>0.433735</td>\n      <td>0.699029</td>\n      <td>0.884058</td>\n      <td>0.721068</td>\n      <td>0.747031</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.699275</td>\n      <td>0.500000</td>\n      <td>0.733333</td>\n      <td>0.887681</td>\n      <td>0.749245</td>\n      <td>0.774860</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.707089</td>\n      <td>0.530120</td>\n      <td>0.747748</td>\n      <td>0.898551</td>\n      <td>0.757764</td>\n      <td>0.781393</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.734983</td>\n      <td>0.542169</td>\n      <td>0.818182</td>\n      <td>0.927798</td>\n      <td>0.771772</td>\n      <td>0.782827</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_moses50_scores, clf_moses50 = run_cross_val(X_emb_outcome, y_emb_outcome, outcome_moses50_params)\n",
    "outcome_moses50_df = pd.DataFrame(data=outcome_moses50_scores, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "outcome_moses50_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMOSES 50\t\tXgboost 50\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t69.125%\t\t\t69.990%\n",
      "\n",
      "precision_0:\t\t73.551%\t\t\t72.604%\n",
      "\n",
      "recall_0:\t\t48.743%\t\t\t51.632%\n",
      "\n",
      "precision_1:\t\t74.409%\t\t\t75.291%\n",
      "\n",
      "recall_1:\t\t89.507%\t\t\t88.347%\n",
      "\n",
      "auc:\t\t\t76.576%\t\t\t77.879%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(outcome_moses50_df, outcome_xg50_df, target_feature=\"posOutcome\", header_1=\"MOSES 50\", header_2=\"Xgboost 50\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}