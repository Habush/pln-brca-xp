{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1549, 8833)\n",
      "Test shape:(664, 8833)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ge_outcome_df = pd.read_csv(\"datasets/train.csv\")\n",
    "ge_outcome_test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "X_outcome, y_outcome = ge_outcome_df[ge_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])], ge_outcome_df[\"posOutcome\"]\n",
    "\n",
    "X_test, y_test = ge_outcome_test_df[ge_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])], ge_outcome_test_df[\"posOutcome\"]\n",
    "\n",
    "print(\"Train shape: {0}\\nTest shape:{1}\".format(X_outcome.shape, X_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Load the models\n",
    "clf_xg50 = XGBClassifier()\n",
    "clf_xg50.load_model(\"datasets/models/xgb50_raw.json\")\n",
    "clf_moses50 = XGBClassifier()\n",
    "clf_moses50.load_model(\"datasets/models/moses50_raw.json\")\n",
    "clf_raw = XGBClassifier()\n",
    "clf_raw.load_model(\"datasets/models/raw_model.json\")\n",
    "clf_pam = XGBClassifier()\n",
    "clf_pam.load_model(\"datasets/models/pam35_raw.json\")\n",
    "clf_gan = XGBClassifier()\n",
    "clf_gan.load_model(\"datasets/models/infogan_model.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def calc_scores(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    recall_0, recall_1 = recall_score(y_test, y_pred, pos_label=0), recall_score(y_test, y_pred, pos_label=1)\n",
    "    precision_0, precision_1 =  precision_score(y_test, y_pred, pos_label=0), precision_score(y_test, y_pred, pos_label=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return np.array([[acc, recall_0, precision_0, recall_1, precision_1, auc_score]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "moses50_genes = [\"PRND\", \"FRS3\", \"FCN3\", \"DSCR4\", \"BRCA2\", \"CXCL6\", \"LMX1B\", \"DLX5\", \"OMP\", \"ADH6\", \"PGAP1\", \"ART3\", \"BCHE\", \"FGB\", \"IL1RAPL1\", \"FSTL4\", \"ASGR1\", \"ZNF135\", \"DLL3\", \"NPHS2\", \"ANGPT2\", \"GLP2R\", \"GRIA3\", \"HOXB8\", \"MSC\", \"PLA2R1\", \"CYP2F1\", \"TAS2R7\", \"NKX6-1\", \"WNT11\", \"CHST11\", \"CLCA4\", \"ENPEP\", \"PAH\", \"WFDC1\", \"CHGA\", \"SEZ6L\", \"UGT2A3\", \"PRDM16\", \"GALR2\", \"GUCA1A\", \"CASQ1\", \"NOS1AP\", \"CACNA2D3\", \"FHOD3\", \"SRGAP3\", \"TMOD2\", \"ATOH1\", \"SLC6A1\", \"HAS1\"]\n",
    "xgb50_genes = ['CDX4','GLRA1', 'OR12D3', 'DSCR4', 'HOXB8', 'C9', 'MTNR1B', 'MOS', 'HSD17B3', 'FGF20', 'KCNH4', 'ATP4B', 'CPB2', 'CRYBB1', 'ANGPTL3', 'MYH8', 'GYS2', 'SLC25A21', 'TAS2R7', 'F11', 'GABRA6', 'MYT1L', 'DEFB126', 'RPL18', 'GABRQ', 'ZFP37', 'PIP5K1B', 'MCM5', 'PRKAA1', 'WDR76', 'CHRM4', 'RPS6KC1', 'EIF1AY', 'WNT1', 'SCN3B', 'NLGN4Y', 'MAGEB1', 'NUDC', 'HIGD1A', 'OXCT2', 'GALR2', 'EEF1B2', 'RXRG', 'CALCA', 'TEX13A', 'CST3', 'IGFBP4', 'CRYGA', 'ESR1', 'ZNF750']\n",
    "pam35_genes = [\"BAG1\", \"BIRC5\", \"BLVRA\", \"CCNB1\", \"CCNE1\", \"CDC20\", \"CDC6\", \"CDH3\", \"CENPF\", \"CEP55\", \"EGFR\", \"ERBB2\", \"ESR1\", \"EXO1\", \"FOXA1\", \"FOXC1\",  \"GRB7\", \"KIF2C\", \"KRT14\", \"KRT17\", \"KRT5\", \"MAPT\", \"MDM2\", \"MELK\", \"MIA\", \"MKI67\", \"MMP11\", \"MYBL2\", \"MYC\", \"PGR\", \"RRM2\", \"SFRP1\", \"SLC39A6\", \"TYMS\", \"UBE2C\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: pipeline (1/4)\n",
      "Fitting classifier2: pipeline (2/4)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Fitting classifier4: xgbclassifier (4/4)\n",
      "[16:11:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:11:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:11:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:11:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   2 out of   5 | elapsed:    1.7s remaining:    2.5s\n",
      "[Parallel(n_jobs=14)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   2 out of   5 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=14)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   2 out of   5 | elapsed:    1.4s remaining:    2.1s\n",
      "[Parallel(n_jobs=14)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   2 out of   5 | elapsed:  3.2min remaining:  4.8min\n",
      "[Parallel(n_jobs=14)]: Done   5 out of   5 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "StackingCVClassifier(classifiers=[Pipeline(steps=[('columnselector',\n                                                   ColumnSelector(cols=['PRND',\n                                                                        'FRS3',\n                                                                        'FCN3',\n                                                                        'DSCR4',\n                                                                        'BRCA2',\n                                                                        'CXCL6',\n                                                                        'LMX1B',\n                                                                        'DLX5',\n                                                                        'OMP',\n                                                                        'ADH6',\n                                                                        'PGAP1',\n                                                                        'ART3',\n                                                                        'BCHE',\n                                                                        'FGB',\n                                                                        'IL1RAPL1',\n                                                                        'FSTL4',\n                                                                        'ASGR1',\n                                                                        'ZNF135',\n                                                                        'DLL3',\n                                                                        'NPHS2',\n                                                                        'ANGPT2',\n                                                                        'GLP2R',\n                                                                        'GRIA3',\n                                                                        'HOXB8',\n                                                                        'MSC',\n                                                                        'PLA2R1',\n                                                                        'CYP2F1',\n                                                                        'TAS2R7',\n                                                                        'NKX6-1',\n                                                                        'WNT11', ...])),\n                                                  ('xgbclassifier',\n                                                   XG...\n                                                monotone_constraints='()',\n                                                n_estimators=700, n_jobs=4,\n                                                num_parallel_tree=1,\n                                                random_state=0, reg_alpha=0,\n                                                reg_lambda=1,\n                                                scale_pos_weight=1,\n                                                subsample=0.6,\n                                                tree_method='exact',\n                                                validate_parameters=1,\n                                                verbosity=None)],\n                     cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n                     meta_classifier=LogisticRegression(), n_jobs=14,\n                     random_state=42, use_clones=False, verbose=True)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "cv = StratifiedKFold(shuffle=True, n_splits=5, random_state=seed)\n",
    "\n",
    "moses50_pipe = make_pipeline(ColumnSelector(cols=moses50_genes),\n",
    "                           clf_moses50)\n",
    "\n",
    "xgb50_pipe = make_pipeline(ColumnSelector(cols=xgb50_genes),\n",
    "                           clf_xg50)\n",
    "\n",
    "pam35_pipe = make_pipeline(ColumnSelector(cols=pam35_genes),\n",
    "                           clf_pam)\n",
    "\n",
    "sclf_1 = StackingCVClassifier(classifiers=[moses50_pipe, xgb50_pipe, pam35_pipe, clf_raw], meta_classifier=LogisticRegression(),\n",
    "                              cv=cv, use_clones=False, verbose=True,\n",
    "                              n_jobs=14,\n",
    "                              random_state=seed)\n",
    "\n",
    "sclf_1.fit(X_outcome, y_outcome)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(sclf_1, X_outcome, y_outcome, n_jobs=10,\n",
    "                                              cv=3, scoring='balanced_accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\"\n",
    "      % (scores.mean(), scores.std()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7217961418602318"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}