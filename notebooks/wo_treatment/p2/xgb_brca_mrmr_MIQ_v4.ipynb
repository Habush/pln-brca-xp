{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, recall_score, balanced_accuracy_score, precision_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300, 400, 500, 600, 700],\n",
    "              'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n",
    "\n",
    "seed = 42\n",
    "st_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "def calc_scores(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    recall_0, recall_1 = recall_score(y_test, y_pred, pos_label=0), recall_score(y_test, y_pred, pos_label=1)\n",
    "    precision_0, precision_1 =  precision_score(y_test, y_pred, pos_label=0), precision_score(y_test, y_pred, pos_label=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    arr = np.array([[acc, precision_0, recall_0, precision_1, recall_1,auc_score]])\n",
    "    return pd.DataFrame(data=arr, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "\n",
    "def recall_0(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "def precision_0(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "scoring = {\"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "           \"recall_0\": make_scorer(recall_0), \"precision_0\": make_scorer(precision_0),\n",
    "           \"recall_1\": make_scorer(recall_score), \"precision_1\": make_scorer(precision_score), \"auc\": \"roc_auc\" }\n",
    "\n",
    "#cross_validation\n",
    "\n",
    "def print_score_comparison(raw_score, emb_score, target_feature=\"posOutcome\",\n",
    "                           header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"balanced_accuracy\"].mean(), emb_score[\"balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_0\"].mean(), emb_score[\"precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_0\"].mean(), emb_score[\"recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_1\"].mean(), emb_score[\"precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_1\"].mean(), emb_score[\"recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"auc\"].mean(), emb_score[\"auc\"].mean()))\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def param_tuning(X, y, n_folds=5, param_comb=25, scoring='roc_auc', jobs=12):\n",
    "    xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    rand_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring=scoring, n_jobs=jobs,\n",
    "                                   cv=skf.split(X, y), verbose=3, random_state=42)\n",
    "\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    rand_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    print(\"Best Score: {:.3%}\".format(rand_search.best_score_))\n",
    "    print(rand_search.best_params_)\n",
    "    return rand_search\n",
    "\n",
    "score_cols = [\"test_balanced_accuracy\",\"test_precision_0\", \"test_recall_0\",\n",
    "               \"test_precision_1\",\"test_recall_1\", \"test_auc\"]\n",
    "\n",
    "def get_scores(cv_results, score_keys=score_cols, df_cols=score_cols):\n",
    "    scores = np.empty([1, len(score_keys)])\n",
    "    for i, s in enumerate(score_keys):\n",
    "        scores[0][i] = np.mean(cv_results[s])\n",
    "    scores_df = pd.DataFrame(data=scores, columns=df_cols)\n",
    "    return scores_df\n",
    "\n",
    "\n",
    "def evaluate_ge(x_train, y_train, x_test, y_test, feats=None, jobs=-1,\n",
    "                scoring=scoring, rand_scoring=\"roc_auc\", target=\"posOutcome\"):\n",
    "    if feats is not None:\n",
    "        x_train = x_train[feats]\n",
    "        x_test = x_test[feats]\n",
    "    rand_search = param_tuning(x_train, y_train, scoring=rand_scoring)\n",
    "    params = rand_search.best_params_\n",
    "    clf = XGBClassifier(**params)\n",
    "    cv_res = cross_validate(clf, x_train, y_train,scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "\n",
    "    cv_res_df = get_scores(cv_res, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "    clf.fit(x_train, y_train)\n",
    "    test_scores_df = calc_scores(clf, x_test, y_test)\n",
    "\n",
    "    return params, cv_res_df, test_scores_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "     A4GALT      AAAS      AACS     AADAC      AAK1      AAMP     AANAT  \\\n0  3.490594  4.705177  7.388903  3.146066  5.324219  7.010299  3.204220   \n1  3.493298  6.025729  6.501462  3.015961  4.639765  7.399345  3.801613   \n2  3.426142  5.449551  5.632613  3.685224  5.643874  6.737401  3.596668   \n3  3.426381  5.595401  6.882855  3.240755  6.075660  6.943799  3.202970   \n4  3.479792  5.565861  4.662279  3.176784  6.033194  7.274996  3.204731   \n\n       AARS    AARSD1  AASDHPPT  ...    ZNHIT2       ZP2      ZPBP    ZSCAN2  \\\n0  7.623260  4.908548  7.920498  ...  3.616936  3.177763  3.120909  3.626377   \n1  8.326222  5.075999  6.635090  ...  4.002873  3.182145  3.414617  3.933382   \n2  7.431818  5.591313  6.596328  ...  2.695141  3.324802  3.251439  2.909459   \n3  7.477471  4.904070  6.518033  ...  3.384700  3.144302  3.158701  3.521218   \n4  7.105333  6.663767  6.667291  ...  3.414956  3.139913  3.185299  3.572568   \n\n       ZW10     ZWINT      ZXDC       ZYX     ZZEF1      ZZZ3  \n0  5.573573  7.840314  5.720305  7.491440  7.049239  6.979166  \n1  3.717363  9.053191  6.370379  7.888914  5.422555  5.951768  \n2  4.385828  6.415808  5.480143  7.644960  6.797248  6.808280  \n3  3.968905  6.774039  6.299851  7.620011  5.797529  5.871506  \n4  3.874406  6.490379  6.589065  6.327172  6.770991  6.890959  \n\n[5 rows x 8832 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A4GALT</th>\n      <th>AAAS</th>\n      <th>AACS</th>\n      <th>AADAC</th>\n      <th>AAK1</th>\n      <th>AAMP</th>\n      <th>AANAT</th>\n      <th>AARS</th>\n      <th>AARSD1</th>\n      <th>AASDHPPT</th>\n      <th>...</th>\n      <th>ZNHIT2</th>\n      <th>ZP2</th>\n      <th>ZPBP</th>\n      <th>ZSCAN2</th>\n      <th>ZW10</th>\n      <th>ZWINT</th>\n      <th>ZXDC</th>\n      <th>ZYX</th>\n      <th>ZZEF1</th>\n      <th>ZZZ3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.490594</td>\n      <td>4.705177</td>\n      <td>7.388903</td>\n      <td>3.146066</td>\n      <td>5.324219</td>\n      <td>7.010299</td>\n      <td>3.204220</td>\n      <td>7.623260</td>\n      <td>4.908548</td>\n      <td>7.920498</td>\n      <td>...</td>\n      <td>3.616936</td>\n      <td>3.177763</td>\n      <td>3.120909</td>\n      <td>3.626377</td>\n      <td>5.573573</td>\n      <td>7.840314</td>\n      <td>5.720305</td>\n      <td>7.491440</td>\n      <td>7.049239</td>\n      <td>6.979166</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.493298</td>\n      <td>6.025729</td>\n      <td>6.501462</td>\n      <td>3.015961</td>\n      <td>4.639765</td>\n      <td>7.399345</td>\n      <td>3.801613</td>\n      <td>8.326222</td>\n      <td>5.075999</td>\n      <td>6.635090</td>\n      <td>...</td>\n      <td>4.002873</td>\n      <td>3.182145</td>\n      <td>3.414617</td>\n      <td>3.933382</td>\n      <td>3.717363</td>\n      <td>9.053191</td>\n      <td>6.370379</td>\n      <td>7.888914</td>\n      <td>5.422555</td>\n      <td>5.951768</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.426142</td>\n      <td>5.449551</td>\n      <td>5.632613</td>\n      <td>3.685224</td>\n      <td>5.643874</td>\n      <td>6.737401</td>\n      <td>3.596668</td>\n      <td>7.431818</td>\n      <td>5.591313</td>\n      <td>6.596328</td>\n      <td>...</td>\n      <td>2.695141</td>\n      <td>3.324802</td>\n      <td>3.251439</td>\n      <td>2.909459</td>\n      <td>4.385828</td>\n      <td>6.415808</td>\n      <td>5.480143</td>\n      <td>7.644960</td>\n      <td>6.797248</td>\n      <td>6.808280</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.426381</td>\n      <td>5.595401</td>\n      <td>6.882855</td>\n      <td>3.240755</td>\n      <td>6.075660</td>\n      <td>6.943799</td>\n      <td>3.202970</td>\n      <td>7.477471</td>\n      <td>4.904070</td>\n      <td>6.518033</td>\n      <td>...</td>\n      <td>3.384700</td>\n      <td>3.144302</td>\n      <td>3.158701</td>\n      <td>3.521218</td>\n      <td>3.968905</td>\n      <td>6.774039</td>\n      <td>6.299851</td>\n      <td>7.620011</td>\n      <td>5.797529</td>\n      <td>5.871506</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.479792</td>\n      <td>5.565861</td>\n      <td>4.662279</td>\n      <td>3.176784</td>\n      <td>6.033194</td>\n      <td>7.274996</td>\n      <td>3.204731</td>\n      <td>7.105333</td>\n      <td>6.663767</td>\n      <td>6.667291</td>\n      <td>...</td>\n      <td>3.414956</td>\n      <td>3.139913</td>\n      <td>3.185299</td>\n      <td>3.572568</td>\n      <td>3.874406</td>\n      <td>6.490379</td>\n      <td>6.589065</td>\n      <td>6.327172</td>\n      <td>6.770991</td>\n      <td>6.890959</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 8832 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "X_train, y_train = train_df[train_df.columns.difference([\"patient_ID\", \"posOutcome\"])], train_df[\"posOutcome\"]\n",
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "fts_50_df = pd.read_csv(\"datasets/mrmr_top50.tsv\", sep=\"\\t\")\n",
    "fts_50_df.columns = [\"Order\", \"Feat_Index\", \"Name\", \"Score\"]\n",
    "fts_50_df[\"Name\"] = fts_50_df[\"Name\"].str.strip()\n",
    "feats_50 = fts_50_df[\"Name\"].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       VNN2     ALAS2      E2F8    KIF21B      PPBP   SLITRK3      AQP9  \\\n0  3.189026  2.844616  4.046337  3.891334  2.993143  3.159996  3.711596   \n1  4.874852  2.845986  5.026899  2.517917  5.312810  3.382119  4.410487   \n2  6.907824  4.942284  3.512500  3.724512  5.608529  2.916534  6.535881   \n3  3.957820  4.426584  3.695720  3.319210  4.085435  3.150267  4.255222   \n4  4.846836  3.986994  3.560645  3.260197  4.244365  3.164787  4.170049   \n\n        DCT     IFNA8    EEF1A2  ...      TGM3      PLS1    GABRB2   SLCO1A2  \\\n0  2.496415  3.465665  8.246389  ...  3.799822  2.877010  3.268373  3.291948   \n1  2.003576  4.518373  6.361501  ...  4.325120  5.431930  3.444966  2.184971   \n2  2.392424  3.456740  4.133781  ...  3.999087  2.300098  3.597382  3.212796   \n3  2.535919  3.466438  4.651417  ...  3.595345  3.578949  3.315006  3.357198   \n4  2.559143  3.468037  5.927124  ...  3.700837  4.838044  3.540718  3.655555   \n\n     CHRNB3       BTC     SEMG1     P2RX7     P2RX3       LPO  \n0  3.290748  4.300402  3.263049  3.203500  3.165366  3.495641  \n1  3.482821  3.648820  2.790352  2.290437  2.604582  3.845958  \n2  3.276235  2.382300  2.845405  4.577597  4.208842  3.275248  \n3  3.283405  3.525310  3.230333  3.168525  3.182496  3.524188  \n4  3.332204  3.494355  3.215563  3.825358  3.197231  3.534038  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VNN2</th>\n      <th>ALAS2</th>\n      <th>E2F8</th>\n      <th>KIF21B</th>\n      <th>PPBP</th>\n      <th>SLITRK3</th>\n      <th>AQP9</th>\n      <th>DCT</th>\n      <th>IFNA8</th>\n      <th>EEF1A2</th>\n      <th>...</th>\n      <th>TGM3</th>\n      <th>PLS1</th>\n      <th>GABRB2</th>\n      <th>SLCO1A2</th>\n      <th>CHRNB3</th>\n      <th>BTC</th>\n      <th>SEMG1</th>\n      <th>P2RX7</th>\n      <th>P2RX3</th>\n      <th>LPO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.189026</td>\n      <td>2.844616</td>\n      <td>4.046337</td>\n      <td>3.891334</td>\n      <td>2.993143</td>\n      <td>3.159996</td>\n      <td>3.711596</td>\n      <td>2.496415</td>\n      <td>3.465665</td>\n      <td>8.246389</td>\n      <td>...</td>\n      <td>3.799822</td>\n      <td>2.877010</td>\n      <td>3.268373</td>\n      <td>3.291948</td>\n      <td>3.290748</td>\n      <td>4.300402</td>\n      <td>3.263049</td>\n      <td>3.203500</td>\n      <td>3.165366</td>\n      <td>3.495641</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.874852</td>\n      <td>2.845986</td>\n      <td>5.026899</td>\n      <td>2.517917</td>\n      <td>5.312810</td>\n      <td>3.382119</td>\n      <td>4.410487</td>\n      <td>2.003576</td>\n      <td>4.518373</td>\n      <td>6.361501</td>\n      <td>...</td>\n      <td>4.325120</td>\n      <td>5.431930</td>\n      <td>3.444966</td>\n      <td>2.184971</td>\n      <td>3.482821</td>\n      <td>3.648820</td>\n      <td>2.790352</td>\n      <td>2.290437</td>\n      <td>2.604582</td>\n      <td>3.845958</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.907824</td>\n      <td>4.942284</td>\n      <td>3.512500</td>\n      <td>3.724512</td>\n      <td>5.608529</td>\n      <td>2.916534</td>\n      <td>6.535881</td>\n      <td>2.392424</td>\n      <td>3.456740</td>\n      <td>4.133781</td>\n      <td>...</td>\n      <td>3.999087</td>\n      <td>2.300098</td>\n      <td>3.597382</td>\n      <td>3.212796</td>\n      <td>3.276235</td>\n      <td>2.382300</td>\n      <td>2.845405</td>\n      <td>4.577597</td>\n      <td>4.208842</td>\n      <td>3.275248</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.957820</td>\n      <td>4.426584</td>\n      <td>3.695720</td>\n      <td>3.319210</td>\n      <td>4.085435</td>\n      <td>3.150267</td>\n      <td>4.255222</td>\n      <td>2.535919</td>\n      <td>3.466438</td>\n      <td>4.651417</td>\n      <td>...</td>\n      <td>3.595345</td>\n      <td>3.578949</td>\n      <td>3.315006</td>\n      <td>3.357198</td>\n      <td>3.283405</td>\n      <td>3.525310</td>\n      <td>3.230333</td>\n      <td>3.168525</td>\n      <td>3.182496</td>\n      <td>3.524188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.846836</td>\n      <td>3.986994</td>\n      <td>3.560645</td>\n      <td>3.260197</td>\n      <td>4.244365</td>\n      <td>3.164787</td>\n      <td>4.170049</td>\n      <td>2.559143</td>\n      <td>3.468037</td>\n      <td>5.927124</td>\n      <td>...</td>\n      <td>3.700837</td>\n      <td>4.838044</td>\n      <td>3.540718</td>\n      <td>3.655555</td>\n      <td>3.332204</td>\n      <td>3.494355</td>\n      <td>3.215563</td>\n      <td>3.825358</td>\n      <td>3.197231</td>\n      <td>3.534038</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_50 = X_train[feats_50]\n",
    "X_train_50.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:43:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:43:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 26.44 seconds.\n",
      "Best Score: 78.050%\n",
      "{'subsample': 1.0, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.03, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:   23.7s finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_50 = param_tuning(X_train_50, y_train, jobs=14, scoring=\"balanced_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "params_50 = {'subsample': 0.8,\n",
    " 'n_estimators': 600,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 5,\n",
    " 'colsample_bytree': 0.6}\n",
    "\n",
    "params_50_acc = {'subsample': 1.0,\n",
    " 'n_estimators': 500,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 1.5,\n",
    " 'colsample_bytree': 0.8}\n",
    "\n",
    "clf_50 = XGBClassifier(**params_50, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([1.0860393 , 1.18201399, 1.78926873, 1.39332485, 1.69145489]),\n 'score_time': array([0.03048277, 0.02456141, 0.01260757, 0.01266479, 0.01258349]),\n 'test_balanced_accuracy': array([0.74494267, 0.77907453, 0.76124079, 0.7963145 , 0.78513514]),\n 'test_recall_0': array([0.79393939, 0.78787879, 0.74545455, 0.78181818, 0.8       ]),\n 'test_precision_0': array([0.74431818, 0.79268293, 0.78846154, 0.82165605, 0.79518072]),\n 'test_recall_1': array([0.69594595, 0.77027027, 0.77702703, 0.81081081, 0.77027027]),\n 'test_precision_1': array([0.75182482, 0.76510067, 0.73248408, 0.76923077, 0.7755102 ]),\n 'test_auc': array([0.83099918, 0.82395577, 0.8496724 , 0.8495086 , 0.83988534])}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_50 = XGBClassifier(**params_50, n_jobs=4)\n",
    "cv_results_50 = cross_validate(clf_50, X_train_50, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.773342\nrecall_0             0.788460\nprecision_0          0.781818\nrecall_1             0.758830\nprecision_1          0.764865\nauc                  0.838804\ndtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_50_df = get_scores(cv_results_50, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "X_test, y_test = test_df[test_df.columns.difference([\"patient_ID\", \"posOutcome\"])], test_df[\"posOutcome\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:21:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6, gamma=5, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.01, max_delta_step=0, max_depth=6,\n              min_child_weight=3, missing=nan, monotone_constraints='()',\n              n_estimators=600, n_jobs=4, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_50.fit(X_train_50, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    74.944036\nrecall_0             76.420455\nprecision_0          75.988701\nrecall_1             73.437500\nprecision_1          73.899371\nauc                  80.808727\ndtype: float64"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_50 = X_test[feats_50]\n",
    "\n",
    "test_scores_50 = calc_scores(clf_50, X_test_50, y_test)\n",
    "scores_test_50_df = pd.DataFrame(data=test_scores_50, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_50_df.mean() * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "fts_100_df = pd.read_csv(\"datasets/mrmr_top100.tsv\", sep=\"\\t\")\n",
    "fts_100_df.columns = [\"Order\", \"Feat_Index\", \"Name\", \"Score\"]\n",
    "fts_100_df[\"Name\"] = fts_100_df[\"Name\"].str.strip()\n",
    "feats_100 = fts_100_df[\"Name\"].to_list()\n",
    "\n",
    "with open(\"datasets/mrmr_ft100.txt\", \"w\") as fp:\n",
    "    for i in feats_100:\n",
    "        fp.write(\"%s\\n\" % i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "       VNN2    SLC9A7      ADD2    FNDC3B    EEF1A2      E2F8      FUT3  \\\n0  3.189026  3.442448  3.283981  6.704807  8.246389  4.046337  4.469728   \n1  4.874852  3.548765  3.662784  7.195187  6.361501  5.026899  5.951502   \n2  6.907824  3.208379  3.682653  7.386021  4.133781  3.512500  3.481282   \n3  3.957820  3.432061  2.821736  7.049656  4.651417  3.695720  3.622156   \n4  4.846836  3.429549  3.562138  6.093097  5.927124  3.560645  4.199089   \n\n       PLS1     KIF1A     ZFPM2  ...     CASQ1   ATP6V1D    CHRNB3      TGM3  \\\n0  2.877010  6.434729  4.089961  ...  3.296052  6.800505  3.290748  3.799822   \n1  5.431930  2.533096  4.317466  ...  3.218257  6.136464  3.482821  4.325120   \n2  2.300098  3.108423  5.881096  ...  3.055024  8.064784  3.276235  3.999087   \n3  3.578949  3.262309  5.774240  ...  3.308403  7.500499  3.283405  3.595345   \n4  4.838044  3.293778  2.471808  ...  3.285745  7.870956  3.332204  3.700837   \n\n     RAD54L    TRIM17     HOXB1      CCR4      SGCG  SLC16A10  \n0  4.188891  3.448275  3.226325  3.345735  2.774195  3.181459  \n1  4.204713  4.131960  3.524856  3.786295  1.804320  3.999230  \n2  3.344914  2.777815  3.495302  3.334185  3.203982  4.547595  \n3  4.098439  3.436705  3.141711  3.375781  2.663900  3.165514  \n4  4.086651  3.482446  3.236798  3.423178  2.669285  3.260832  \n\n[5 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VNN2</th>\n      <th>SLC9A7</th>\n      <th>ADD2</th>\n      <th>FNDC3B</th>\n      <th>EEF1A2</th>\n      <th>E2F8</th>\n      <th>FUT3</th>\n      <th>PLS1</th>\n      <th>KIF1A</th>\n      <th>ZFPM2</th>\n      <th>...</th>\n      <th>CASQ1</th>\n      <th>ATP6V1D</th>\n      <th>CHRNB3</th>\n      <th>TGM3</th>\n      <th>RAD54L</th>\n      <th>TRIM17</th>\n      <th>HOXB1</th>\n      <th>CCR4</th>\n      <th>SGCG</th>\n      <th>SLC16A10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.189026</td>\n      <td>3.442448</td>\n      <td>3.283981</td>\n      <td>6.704807</td>\n      <td>8.246389</td>\n      <td>4.046337</td>\n      <td>4.469728</td>\n      <td>2.877010</td>\n      <td>6.434729</td>\n      <td>4.089961</td>\n      <td>...</td>\n      <td>3.296052</td>\n      <td>6.800505</td>\n      <td>3.290748</td>\n      <td>3.799822</td>\n      <td>4.188891</td>\n      <td>3.448275</td>\n      <td>3.226325</td>\n      <td>3.345735</td>\n      <td>2.774195</td>\n      <td>3.181459</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.874852</td>\n      <td>3.548765</td>\n      <td>3.662784</td>\n      <td>7.195187</td>\n      <td>6.361501</td>\n      <td>5.026899</td>\n      <td>5.951502</td>\n      <td>5.431930</td>\n      <td>2.533096</td>\n      <td>4.317466</td>\n      <td>...</td>\n      <td>3.218257</td>\n      <td>6.136464</td>\n      <td>3.482821</td>\n      <td>4.325120</td>\n      <td>4.204713</td>\n      <td>4.131960</td>\n      <td>3.524856</td>\n      <td>3.786295</td>\n      <td>1.804320</td>\n      <td>3.999230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.907824</td>\n      <td>3.208379</td>\n      <td>3.682653</td>\n      <td>7.386021</td>\n      <td>4.133781</td>\n      <td>3.512500</td>\n      <td>3.481282</td>\n      <td>2.300098</td>\n      <td>3.108423</td>\n      <td>5.881096</td>\n      <td>...</td>\n      <td>3.055024</td>\n      <td>8.064784</td>\n      <td>3.276235</td>\n      <td>3.999087</td>\n      <td>3.344914</td>\n      <td>2.777815</td>\n      <td>3.495302</td>\n      <td>3.334185</td>\n      <td>3.203982</td>\n      <td>4.547595</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.957820</td>\n      <td>3.432061</td>\n      <td>2.821736</td>\n      <td>7.049656</td>\n      <td>4.651417</td>\n      <td>3.695720</td>\n      <td>3.622156</td>\n      <td>3.578949</td>\n      <td>3.262309</td>\n      <td>5.774240</td>\n      <td>...</td>\n      <td>3.308403</td>\n      <td>7.500499</td>\n      <td>3.283405</td>\n      <td>3.595345</td>\n      <td>4.098439</td>\n      <td>3.436705</td>\n      <td>3.141711</td>\n      <td>3.375781</td>\n      <td>2.663900</td>\n      <td>3.165514</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.846836</td>\n      <td>3.429549</td>\n      <td>3.562138</td>\n      <td>6.093097</td>\n      <td>5.927124</td>\n      <td>3.560645</td>\n      <td>4.199089</td>\n      <td>4.838044</td>\n      <td>3.293778</td>\n      <td>2.471808</td>\n      <td>...</td>\n      <td>3.285745</td>\n      <td>7.870956</td>\n      <td>3.332204</td>\n      <td>3.700837</td>\n      <td>4.086651</td>\n      <td>3.482446</td>\n      <td>3.236798</td>\n      <td>3.423178</td>\n      <td>2.669285</td>\n      <td>3.260832</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_100 = X_train[feats_100]\n",
    "X_train_100.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:44:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:44:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 1 minutes and 2.77 seconds.\n",
      "Best Score: 86.505%\n",
      "{'subsample': 1.0, 'n_estimators': 700, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 2, 'colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:   51.2s finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_100 = param_tuning(X_train_100, y_train, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "params_100 = {'subsample': 1.0,\n",
    " 'n_estimators': 700,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 2,\n",
    " 'colsample_bytree': 1.0}\n",
    "\n",
    "clf_100 = XGBClassifier(**params_100, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([5.71115232, 5.39548516, 5.37466288, 6.26632833, 5.48115301]),\n 'score_time': array([0.01630974, 0.0211966 , 0.02494478, 0.01715851, 0.01657534]),\n 'test_balanced_accuracy': array([0.7522932 , 0.79830057, 0.78920966, 0.80773956, 0.78583129]),\n 'test_recall_0': array([0.84242424, 0.80606061, 0.78787879, 0.81818182, 0.78787879]),\n 'test_precision_0': array([0.73544974, 0.81097561, 0.80745342, 0.81818182, 0.80246914]),\n 'test_recall_1': array([0.66216216, 0.79054054, 0.79054054, 0.7972973 , 0.78378378]),\n 'test_precision_1': array([0.79032258, 0.7852349 , 0.76973684, 0.7972973 , 0.76821192]),\n 'test_auc': array([0.83665029, 0.86855037, 0.87223587, 0.87858313, 0.86920557])}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_100 = cross_validate(clf_100, X_train_100, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.786675\nrecall_0             0.794906\nprecision_0          0.808485\nrecall_1             0.782161\nprecision_1          0.764865\nauc                  0.865045\ndtype: float64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_100_df = get_scores(cv_results_100, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_100_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:44:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.756689\nrecall_0             0.782738\nprecision_0          0.742938\nrecall_1             0.729167\nprecision_1          0.770440\nauc                  0.815043\ndtype: float64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_100.fit(X_train_100, y_train)\n",
    "X_test_100 = X_test[feats_100]\n",
    "\n",
    "test_scores_100 = calc_scores(clf_100, X_test_100, y_test)\n",
    "scores_test_100_df = pd.DataFrame(data=test_scores_100, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_100_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "with open(\"mrmr_ft50.txt\", \"w\") as fp:\n",
    "    for f in feats_50:\n",
    "        fp.write(f + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([84.99123073, 85.22930431, 84.73753142, 83.90528011, 85.05328965]),\n 'score_time': array([0.03603697, 0.01239944, 0.05494833, 0.06586123, 0.04502559]),\n 'test_balanced_accuracy': array([0.76347256, 0.78781736, 0.77848075, 0.78349713, 0.78920966]),\n 'test_recall_0': array([0.82424242, 0.81212121, 0.73939394, 0.76969697, 0.78787879]),\n 'test_precision_0': array([0.75555556, 0.79289941, 0.81879195, 0.8089172 , 0.80745342]),\n 'test_recall_1': array([0.7027027 , 0.76351351, 0.81756757, 0.7972973 , 0.79054054]),\n 'test_precision_1': array([0.78195489, 0.78472222, 0.73780488, 0.75641026, 0.76973684]),\n 'test_auc': array([0.82624898, 0.82461097, 0.83181818, 0.83992629, 0.83718264])}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_50_acc = XGBClassifier(**params_50_acc)\n",
    "cv_results_50_acc = cross_validate(clf_50_acc, X_train_50, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_50_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.780495\nrecall_0             0.796724\nprecision_0          0.786667\nrecall_1             0.766126\nprecision_1          0.774324\nauc                  0.831957\ndtype: float64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_50_acc_df = get_scores(cv_results_50_acc, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_50_acc_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "X_test, y_test = test_df[test_df.columns.difference([\"patient_ID\", \"posOutcome\"])], test_df[\"posOutcome\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:46:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.8, gamma=1.5, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.03, max_delta_step=0, max_depth=6,\n              min_child_weight=3, missing=nan, monotone_constraints='()',\n              n_estimators=500, n_jobs=16, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_50_acc.fit(X_train_50, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.749440\nrecall_0             0.764205\nprecision_0          0.759887\nrecall_1             0.734375\nprecision_1          0.738994\nauc                  0.808087\ndtype: float64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_50_acc = X_test[feats_50]\n",
    "\n",
    "test_scores_50_acc = calc_scores(clf_50_acc, X_test_50_acc, y_test)\n",
    "scores_test_50_acc_df = pd.DataFrame(data=test_scores_50_acc, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:47:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:47:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 57.05 seconds.\n",
      "Best Score: 79.031%\n",
      "{'subsample': 1.0, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.03, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:   50.5s finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_100_acc = param_tuning(X_train_100, y_train, jobs=14,\n",
    "                                   scoring=\"balanced_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "params_100_acc = {'subsample': 1.0,\n",
    " 'n_estimators': 500,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 1.5,\n",
    " 'colsample_bytree': 0.8}\n",
    "\n",
    "clf_100_acc = XGBClassifier(**params_100_acc, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([2.21092725, 3.06532526, 2.77823281, 3.44965267, 3.39590836]),\n 'score_time': array([0.04098296, 0.01549959, 0.01548004, 0.01407075, 0.01474571]),\n 'test_balanced_accuracy': array([0.7492629 , 0.79154382, 0.79154382, 0.81449631, 0.80470925]),\n 'test_recall_0': array([0.83636364, 0.80606061, 0.80606061, 0.81818182, 0.81212121]),\n 'test_precision_0': array([0.73404255, 0.80120482, 0.80120482, 0.82822086, 0.81707317]),\n 'test_recall_1': array([0.66216216, 0.77702703, 0.77702703, 0.81081081, 0.7972973 ]),\n 'test_precision_1': array([0.784     , 0.78231293, 0.78231293, 0.8       , 0.79194631]),\n 'test_auc': array([0.84025389, 0.85851761, 0.87162162, 0.87858313, 0.86879607])}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_100_acc = cross_validate(clf_100_acc, X_train_100, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_100_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.790311\nrecall_0             0.796349\nprecision_0          0.815758\nrecall_1             0.788114\nprecision_1          0.764865\nauc                  0.863554\ndtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_100_acc_df = get_scores(cv_results_100_acc, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_100_acc_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:47:29] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.756689\nrecall_0             0.782738\nprecision_0          0.742938\nrecall_1             0.729167\nprecision_1          0.770440\nauc                  0.815043\ndtype: float64"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_100_acc.fit(X_train_100, y_train)\n",
    "X_test_100 = X_test[feats_100]\n",
    "\n",
    "test_scores_100_acc = calc_scores(clf_100_acc, X_test_100, y_test)\n",
    "scores_test_100_acc_df = pd.DataFrame(data=test_scores_100_acc, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_100_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "fts_250_df = pd.read_csv(\"datasets/mrmr_top250.tsv\", sep=\"\\t\")\n",
    "fts_250_df.columns = [\"Order\", \"Feat_Index\", \"Name\", \"Score\"]\n",
    "fts_250_df[\"Name\"] = fts_250_df[\"Name\"].str.strip()\n",
    "feats_250 = fts_250_df[\"Name\"].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "       VNN2    SLC9A7      ADD2    FNDC3B    EEF1A2      E2F8      FUT3  \\\n0  3.189026  3.442448  3.283981  6.704807  8.246389  4.046337  4.469728   \n1  4.874852  3.548765  3.662784  7.195187  6.361501  5.026899  5.951502   \n2  6.907824  3.208379  3.682653  7.386021  4.133781  3.512500  3.481282   \n3  3.957820  3.432061  2.821736  7.049656  4.651417  3.695720  3.622156   \n4  4.846836  3.429549  3.562138  6.093097  5.927124  3.560645  4.199089   \n\n       PLS1     KIF1A     ZFPM2  ...     EPHA5    ZNF132  PNLIPRP2     FOLR3  \\\n0  2.877010  6.434729  4.089961  ...  3.057387  3.065054  3.191119  2.912554   \n1  5.431930  2.533096  4.317466  ...  3.231490  2.947054  2.612252  3.816940   \n2  2.300098  3.108423  5.881096  ...  3.104999  3.610148  2.493980  3.102581   \n3  3.578949  3.262309  5.774240  ...  3.058671  2.982013  3.206150  2.992058   \n4  4.838044  3.293778  2.471808  ...  3.108481  3.068660  3.168892  3.013119   \n\n      GRIA3       F11     FETUB     MCM10     GNAT1     MYOM2  \n0  3.110144  3.054204  3.461555  5.718198  3.160783  3.652451  \n1  2.784161  3.189547  2.898729  3.676932  3.608013  3.791195  \n2  3.800372  2.337907  3.223666  2.091747  3.111369  3.391864  \n3  3.114048  3.048890  3.473469  3.328275  3.201443  3.706868  \n4  3.149837  3.054605  3.493431  3.246946  3.248864  3.627807  \n\n[5 rows x 250 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VNN2</th>\n      <th>SLC9A7</th>\n      <th>ADD2</th>\n      <th>FNDC3B</th>\n      <th>EEF1A2</th>\n      <th>E2F8</th>\n      <th>FUT3</th>\n      <th>PLS1</th>\n      <th>KIF1A</th>\n      <th>ZFPM2</th>\n      <th>...</th>\n      <th>EPHA5</th>\n      <th>ZNF132</th>\n      <th>PNLIPRP2</th>\n      <th>FOLR3</th>\n      <th>GRIA3</th>\n      <th>F11</th>\n      <th>FETUB</th>\n      <th>MCM10</th>\n      <th>GNAT1</th>\n      <th>MYOM2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.189026</td>\n      <td>3.442448</td>\n      <td>3.283981</td>\n      <td>6.704807</td>\n      <td>8.246389</td>\n      <td>4.046337</td>\n      <td>4.469728</td>\n      <td>2.877010</td>\n      <td>6.434729</td>\n      <td>4.089961</td>\n      <td>...</td>\n      <td>3.057387</td>\n      <td>3.065054</td>\n      <td>3.191119</td>\n      <td>2.912554</td>\n      <td>3.110144</td>\n      <td>3.054204</td>\n      <td>3.461555</td>\n      <td>5.718198</td>\n      <td>3.160783</td>\n      <td>3.652451</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.874852</td>\n      <td>3.548765</td>\n      <td>3.662784</td>\n      <td>7.195187</td>\n      <td>6.361501</td>\n      <td>5.026899</td>\n      <td>5.951502</td>\n      <td>5.431930</td>\n      <td>2.533096</td>\n      <td>4.317466</td>\n      <td>...</td>\n      <td>3.231490</td>\n      <td>2.947054</td>\n      <td>2.612252</td>\n      <td>3.816940</td>\n      <td>2.784161</td>\n      <td>3.189547</td>\n      <td>2.898729</td>\n      <td>3.676932</td>\n      <td>3.608013</td>\n      <td>3.791195</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.907824</td>\n      <td>3.208379</td>\n      <td>3.682653</td>\n      <td>7.386021</td>\n      <td>4.133781</td>\n      <td>3.512500</td>\n      <td>3.481282</td>\n      <td>2.300098</td>\n      <td>3.108423</td>\n      <td>5.881096</td>\n      <td>...</td>\n      <td>3.104999</td>\n      <td>3.610148</td>\n      <td>2.493980</td>\n      <td>3.102581</td>\n      <td>3.800372</td>\n      <td>2.337907</td>\n      <td>3.223666</td>\n      <td>2.091747</td>\n      <td>3.111369</td>\n      <td>3.391864</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.957820</td>\n      <td>3.432061</td>\n      <td>2.821736</td>\n      <td>7.049656</td>\n      <td>4.651417</td>\n      <td>3.695720</td>\n      <td>3.622156</td>\n      <td>3.578949</td>\n      <td>3.262309</td>\n      <td>5.774240</td>\n      <td>...</td>\n      <td>3.058671</td>\n      <td>2.982013</td>\n      <td>3.206150</td>\n      <td>2.992058</td>\n      <td>3.114048</td>\n      <td>3.048890</td>\n      <td>3.473469</td>\n      <td>3.328275</td>\n      <td>3.201443</td>\n      <td>3.706868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.846836</td>\n      <td>3.429549</td>\n      <td>3.562138</td>\n      <td>6.093097</td>\n      <td>5.927124</td>\n      <td>3.560645</td>\n      <td>4.199089</td>\n      <td>4.838044</td>\n      <td>3.293778</td>\n      <td>2.471808</td>\n      <td>...</td>\n      <td>3.108481</td>\n      <td>3.068660</td>\n      <td>3.168892</td>\n      <td>3.013119</td>\n      <td>3.149837</td>\n      <td>3.054605</td>\n      <td>3.493431</td>\n      <td>3.246946</td>\n      <td>3.248864</td>\n      <td>3.627807</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 250 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_250 = X_train[feats_250]\n",
    "X_train_250.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:49:18] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:49:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 1 minutes and 55.21 seconds.\n",
      "Best Score: 86.037%\n",
      "{'subsample': 0.8, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_250 = param_tuning(X_train_250, y_train, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "params_250 = {'subsample': 1.0,\n",
    " 'n_estimators': 700,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 2,\n",
    " 'colsample_bytree': 1.0}\n",
    "\n",
    "clf_250 = XGBClassifier(**params_250, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([11.09212136, 10.92821479, 10.87433219, 12.678509  , 10.35476208]),\n 'score_time': array([0.02493453, 0.02382922, 0.02383351, 0.02303648, 0.06923652]),\n 'test_balanced_accuracy': array([0.76312449, 0.78314906, 0.77569615, 0.78548321, 0.79527027]),\n 'test_recall_0': array([0.83030303, 0.77575758, 0.78787879, 0.79393939, 0.8       ]),\n 'test_precision_0': array([0.75274725, 0.80503145, 0.78787879, 0.79878049, 0.80981595]),\n 'test_recall_1': array([0.69594595, 0.79054054, 0.76351351, 0.77702703, 0.79054054]),\n 'test_precision_1': array([0.78625954, 0.75974026, 0.76351351, 0.77181208, 0.78      ]),\n 'test_auc': array([0.8476249 , 0.8490991 , 0.8549959 , 0.86285831, 0.85876331])}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_250 = cross_validate(clf_250, X_train_250, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_250"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.780545\nrecall_0             0.790851\nprecision_0          0.797576\nrecall_1             0.772265\nprecision_1          0.763514\nauc                  0.854668\ndtype: float64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_250_df = get_scores(cv_results_250, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_250_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:49:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.757622\nrecall_0             0.778426\nprecision_0          0.754237\nrecall_1             0.735562\nprecision_1          0.761006\nauc                  0.825525\ndtype: float64"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_250.fit(X_train_250, y_train)\n",
    "X_test_250 = X_test[feats_250]\n",
    "\n",
    "test_scores_250 = calc_scores(clf_250, X_test_250, y_test)\n",
    "scores_test_250_df = pd.DataFrame(data=test_scores_250, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_250_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:51:32] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:51:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 1 minutes and 53.7 seconds.\n",
      "Best Score: 79.166%\n",
      "{'subsample': 0.6, 'n_estimators': 400, 'min_child_weight': 4, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.5, 'colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_250_acc = param_tuning(X_train_250, y_train, jobs=14, scoring=\"balanced_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "params_250_acc = {'subsample': 0.6,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 4,\n",
    " 'max_depth': 4,\n",
    " 'learning_rate': 0.05,\n",
    " 'gamma': 0.5,\n",
    " 'colsample_bytree': 1.0}\n",
    "\n",
    "clf_250_acc = XGBClassifier(**params_250_acc, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([2.43479872, 3.91175222, 3.35607243, 2.6762898 , 3.34731841]),\n 'score_time': array([0.05500865, 0.01890111, 0.02124858, 0.05094147, 0.01976895]),\n 'test_balanced_accuracy': array([0.77862408, 0.78583129, 0.78513514, 0.81648239, 0.79223997]),\n 'test_recall_0': array([0.85454545, 0.78787879, 0.8       , 0.84242424, 0.79393939]),\n 'test_precision_0': array([0.76216216, 0.80246914, 0.79518072, 0.81764706, 0.80864198]),\n 'test_recall_1': array([0.7027027 , 0.78378378, 0.77027027, 0.79054054, 0.79054054]),\n 'test_precision_1': array([0.8125    , 0.76821192, 0.7755102 , 0.81818182, 0.77483444]),\n 'test_auc': array([0.85462735, 0.84471744, 0.85573301, 0.87747748, 0.85036855])}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_250_acc = cross_validate(clf_250_acc, X_train_250, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_250_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.791663\nrecall_0             0.797220\nprecision_0          0.815758\nrecall_1             0.789848\nprecision_1          0.767568\nauc                  0.856585\ndtype: float64"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_250_acc_df = get_scores(cv_results_250_acc, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_250_acc_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:51:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.751972\nrecall_0             0.775811\nprecision_0          0.742938\nrecall_1             0.726727\nprecision_1          0.761006\nauc                  0.823553\ndtype: float64"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_250_acc.fit(X_train_250, y_train)\n",
    "X_test_250_acc = X_test[feats_250]\n",
    "\n",
    "test_scores_250_acc = calc_scores(clf_250_acc, X_test_250_acc, y_test)\n",
    "scores_test_250_acc_df = pd.DataFrame(data=test_scores_250_acc, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_250_acc_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def discretize_dataset(X, features, bins_labels = None):\n",
    "    if bins_labels is None:\n",
    "\t    bins_labels = [-1, 0, 1]\n",
    "    X_disc = X[features]\n",
    "    bin_dict = {}\n",
    "\n",
    "    for ft in features:\n",
    "        r1 = X_disc[ft].mean() - X_disc[ft].std() / 2\n",
    "        r2 = X_disc[ft].mean() + X_disc[ft].std() / 2\n",
    "        bin_dict[ft]= [-np.inf, r1, r2, np.inf]\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    le.fit(bins_labels)\n",
    "\n",
    "    for ft in bin_dict:\n",
    "        X_disc[ft] = le.transform(pd.cut(X_disc[ft], bins=bin_dict[ft], labels=bins_labels))\n",
    "\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    transformed = ohe.fit_transform(X_disc).toarray()\n",
    "    X_disc = pd.DataFrame(transformed, columns=ohe.get_feature_names(features))\n",
    "    return X_disc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "   VNN2_0  VNN2_1  VNN2_2  ALAS2_0  ALAS2_1  ALAS2_2  E2F8_0  E2F8_1  E2F8_2  \\\n0     1.0     0.0     0.0      1.0      0.0      0.0     0.0     1.0     0.0   \n1     0.0     0.0     1.0      1.0      0.0      0.0     0.0     0.0     1.0   \n2     0.0     0.0     1.0      0.0      0.0      1.0     1.0     0.0     0.0   \n3     0.0     1.0     0.0      0.0      1.0      0.0     0.0     1.0     0.0   \n4     0.0     0.0     1.0      0.0      1.0      0.0     1.0     0.0     0.0   \n\n   KIF21B_0  ...  SEMG1_2  P2RX7_0  P2RX7_1  P2RX7_2  P2RX3_0  P2RX3_1  \\\n0       0.0  ...      0.0      0.0      1.0      0.0      0.0      1.0   \n1       1.0  ...      0.0      1.0      0.0      0.0      1.0      0.0   \n2       0.0  ...      0.0      0.0      0.0      1.0      0.0      0.0   \n3       0.0  ...      0.0      0.0      1.0      0.0      0.0      1.0   \n4       0.0  ...      0.0      0.0      0.0      1.0      0.0      1.0   \n\n   P2RX3_2  LPO_0  LPO_1  LPO_2  \n0      0.0    0.0    1.0    0.0  \n1      0.0    0.0    0.0    1.0  \n2      1.0    1.0    0.0    0.0  \n3      0.0    0.0    1.0    0.0  \n4      0.0    0.0    1.0    0.0  \n\n[5 rows x 150 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VNN2_0</th>\n      <th>VNN2_1</th>\n      <th>VNN2_2</th>\n      <th>ALAS2_0</th>\n      <th>ALAS2_1</th>\n      <th>ALAS2_2</th>\n      <th>E2F8_0</th>\n      <th>E2F8_1</th>\n      <th>E2F8_2</th>\n      <th>KIF21B_0</th>\n      <th>...</th>\n      <th>SEMG1_2</th>\n      <th>P2RX7_0</th>\n      <th>P2RX7_1</th>\n      <th>P2RX7_2</th>\n      <th>P2RX3_0</th>\n      <th>P2RX3_1</th>\n      <th>P2RX3_2</th>\n      <th>LPO_0</th>\n      <th>LPO_1</th>\n      <th>LPO_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 150 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_50_disc = discretize_dataset(X_train_50, feats_50)\n",
    "X_train_50_disc.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[14:02:05] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:02:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 29.15 seconds.\n",
      "Best Score: 81.724%\n",
      "{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 2, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:   27.7s finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_50_disc = param_tuning(X_train_50_disc, y_train, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "params_50_disc = {'subsample': 0.8,\n",
    " 'n_estimators': 300,\n",
    " 'min_child_weight': 5,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 2,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([43.05165124, 44.55136251, 44.39183044, 44.17680407, 44.62382197]),\n 'score_time': array([0.06611395, 0.03911924, 0.04112458, 0.04994822, 0.01732683]),\n 'test_balanced_accuracy': array([0.71791564, 0.76427109, 0.75890663, 0.77882883, 0.76019656]),\n 'test_recall_0': array([0.79393939, 0.75151515, 0.72727273, 0.73333333, 0.76363636]),\n 'test_precision_0': array([0.71195652, 0.78980892, 0.79470199, 0.82312925, 0.77777778]),\n 'test_recall_1': array([0.64189189, 0.77702703, 0.79054054, 0.82432432, 0.75675676]),\n 'test_precision_1': array([0.73643411, 0.73717949, 0.72222222, 0.73493976, 0.74172185]),\n 'test_auc': array([0.78820639, 0.80687961, 0.82448812, 0.83918919, 0.82743653])}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_50_disc = XGBClassifier(**params_50_disc)\n",
    "cv_results_50_disc = cross_validate(clf_50_disc, X_train_50_disc, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_50_disc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.756024\nrecall_0             0.779475\nprecision_0          0.753939\nrecall_1             0.734499\nprecision_1          0.758108\nauc                  0.817240\ndtype: float64"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_50_disc_df = get_scores(cv_results_50_disc, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_50_disc_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tContin 50 Feats\t\tDisc 50 Feats\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t77.334%\t\t\t75.670%\n",
      "\n",
      "precision_0:\t\t78.182%\t\t\t75.394%\n",
      "\n",
      "recall_0:\t\t78.846%\t\t\t78.031%\n",
      "\n",
      "precision_1:\t\t76.486%\t\t\t75.946%\n",
      "\n",
      "recall_1:\t\t75.883%\t\t\t73.386%\n",
      "\n",
      "auc:\t\t\t83.880%\t\t\t81.801%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(scores_50_df, scores_50_disc_df, header_1=\"Contin 50 Feats\", header_2=\"Disc 50 Feats\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tROC_AUC 50 Feats\t\tAcc 50 Feats\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t77.334%\t\t\t78.050%\n",
      "\n",
      "precision_0:\t\t78.182%\t\t\t78.667%\n",
      "\n",
      "recall_0:\t\t78.846%\t\t\t79.672%\n",
      "\n",
      "precision_1:\t\t76.486%\t\t\t77.432%\n",
      "\n",
      "recall_1:\t\t75.883%\t\t\t76.613%\n",
      "\n",
      "auc:\t\t\t83.880%\t\t\t83.196%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(scores_50_df, scores_50_acc_df, header_1=\"ROC_AUC 50 Feats\", header_2=\"Acc 50 Feats\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[12:03:20] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:03:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 12.66 seconds.\n",
      "Best Score: 76.245%\n",
      "{'subsample': 1.0, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.02, 'gamma': 2, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:   11.4s finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_50_disc_acc = param_tuning(X_train_50_disc, y_train, jobs=14, scoring=\"balanced_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "params_50_disc_acc = {'subsample': 1.0,\n",
    " 'n_estimators': 600,\n",
    " 'min_child_weight': 2,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.02,\n",
    " 'gamma': 2,\n",
    " 'colsample_bytree': 0.6}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([120.20607376, 124.14437604, 123.56309533, 123.47662973,\n        124.14804626]),\n 'score_time': array([0.06935263, 0.02463698, 0.05627537, 0.04311252, 0.02216101]),\n 'test_balanced_accuracy': array([0.70952088, 0.76496724, 0.77510238, 0.7791769 , 0.78349713]),\n 'test_recall_0': array([0.76363636, 0.73939394, 0.73939394, 0.72727273, 0.76969697]),\n 'test_precision_0': array([0.71186441, 0.79738562, 0.81333333, 0.82758621, 0.8089172 ]),\n 'test_recall_1': array([0.65540541, 0.79054054, 0.81081081, 0.83108108, 0.7972973 ]),\n 'test_precision_1': array([0.71323529, 0.73125   , 0.73619632, 0.73214286, 0.75641026]),\n 'test_auc': array([0.79144144, 0.8030303 , 0.82567568, 0.83046683, 0.83157248])}"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_50_disc_acc = XGBClassifier(**params_50_disc_acc)\n",
    "cv_results_50_disc_acc = cross_validate(clf_50_disc_acc, X_train_50_disc, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_50_disc_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.762453\nrecall_0             0.791817\nprecision_0          0.747879\nrecall_1             0.733847\nprecision_1          0.777027\nauc                  0.816437\ndtype: float64"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_50_disc_acc_df = get_scores(cv_results_50_disc_acc, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_50_disc_acc_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "clf_50_acc.save_model(\"datasets/models/clf_mrmr50_acc.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "fts_500_df = pd.read_csv(\"datasets/mrmr_top500.tsv\", sep=\"\\t\")\n",
    "fts_500_df.columns = [\"Order\", \"Feat_Index\", \"Name\", \"Score\"]\n",
    "fts_500_df[\"Name\"] = fts_500_df[\"Name\"].str.strip()\n",
    "feats_500 = fts_500_df[\"Name\"].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "       VNN2    SLC9A7      ADD2    FNDC3B    EEF1A2      E2F8      FUT3  \\\n0  3.189026  3.442448  3.283981  6.704807  8.246389  4.046337  4.469728   \n1  4.874852  3.548765  3.662784  7.195187  6.361501  5.026899  5.951502   \n2  6.907824  3.208379  3.682653  7.386021  4.133781  3.512500  3.481282   \n3  3.957820  3.432061  2.821736  7.049656  4.651417  3.695720  3.622156   \n4  4.846836  3.429549  3.562138  6.093097  5.927124  3.560645  4.199089   \n\n       PLS1     KIF1A     ZFPM2  ...    PHOX2B      GCM2     CDH20     PDE6H  \\\n0  2.877010  6.434729  4.089961  ...  2.991383  3.518356  3.418152  3.066050   \n1  5.431930  2.533096  4.317466  ...  2.410918  2.919491  3.381002  2.671217   \n2  2.300098  3.108423  5.881096  ...  2.736880  2.662786  3.083944  2.852804   \n3  3.578949  3.262309  5.774240  ...  2.970060  3.495451  3.419500  3.066539   \n4  4.838044  3.293778  2.471808  ...  2.989385  3.521955  3.419794  3.066645   \n\n     MTNR1B     CFHR5     GLP2R      DRD4    SLC2A2  C20orf195  \n0  3.346713  3.180736  3.226912  3.155459  3.094382   3.271942  \n1  3.100490  2.762882  3.239015  3.547748  3.365475   3.768267  \n2  3.566948  3.349166  3.623747  2.926309  2.964687   3.057714  \n3  3.337807  3.183639  3.227968  3.155875  3.094691   3.272536  \n4  3.347787  3.183792  3.228055  3.136840  3.094815   3.263791  \n\n[5 rows x 500 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VNN2</th>\n      <th>SLC9A7</th>\n      <th>ADD2</th>\n      <th>FNDC3B</th>\n      <th>EEF1A2</th>\n      <th>E2F8</th>\n      <th>FUT3</th>\n      <th>PLS1</th>\n      <th>KIF1A</th>\n      <th>ZFPM2</th>\n      <th>...</th>\n      <th>PHOX2B</th>\n      <th>GCM2</th>\n      <th>CDH20</th>\n      <th>PDE6H</th>\n      <th>MTNR1B</th>\n      <th>CFHR5</th>\n      <th>GLP2R</th>\n      <th>DRD4</th>\n      <th>SLC2A2</th>\n      <th>C20orf195</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.189026</td>\n      <td>3.442448</td>\n      <td>3.283981</td>\n      <td>6.704807</td>\n      <td>8.246389</td>\n      <td>4.046337</td>\n      <td>4.469728</td>\n      <td>2.877010</td>\n      <td>6.434729</td>\n      <td>4.089961</td>\n      <td>...</td>\n      <td>2.991383</td>\n      <td>3.518356</td>\n      <td>3.418152</td>\n      <td>3.066050</td>\n      <td>3.346713</td>\n      <td>3.180736</td>\n      <td>3.226912</td>\n      <td>3.155459</td>\n      <td>3.094382</td>\n      <td>3.271942</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.874852</td>\n      <td>3.548765</td>\n      <td>3.662784</td>\n      <td>7.195187</td>\n      <td>6.361501</td>\n      <td>5.026899</td>\n      <td>5.951502</td>\n      <td>5.431930</td>\n      <td>2.533096</td>\n      <td>4.317466</td>\n      <td>...</td>\n      <td>2.410918</td>\n      <td>2.919491</td>\n      <td>3.381002</td>\n      <td>2.671217</td>\n      <td>3.100490</td>\n      <td>2.762882</td>\n      <td>3.239015</td>\n      <td>3.547748</td>\n      <td>3.365475</td>\n      <td>3.768267</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.907824</td>\n      <td>3.208379</td>\n      <td>3.682653</td>\n      <td>7.386021</td>\n      <td>4.133781</td>\n      <td>3.512500</td>\n      <td>3.481282</td>\n      <td>2.300098</td>\n      <td>3.108423</td>\n      <td>5.881096</td>\n      <td>...</td>\n      <td>2.736880</td>\n      <td>2.662786</td>\n      <td>3.083944</td>\n      <td>2.852804</td>\n      <td>3.566948</td>\n      <td>3.349166</td>\n      <td>3.623747</td>\n      <td>2.926309</td>\n      <td>2.964687</td>\n      <td>3.057714</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.957820</td>\n      <td>3.432061</td>\n      <td>2.821736</td>\n      <td>7.049656</td>\n      <td>4.651417</td>\n      <td>3.695720</td>\n      <td>3.622156</td>\n      <td>3.578949</td>\n      <td>3.262309</td>\n      <td>5.774240</td>\n      <td>...</td>\n      <td>2.970060</td>\n      <td>3.495451</td>\n      <td>3.419500</td>\n      <td>3.066539</td>\n      <td>3.337807</td>\n      <td>3.183639</td>\n      <td>3.227968</td>\n      <td>3.155875</td>\n      <td>3.094691</td>\n      <td>3.272536</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.846836</td>\n      <td>3.429549</td>\n      <td>3.562138</td>\n      <td>6.093097</td>\n      <td>5.927124</td>\n      <td>3.560645</td>\n      <td>4.199089</td>\n      <td>4.838044</td>\n      <td>3.293778</td>\n      <td>2.471808</td>\n      <td>...</td>\n      <td>2.989385</td>\n      <td>3.521955</td>\n      <td>3.419794</td>\n      <td>3.066645</td>\n      <td>3.347787</td>\n      <td>3.183792</td>\n      <td>3.228055</td>\n      <td>3.136840</td>\n      <td>3.094815</td>\n      <td>3.263791</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 500 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_500 = X_train[feats_500]\n",
    "X_train_500.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[13:59:58] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:59:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 3 minutes and 11.61 seconds.\n",
      "Best Score: 85.836%\n",
      "{'subsample': 1.0, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.03, 'gamma': 0.5, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  3.0min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_500 = param_tuning(X_train_500, y_train, jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "params_500 = {'subsample': 1.0,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 0.5,\n",
    " 'colsample_bytree': 0.6}\n",
    "clf_500 = XGBClassifier(**params_500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.791314\nrecall_0             0.794133\nprecision_0          0.821818\nrecall_1             0.793073\nprecision_1          0.760811\nauc                  0.858362\ndtype: float64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_500 = cross_validate(clf_500, X_train_500, y_train,scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_500_df = get_scores(cv_results_500, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "cv_results_500_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.756343\nrecall_0             0.766017\nprecision_0          0.776836\nrecall_1             0.747604\nprecision_1          0.735849\nauc                  0.824175\ndtype: float64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_500.fit(X_train_500, y_train)\n",
    "X_test_500 = X_test[feats_500]\n",
    "\n",
    "test_scores_500 = calc_scores(clf_500, X_test_500, y_test)\n",
    "test_scores_500_df = pd.DataFrame(data=test_scores_500, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "test_scores_500_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "clf_500.save_model(\"datasets/models/clf_mrmr500.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mrmr_ft50 = load_fea"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}