{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, recall_score, balanced_accuracy_score, precision_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300, 400, 500, 600, 700],\n",
    "              'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n",
    "\n",
    "seed = 42\n",
    "st_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "def calc_scores(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    recall_0, recall_1 = recall_score(y_test, y_pred, pos_label=0), recall_score(y_test, y_pred, pos_label=1)\n",
    "    precision_0, precision_1 =  precision_score(y_test, y_pred, pos_label=0), precision_score(y_test, y_pred, pos_label=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return np.array([[acc, precision_0, recall_0, precision_1, recall_1,auc_score]])\n",
    "\n",
    "def recall_0(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "def precision_0(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "scoring = {\"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "           \"recall_0\": make_scorer(recall_0), \"precision_0\": make_scorer(precision_0),\n",
    "           \"recall_1\": make_scorer(recall_score), \"precision_1\": make_scorer(precision_score), \"auc\": \"roc_auc\" }\n",
    "\n",
    "#cross_validation\n",
    "\n",
    "def print_score_comparison(raw_score, emb_score, target_feature=\"posOutcome\",\n",
    "                           header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"balanced_accuracy\"].mean(), emb_score[\"balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_0\"].mean(), emb_score[\"precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_0\"].mean(), emb_score[\"recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_1\"].mean(), emb_score[\"precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_1\"].mean(), emb_score[\"recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"auc\"].mean(), emb_score[\"auc\"].mean()))\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def param_tuning(X, y, n_folds=5, param_comb=25, scoring='roc_auc', jobs=12):\n",
    "    xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    rand_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring=scoring, n_jobs=jobs,\n",
    "                                   cv=skf.split(X, y), verbose=3, random_state=42)\n",
    "\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    rand_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    print(\"Best Score: {:.3%}\".format(rand_search.best_score_))\n",
    "    print(rand_search.best_params_)\n",
    "    return rand_search\n",
    "\n",
    "score_cols = [\"test_balanced_accuracy\",\"test_precision_0\", \"test_recall_0\",\n",
    "               \"test_precision_1\",\"test_recall_1\", \"test_auc\"]\n",
    "\n",
    "def get_scores(cv_results, score_keys=score_cols, df_cols=score_cols):\n",
    "    scores = np.empty([1, len(score_keys)])\n",
    "    for i, s in enumerate(score_keys):\n",
    "        scores[0][i] = np.mean(cv_results[s])\n",
    "    scores_df = pd.DataFrame(data=scores, columns=df_cols)\n",
    "    return scores_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "     A4GALT      AAAS      AACS     AADAC      AAK1      AAMP     AANAT  \\\n0  3.490594  4.705177  7.388903  3.146066  5.324219  7.010299  3.204220   \n1  3.493298  6.025729  6.501462  3.015961  4.639765  7.399345  3.801613   \n2  3.426142  5.449551  5.632613  3.685224  5.643874  6.737401  3.596668   \n3  3.426381  5.595401  6.882855  3.240755  6.075660  6.943799  3.202970   \n4  3.479792  5.565861  4.662279  3.176784  6.033194  7.274996  3.204731   \n\n       AARS    AARSD1  AASDHPPT  ...    ZNHIT2       ZP2      ZPBP    ZSCAN2  \\\n0  7.623260  4.908548  7.920498  ...  3.616936  3.177763  3.120909  3.626377   \n1  8.326222  5.075999  6.635090  ...  4.002873  3.182145  3.414617  3.933382   \n2  7.431818  5.591313  6.596328  ...  2.695141  3.324802  3.251439  2.909459   \n3  7.477471  4.904070  6.518033  ...  3.384700  3.144302  3.158701  3.521218   \n4  7.105333  6.663767  6.667291  ...  3.414956  3.139913  3.185299  3.572568   \n\n       ZW10     ZWINT      ZXDC       ZYX     ZZEF1      ZZZ3  \n0  5.573573  7.840314  5.720305  7.491440  7.049239  6.979166  \n1  3.717363  9.053191  6.370379  7.888914  5.422555  5.951768  \n2  4.385828  6.415808  5.480143  7.644960  6.797248  6.808280  \n3  3.968905  6.774039  6.299851  7.620011  5.797529  5.871506  \n4  3.874406  6.490379  6.589065  6.327172  6.770991  6.890959  \n\n[5 rows x 8832 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A4GALT</th>\n      <th>AAAS</th>\n      <th>AACS</th>\n      <th>AADAC</th>\n      <th>AAK1</th>\n      <th>AAMP</th>\n      <th>AANAT</th>\n      <th>AARS</th>\n      <th>AARSD1</th>\n      <th>AASDHPPT</th>\n      <th>...</th>\n      <th>ZNHIT2</th>\n      <th>ZP2</th>\n      <th>ZPBP</th>\n      <th>ZSCAN2</th>\n      <th>ZW10</th>\n      <th>ZWINT</th>\n      <th>ZXDC</th>\n      <th>ZYX</th>\n      <th>ZZEF1</th>\n      <th>ZZZ3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.490594</td>\n      <td>4.705177</td>\n      <td>7.388903</td>\n      <td>3.146066</td>\n      <td>5.324219</td>\n      <td>7.010299</td>\n      <td>3.204220</td>\n      <td>7.623260</td>\n      <td>4.908548</td>\n      <td>7.920498</td>\n      <td>...</td>\n      <td>3.616936</td>\n      <td>3.177763</td>\n      <td>3.120909</td>\n      <td>3.626377</td>\n      <td>5.573573</td>\n      <td>7.840314</td>\n      <td>5.720305</td>\n      <td>7.491440</td>\n      <td>7.049239</td>\n      <td>6.979166</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.493298</td>\n      <td>6.025729</td>\n      <td>6.501462</td>\n      <td>3.015961</td>\n      <td>4.639765</td>\n      <td>7.399345</td>\n      <td>3.801613</td>\n      <td>8.326222</td>\n      <td>5.075999</td>\n      <td>6.635090</td>\n      <td>...</td>\n      <td>4.002873</td>\n      <td>3.182145</td>\n      <td>3.414617</td>\n      <td>3.933382</td>\n      <td>3.717363</td>\n      <td>9.053191</td>\n      <td>6.370379</td>\n      <td>7.888914</td>\n      <td>5.422555</td>\n      <td>5.951768</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.426142</td>\n      <td>5.449551</td>\n      <td>5.632613</td>\n      <td>3.685224</td>\n      <td>5.643874</td>\n      <td>6.737401</td>\n      <td>3.596668</td>\n      <td>7.431818</td>\n      <td>5.591313</td>\n      <td>6.596328</td>\n      <td>...</td>\n      <td>2.695141</td>\n      <td>3.324802</td>\n      <td>3.251439</td>\n      <td>2.909459</td>\n      <td>4.385828</td>\n      <td>6.415808</td>\n      <td>5.480143</td>\n      <td>7.644960</td>\n      <td>6.797248</td>\n      <td>6.808280</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.426381</td>\n      <td>5.595401</td>\n      <td>6.882855</td>\n      <td>3.240755</td>\n      <td>6.075660</td>\n      <td>6.943799</td>\n      <td>3.202970</td>\n      <td>7.477471</td>\n      <td>4.904070</td>\n      <td>6.518033</td>\n      <td>...</td>\n      <td>3.384700</td>\n      <td>3.144302</td>\n      <td>3.158701</td>\n      <td>3.521218</td>\n      <td>3.968905</td>\n      <td>6.774039</td>\n      <td>6.299851</td>\n      <td>7.620011</td>\n      <td>5.797529</td>\n      <td>5.871506</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.479792</td>\n      <td>5.565861</td>\n      <td>4.662279</td>\n      <td>3.176784</td>\n      <td>6.033194</td>\n      <td>7.274996</td>\n      <td>3.204731</td>\n      <td>7.105333</td>\n      <td>6.663767</td>\n      <td>6.667291</td>\n      <td>...</td>\n      <td>3.414956</td>\n      <td>3.139913</td>\n      <td>3.185299</td>\n      <td>3.572568</td>\n      <td>3.874406</td>\n      <td>6.490379</td>\n      <td>6.589065</td>\n      <td>6.327172</td>\n      <td>6.770991</td>\n      <td>6.890959</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 8832 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "X_train, y_train = train_df[train_df.columns.difference([\"patient_ID\", \"posOutcome\"])], train_df[\"posOutcome\"]\n",
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    PCOLCE2      SGCA    SFTPA2     INSL6      RHAG       OMP     NPY5R  \\\n0  3.148430  3.592749  3.903130  3.349360  2.492889  3.232596  3.372126   \n1  3.189867  3.187450  4.298787  3.315854  2.163489  3.093923  4.943535   \n2  4.722449  3.113225  3.547999  3.763481  3.277243  3.421224  2.487729   \n3  4.268493  3.594347  3.911735  3.350790  2.456152  3.233919  3.315442   \n4  2.877485  3.589070  3.878472  3.350356  2.478397  3.233986  3.395737   \n\n      STMN2    SCARF1    KIF13A  ...       MPO       PPY    UBQLN3    CYP7A1  \\\n0  3.698328  3.380497  3.232026  ...  3.191073  3.634918  3.452820  3.084802   \n1  4.298039  2.957697  4.002984  ...  3.304428  4.022183  2.987215  2.970891   \n2  2.386824  4.093911  3.254019  ...  3.904301  3.710354  3.444630  2.917371   \n3  3.589309  5.563479  3.702511  ...  3.198184  3.640382  3.453832  3.093994   \n4  3.352484  3.360377  3.169454  ...  3.216300  3.638380  3.454280  3.094129   \n\n      HOXB8   HSD11B2      RRAD       PAH         T      PON1  \n0  3.127523  3.343292  3.164438  2.840337  3.189698  3.108159  \n1  2.779550  2.572359  1.580958  2.691363  3.177675  3.213405  \n2  3.051644  3.241207  3.744355  2.109861  4.059390  2.632372  \n3  3.069023  3.238938  3.065845  2.738419  3.229419  3.149284  \n4  3.112289  3.308742  3.044857  2.764971  3.207398  3.088351  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PCOLCE2</th>\n      <th>SGCA</th>\n      <th>SFTPA2</th>\n      <th>INSL6</th>\n      <th>RHAG</th>\n      <th>OMP</th>\n      <th>NPY5R</th>\n      <th>STMN2</th>\n      <th>SCARF1</th>\n      <th>KIF13A</th>\n      <th>...</th>\n      <th>MPO</th>\n      <th>PPY</th>\n      <th>UBQLN3</th>\n      <th>CYP7A1</th>\n      <th>HOXB8</th>\n      <th>HSD11B2</th>\n      <th>RRAD</th>\n      <th>PAH</th>\n      <th>T</th>\n      <th>PON1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.148430</td>\n      <td>3.592749</td>\n      <td>3.903130</td>\n      <td>3.349360</td>\n      <td>2.492889</td>\n      <td>3.232596</td>\n      <td>3.372126</td>\n      <td>3.698328</td>\n      <td>3.380497</td>\n      <td>3.232026</td>\n      <td>...</td>\n      <td>3.191073</td>\n      <td>3.634918</td>\n      <td>3.452820</td>\n      <td>3.084802</td>\n      <td>3.127523</td>\n      <td>3.343292</td>\n      <td>3.164438</td>\n      <td>2.840337</td>\n      <td>3.189698</td>\n      <td>3.108159</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.189867</td>\n      <td>3.187450</td>\n      <td>4.298787</td>\n      <td>3.315854</td>\n      <td>2.163489</td>\n      <td>3.093923</td>\n      <td>4.943535</td>\n      <td>4.298039</td>\n      <td>2.957697</td>\n      <td>4.002984</td>\n      <td>...</td>\n      <td>3.304428</td>\n      <td>4.022183</td>\n      <td>2.987215</td>\n      <td>2.970891</td>\n      <td>2.779550</td>\n      <td>2.572359</td>\n      <td>1.580958</td>\n      <td>2.691363</td>\n      <td>3.177675</td>\n      <td>3.213405</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.722449</td>\n      <td>3.113225</td>\n      <td>3.547999</td>\n      <td>3.763481</td>\n      <td>3.277243</td>\n      <td>3.421224</td>\n      <td>2.487729</td>\n      <td>2.386824</td>\n      <td>4.093911</td>\n      <td>3.254019</td>\n      <td>...</td>\n      <td>3.904301</td>\n      <td>3.710354</td>\n      <td>3.444630</td>\n      <td>2.917371</td>\n      <td>3.051644</td>\n      <td>3.241207</td>\n      <td>3.744355</td>\n      <td>2.109861</td>\n      <td>4.059390</td>\n      <td>2.632372</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.268493</td>\n      <td>3.594347</td>\n      <td>3.911735</td>\n      <td>3.350790</td>\n      <td>2.456152</td>\n      <td>3.233919</td>\n      <td>3.315442</td>\n      <td>3.589309</td>\n      <td>5.563479</td>\n      <td>3.702511</td>\n      <td>...</td>\n      <td>3.198184</td>\n      <td>3.640382</td>\n      <td>3.453832</td>\n      <td>3.093994</td>\n      <td>3.069023</td>\n      <td>3.238938</td>\n      <td>3.065845</td>\n      <td>2.738419</td>\n      <td>3.229419</td>\n      <td>3.149284</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.877485</td>\n      <td>3.589070</td>\n      <td>3.878472</td>\n      <td>3.350356</td>\n      <td>2.478397</td>\n      <td>3.233986</td>\n      <td>3.395737</td>\n      <td>3.352484</td>\n      <td>3.360377</td>\n      <td>3.169454</td>\n      <td>...</td>\n      <td>3.216300</td>\n      <td>3.638380</td>\n      <td>3.454280</td>\n      <td>3.094129</td>\n      <td>3.112289</td>\n      <td>3.308742</td>\n      <td>3.044857</td>\n      <td>2.764971</td>\n      <td>3.207398</td>\n      <td>3.088351</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_moses50 = []\n",
    "\n",
    "with open(\"datasets/moses_ft50.txt\", \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        fts_moses50.append(line.strip())\n",
    "\n",
    "X_moses50 = X_train[fts_moses50]\n",
    "X_moses50.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[11:10:58] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:10:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 24.1 seconds.\n",
      "Best Score: 80.412%\n",
      "{'subsample': 0.8, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 5, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:   21.7s finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses50 = param_tuning(X_moses50, y_train, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "params_moses50 = {'subsample': 0.8,\n",
    " 'n_estimators': 600,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 5,\n",
    " 'colsample_bytree': 0.6}\n",
    "\n",
    "clf_moses50 = XGBClassifier(**params_moses50, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([1.11466408, 1.02984762, 1.42984104, 1.44669271, 1.33950138]),\n 'score_time': array([0.02916408, 0.03314805, 0.0126574 , 0.0124681 , 0.01332188]),\n 'test_balanced_accuracy': array([0.74215807, 0.75472973, 0.729095  , 0.76928747, 0.7246724 ]),\n 'test_recall_0': array([0.84242424, 0.8       , 0.77575758, 0.78181818, 0.79393939]),\n 'test_precision_0': array([0.72395833, 0.75428571, 0.73142857, 0.78181818, 0.71978022]),\n 'test_recall_1': array([0.64189189, 0.70945946, 0.68243243, 0.75675676, 0.65540541]),\n 'test_precision_1': array([0.78512397, 0.76086957, 0.73188406, 0.75675676, 0.74045802]),\n 'test_auc': array([0.80679771, 0.79178952, 0.81322686, 0.81355446, 0.79520885])}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_moses50 = cross_validate(clf_moses50, X_moses50, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_moses50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.743989\nrecall_0             0.742254\nprecision_0          0.798788\nrecall_1             0.755018\nprecision_1          0.689189\nauc                  0.804115\ndtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_moses50_df = get_scores(cv_results_moses50, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_moses50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "X_test, y_test = test_df[test_df.columns.difference([\"patient_ID\", \"posOutcome\"])], test_df[\"posOutcome\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6, gamma=5, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.01, max_delta_step=0, max_depth=6,\n              min_child_weight=3, missing=nan, monotone_constraints='()',\n              n_estimators=600, n_jobs=4, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_moses50.fit(X_moses50, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.749094\nrecall_0             0.749333\nprecision_0          0.793785\nrecall_1             0.754209\nprecision_1          0.704403\nauc                  0.799568\ndtype: float64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_moses50 = X_test[fts_moses50]\n",
    "\n",
    "test_scores_moses50 = calc_scores(clf_moses50, X_test_moses50, y_test)\n",
    "scores_test_50_df = pd.DataFrame(data=test_scores_moses50, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def discretize_dataset(X, features, bins_labels = None):\n",
    "    if bins_labels is None:\n",
    "\t    bins_labels = [-1, 0, 1]\n",
    "    X_disc = X[features]\n",
    "    bin_dict = {}\n",
    "\n",
    "    for ft in fts_moses50:\n",
    "        r1 = X_disc[ft].mean() - X_disc[ft].std() / 2\n",
    "        r2 = X_disc[ft].mean() + X_disc[ft].std() / 2\n",
    "        bin_dict[ft]= [-np.inf, r1, r2, np.inf]\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    le.fit(bins_labels)\n",
    "\n",
    "    for ft in bin_dict:\n",
    "        X_disc[ft] = le.transform(pd.cut(X_disc[ft], bins=bin_dict[ft], labels=bins_labels))\n",
    "        # X_disc[ft] = X_disc[ft].astype(dtype=np.int64)\n",
    "    return X_disc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   PCOLCE2  SGCA  SFTPA2  INSL6  RHAG  OMP  NPY5R  STMN2  SCARF1  KIF13A  ...  \\\n0        1     1       1      1     1    1      1      1       1       1  ...   \n1        1     0       1      1     0    0      2      2       0       2  ...   \n2        2     0       0      2     2    2      0      0       2       1  ...   \n3        1     1       1      1     1    1      1      1       2       2  ...   \n4        0     1       1      1     1    1      1      0       1       1  ...   \n\n   MPO  PPY  UBQLN3  CYP7A1  HOXB8  HSD11B2  RRAD  PAH  T  PON1  \n0    1    1       1       1      1        1     1    1  1     1  \n1    1    2       0       0      0        0     0    1  1     1  \n2    2    1       1       0      1        1     2    0  2     0  \n3    1    1       1       1      1        1     1    1  1     1  \n4    1    1       1       1      1        1     1    1  1     1  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PCOLCE2</th>\n      <th>SGCA</th>\n      <th>SFTPA2</th>\n      <th>INSL6</th>\n      <th>RHAG</th>\n      <th>OMP</th>\n      <th>NPY5R</th>\n      <th>STMN2</th>\n      <th>SCARF1</th>\n      <th>KIF13A</th>\n      <th>...</th>\n      <th>MPO</th>\n      <th>PPY</th>\n      <th>UBQLN3</th>\n      <th>CYP7A1</th>\n      <th>HOXB8</th>\n      <th>HSD11B2</th>\n      <th>RRAD</th>\n      <th>PAH</th>\n      <th>T</th>\n      <th>PON1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moses50_disc = discretize_dataset(X_moses50, fts_moses50)\n",
    "X_moses50_disc.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 2])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_moses50_disc = param_tuning(X_moses50_disc, y_train, jobs=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "    PCOLCE2      SGCA    SFTPA2     INSL6      RHAG       OMP     NPY5R  \\\n0  3.148430  3.592749  3.903130  3.349360  2.492889  3.232596  3.372126   \n1  3.189867  3.187450  4.298787  3.315854  2.163489  3.093923  4.943535   \n2  4.722449  3.113225  3.547999  3.763481  3.277243  3.421224  2.487729   \n3  4.268493  3.594347  3.911735  3.350790  2.456152  3.233919  3.315442   \n4  2.877485  3.589070  3.878472  3.350356  2.478397  3.233986  3.395737   \n\n      STMN2    SCARF1    KIF13A  ...       PGC    PRDM16     GRIA2     PDE6H  \\\n0  3.698328  3.380497  3.232026  ...  3.066523  2.981560  3.722755  3.066050   \n1  4.298039  2.957697  4.002984  ...  2.185713  2.600702  4.108615  2.671217   \n2  2.386824  4.093911  3.254019  ...  3.002238  2.867571  3.165894  2.852804   \n3  3.589309  5.563479  3.702511  ...  3.024053  2.976027  7.697695  3.066539   \n4  3.352484  3.360377  3.169454  ...  3.045817  2.981492  3.660311  3.066645   \n\n     SLC7A4      ZFP2     ZNF10       PRL    SLC5A4     GALR2  \n0  3.190915  3.331363  3.647163  3.258032  3.371849  3.437293  \n1  3.577205  3.113802  4.302391  4.042981  3.632030  3.644259  \n2  3.032430  3.334047  3.056203  3.079016  3.055022  3.336115  \n3  3.147233  3.280103  4.322220  3.196184  3.373126  3.439084  \n4  3.178023  3.224418  3.929318  3.263807  3.373217  3.439146  \n\n[5 rows x 83 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PCOLCE2</th>\n      <th>SGCA</th>\n      <th>SFTPA2</th>\n      <th>INSL6</th>\n      <th>RHAG</th>\n      <th>OMP</th>\n      <th>NPY5R</th>\n      <th>STMN2</th>\n      <th>SCARF1</th>\n      <th>KIF13A</th>\n      <th>...</th>\n      <th>PGC</th>\n      <th>PRDM16</th>\n      <th>GRIA2</th>\n      <th>PDE6H</th>\n      <th>SLC7A4</th>\n      <th>ZFP2</th>\n      <th>ZNF10</th>\n      <th>PRL</th>\n      <th>SLC5A4</th>\n      <th>GALR2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.148430</td>\n      <td>3.592749</td>\n      <td>3.903130</td>\n      <td>3.349360</td>\n      <td>2.492889</td>\n      <td>3.232596</td>\n      <td>3.372126</td>\n      <td>3.698328</td>\n      <td>3.380497</td>\n      <td>3.232026</td>\n      <td>...</td>\n      <td>3.066523</td>\n      <td>2.981560</td>\n      <td>3.722755</td>\n      <td>3.066050</td>\n      <td>3.190915</td>\n      <td>3.331363</td>\n      <td>3.647163</td>\n      <td>3.258032</td>\n      <td>3.371849</td>\n      <td>3.437293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.189867</td>\n      <td>3.187450</td>\n      <td>4.298787</td>\n      <td>3.315854</td>\n      <td>2.163489</td>\n      <td>3.093923</td>\n      <td>4.943535</td>\n      <td>4.298039</td>\n      <td>2.957697</td>\n      <td>4.002984</td>\n      <td>...</td>\n      <td>2.185713</td>\n      <td>2.600702</td>\n      <td>4.108615</td>\n      <td>2.671217</td>\n      <td>3.577205</td>\n      <td>3.113802</td>\n      <td>4.302391</td>\n      <td>4.042981</td>\n      <td>3.632030</td>\n      <td>3.644259</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.722449</td>\n      <td>3.113225</td>\n      <td>3.547999</td>\n      <td>3.763481</td>\n      <td>3.277243</td>\n      <td>3.421224</td>\n      <td>2.487729</td>\n      <td>2.386824</td>\n      <td>4.093911</td>\n      <td>3.254019</td>\n      <td>...</td>\n      <td>3.002238</td>\n      <td>2.867571</td>\n      <td>3.165894</td>\n      <td>2.852804</td>\n      <td>3.032430</td>\n      <td>3.334047</td>\n      <td>3.056203</td>\n      <td>3.079016</td>\n      <td>3.055022</td>\n      <td>3.336115</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.268493</td>\n      <td>3.594347</td>\n      <td>3.911735</td>\n      <td>3.350790</td>\n      <td>2.456152</td>\n      <td>3.233919</td>\n      <td>3.315442</td>\n      <td>3.589309</td>\n      <td>5.563479</td>\n      <td>3.702511</td>\n      <td>...</td>\n      <td>3.024053</td>\n      <td>2.976027</td>\n      <td>7.697695</td>\n      <td>3.066539</td>\n      <td>3.147233</td>\n      <td>3.280103</td>\n      <td>4.322220</td>\n      <td>3.196184</td>\n      <td>3.373126</td>\n      <td>3.439084</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.877485</td>\n      <td>3.589070</td>\n      <td>3.878472</td>\n      <td>3.350356</td>\n      <td>2.478397</td>\n      <td>3.233986</td>\n      <td>3.395737</td>\n      <td>3.352484</td>\n      <td>3.360377</td>\n      <td>3.169454</td>\n      <td>...</td>\n      <td>3.045817</td>\n      <td>2.981492</td>\n      <td>3.660311</td>\n      <td>3.066645</td>\n      <td>3.178023</td>\n      <td>3.224418</td>\n      <td>3.929318</td>\n      <td>3.263807</td>\n      <td>3.373217</td>\n      <td>3.439146</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 83 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_moses83 = []\n",
    "\n",
    "with open(\"datasets/moses_ft83.txt\", \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        fts_moses83.append(line.strip())\n",
    "\n",
    "X_moses83 = X_train[fts_moses83]\n",
    "X_moses83.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[12:14:59] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:14:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 35.99 seconds.\n",
      "Best Score: 74.718%\n",
      "{'subsample': 1.0, 'n_estimators': 400, 'min_child_weight': 4, 'max_depth': 6, 'learning_rate': 0.02, 'gamma': 5, 'colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=14)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=14)]: Done   4 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=14)]: Done 125 out of 125 | elapsed:   31.9s finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses83 = param_tuning(X_moses83, y_train, jobs=14, scoring=\"balanced_accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "params_moses83 = {'subsample': 1.0,\n",
    "                  'n_estimators': 400,\n",
    "                  'min_child_weight': 4,\n",
    "                  'max_depth': 6,\n",
    "                  'learning_rate': 0.02,\n",
    "                  'gamma': 5,\n",
    "                  'colsample_bytree': 1.0}\n",
    "\n",
    "clf_moses83 = XGBClassifier(**params_moses83, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fit_time': array([2.07262707, 1.96360373, 1.33789372, 1.35235715, 2.11978889]),\n 'score_time': array([0.01216316, 0.01650262, 0.01989007, 0.02052927, 0.01205277]),\n 'test_balanced_accuracy': array([0.74250614, 0.76287879, 0.75169943, 0.74330467, 0.73550369]),\n 'test_recall_0': array([0.83636364, 0.77575758, 0.79393939, 0.76363636, 0.78181818]),\n 'test_precision_0': array([0.72631579, 0.77575758, 0.75287356, 0.75449102, 0.73714286]),\n 'test_recall_1': array([0.64864865, 0.75      , 0.70945946, 0.72297297, 0.68918919]),\n 'test_precision_1': array([0.7804878 , 0.75      , 0.75539568, 0.73287671, 0.73913043]),\n 'test_auc': array([0.80937756, 0.8018018 , 0.81398444, 0.8031122 , 0.80126945])}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_moses83 = cross_validate(clf_moses83, X_moses83, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_moses83"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.747179\nrecall_0             0.749316\nprecision_0          0.790303\nrecall_1             0.751578\nprecision_1          0.704054\nauc                  0.805909\ndtype: float64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_moses83_df = get_scores(cv_results_moses83, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_moses83_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.726628\nrecall_0             0.728723\nprecision_0          0.774011\nrecall_1             0.729730\nprecision_1          0.679245\nauc                  0.795193\ndtype: float64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_moses83.fit(X_moses83, y_train)\n",
    "X_test_moses83 = X_test[fts_moses83]\n",
    "\n",
    "test_scores_moses83 = calc_scores(clf_moses83, X_test_moses83, y_test)\n",
    "scores_test_83_df = pd.DataFrame(data=test_scores_moses83, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "scores_test_83_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "clf_moses83.save_model(\"datasets/models/clf_moses83.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "        PPY       RGN     CDH20       CPZ     HESX1     TBL1Y      PRG2  \\\n0  3.634918  6.678143  3.418152  3.698522  3.572909  3.571194  6.950399   \n1  4.022183  4.527047  3.381002  3.925558  3.715131  3.460038  4.056473   \n2  3.710354  3.087923  3.083944  4.947658  5.083375  3.309398  2.735483   \n3  3.640382  3.325559  3.419500  6.530958  3.543959  3.571256  3.402627   \n4  3.638380  3.373206  3.419794  3.603261  6.968873  3.573625  3.428841   \n\n       CRY2     MFAP4     PVRL3  ...     WISP1     WISP3     WNT2B     ZBTB3  \\\n0  6.055297  4.347075  3.330911  ...  3.685007  3.302871  3.308621  3.552972   \n1  5.584762  5.629210  4.045242  ...  3.685147  3.697984  2.467508  4.411691   \n2  5.931768  6.306764  4.481756  ...  5.280646  3.242144  3.546346  4.125019   \n3  6.579714  7.918224  3.474763  ...  5.593913  3.347911  3.251575  3.527236   \n4  5.690064  2.977116  3.338315  ...  3.350563  3.359097  3.266639  3.571667   \n\n      ZFHX4    ZFYVE9     ZNF10    ZNF214    ZNF215     ZNF80  \n0  3.946286  3.761024  3.647163  3.125024  3.016956  3.547274  \n1  4.910276  4.296368  4.302391  3.821208  3.928156  4.072608  \n2  5.797823  3.807700  3.056203  3.409324  3.458087  3.878680  \n3  6.548565  2.997048  4.322220  3.075615  2.999787  3.466420  \n4  3.462968  3.849481  3.929318  3.135227  2.959384  3.549222  \n\n[5 rows x 500 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PPY</th>\n      <th>RGN</th>\n      <th>CDH20</th>\n      <th>CPZ</th>\n      <th>HESX1</th>\n      <th>TBL1Y</th>\n      <th>PRG2</th>\n      <th>CRY2</th>\n      <th>MFAP4</th>\n      <th>PVRL3</th>\n      <th>...</th>\n      <th>WISP1</th>\n      <th>WISP3</th>\n      <th>WNT2B</th>\n      <th>ZBTB3</th>\n      <th>ZFHX4</th>\n      <th>ZFYVE9</th>\n      <th>ZNF10</th>\n      <th>ZNF214</th>\n      <th>ZNF215</th>\n      <th>ZNF80</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.634918</td>\n      <td>6.678143</td>\n      <td>3.418152</td>\n      <td>3.698522</td>\n      <td>3.572909</td>\n      <td>3.571194</td>\n      <td>6.950399</td>\n      <td>6.055297</td>\n      <td>4.347075</td>\n      <td>3.330911</td>\n      <td>...</td>\n      <td>3.685007</td>\n      <td>3.302871</td>\n      <td>3.308621</td>\n      <td>3.552972</td>\n      <td>3.946286</td>\n      <td>3.761024</td>\n      <td>3.647163</td>\n      <td>3.125024</td>\n      <td>3.016956</td>\n      <td>3.547274</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.022183</td>\n      <td>4.527047</td>\n      <td>3.381002</td>\n      <td>3.925558</td>\n      <td>3.715131</td>\n      <td>3.460038</td>\n      <td>4.056473</td>\n      <td>5.584762</td>\n      <td>5.629210</td>\n      <td>4.045242</td>\n      <td>...</td>\n      <td>3.685147</td>\n      <td>3.697984</td>\n      <td>2.467508</td>\n      <td>4.411691</td>\n      <td>4.910276</td>\n      <td>4.296368</td>\n      <td>4.302391</td>\n      <td>3.821208</td>\n      <td>3.928156</td>\n      <td>4.072608</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.710354</td>\n      <td>3.087923</td>\n      <td>3.083944</td>\n      <td>4.947658</td>\n      <td>5.083375</td>\n      <td>3.309398</td>\n      <td>2.735483</td>\n      <td>5.931768</td>\n      <td>6.306764</td>\n      <td>4.481756</td>\n      <td>...</td>\n      <td>5.280646</td>\n      <td>3.242144</td>\n      <td>3.546346</td>\n      <td>4.125019</td>\n      <td>5.797823</td>\n      <td>3.807700</td>\n      <td>3.056203</td>\n      <td>3.409324</td>\n      <td>3.458087</td>\n      <td>3.878680</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.640382</td>\n      <td>3.325559</td>\n      <td>3.419500</td>\n      <td>6.530958</td>\n      <td>3.543959</td>\n      <td>3.571256</td>\n      <td>3.402627</td>\n      <td>6.579714</td>\n      <td>7.918224</td>\n      <td>3.474763</td>\n      <td>...</td>\n      <td>5.593913</td>\n      <td>3.347911</td>\n      <td>3.251575</td>\n      <td>3.527236</td>\n      <td>6.548565</td>\n      <td>2.997048</td>\n      <td>4.322220</td>\n      <td>3.075615</td>\n      <td>2.999787</td>\n      <td>3.466420</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.638380</td>\n      <td>3.373206</td>\n      <td>3.419794</td>\n      <td>3.603261</td>\n      <td>6.968873</td>\n      <td>3.573625</td>\n      <td>3.428841</td>\n      <td>5.690064</td>\n      <td>2.977116</td>\n      <td>3.338315</td>\n      <td>...</td>\n      <td>3.350563</td>\n      <td>3.359097</td>\n      <td>3.266639</td>\n      <td>3.571667</td>\n      <td>3.462968</td>\n      <td>3.849481</td>\n      <td>3.929318</td>\n      <td>3.135227</td>\n      <td>2.959384</td>\n      <td>3.549222</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 500 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_moses500 = []\n",
    "\n",
    "with open(\"datasets/moses_ft500_bmc.txt\", \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        fts_moses500.append(line.strip())\n",
    "\n",
    "X_moses500 = X_train[fts_moses500]\n",
    "X_moses500.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[13:46:59] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:46:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 3 minutes and 27.02 seconds.\n",
      "Best Score: 82.742%\n",
      "{'subsample': 0.6, 'n_estimators': 400, 'min_child_weight': 2, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 1, 'colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=12)]: Done 125 out of 125 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses500 = param_tuning(X_moses500, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "params_moses500 = {'subsample': 0.6,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 2,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.05,\n",
    " 'gamma': 1,\n",
    " 'colsample_bytree': 1.0}\n",
    "\n",
    "clf_moses500 = XGBClassifier(**params_moses500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.767310\nrecall_0             0.774468\nprecision_0          0.792727\nrecall_1             0.763548\nprecision_1          0.741892\nauc                  0.827420\ndtype: float64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_moses500 = cross_validate(clf_moses500, X_moses500, y_train,\n",
    "                               scoring=scoring, cv=st_cv, n_jobs=-1)\n",
    "cv_results_moses500 = get_scores(cv_results_moses500, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "cv_results_moses500.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.761992\nrecall_0             0.768595\nprecision_0          0.788136\nrecall_1             0.757282\nprecision_1          0.735849\nauc                  0.820861\ndtype: float64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_moses500.fit(X_moses500, y_train)\n",
    "X_test_moses500 = X_test[fts_moses500]\n",
    "\n",
    "test_scores_moses500 = calc_scores(clf_moses500, X_test_moses500, y_test)\n",
    "test_scores_moses500_df = pd.DataFrame(data=test_scores_moses500, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "test_scores_moses500_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "clf_moses500.save_model(\"datasets/models/clf_moses500.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}