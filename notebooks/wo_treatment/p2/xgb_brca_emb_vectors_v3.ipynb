{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, recall_score, balanced_accuracy_score, precision_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300, 400, 500, 600, 700],\n",
    "              'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n",
    "\n",
    "seed = 42\n",
    "st_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "def calc_scores(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    recall_0, recall_1 = recall_score(y_test, y_pred, pos_label=0), recall_score(y_test, y_pred, pos_label=1)\n",
    "    precision_0, precision_1 =  precision_score(y_test, y_pred, pos_label=0), precision_score(y_test, y_pred, pos_label=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    arr = np.array([[acc, precision_0, recall_0, precision_1, recall_1,auc_score]])\n",
    "    return pd.DataFrame(data=arr, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "\n",
    "def recall_0(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "def precision_0(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "scoring = {\"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "           \"recall_0\": make_scorer(recall_0), \"precision_0\": make_scorer(precision_0),\n",
    "           \"recall_1\": make_scorer(recall_score), \"precision_1\": make_scorer(precision_score), \"auc\": \"roc_auc\" }\n",
    "\n",
    "#cross_validation\n",
    "\n",
    "def print_score_comparison(raw_score, emb_score, target_feature=\"posOutcome\",\n",
    "                           header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"balanced_accuracy\"].mean(), emb_score[\"balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_0\"].mean(), emb_score[\"precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_0\"].mean(), emb_score[\"recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_1\"].mean(), emb_score[\"precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_1\"].mean(), emb_score[\"recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"auc\"].mean(), emb_score[\"auc\"].mean()))\n",
    "\n",
    "def print_score_comparison_cv(raw_score, emb_score, target_feature=\"posOutcome\",header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_balanced_accuracy\"].mean(), emb_score[\"test_balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_precision_0\"].mean(), emb_score[\"test_precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_recall_0\"].mean(), emb_score[\"test_recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_precision_1\"].mean(), emb_score[\"test_precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_recall_1\"].mean(), emb_score[\"test_recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_auc\"].mean(), emb_score[\"test_auc\"].mean()))\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def param_tuning(X, y, n_folds=5, param_comb=25, scoring='roc_auc', jobs=12):\n",
    "    xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    rand_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring=scoring, n_jobs=jobs,\n",
    "                                   cv=skf.split(X, y), verbose=3, random_state=42)\n",
    "\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    rand_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    print(\"Best Score: {:.3%}\".format(rand_search.best_score_))\n",
    "    print(rand_search.best_params_)\n",
    "    return rand_search\n",
    "\n",
    "score_cols = [\"test_balanced_accuracy\",\"test_precision_0\", \"test_recall_0\",\n",
    "               \"test_precision_1\",\"test_recall_1\", \"test_auc\"]\n",
    "\n",
    "def get_scores(cv_results, score_keys=None, df_cols=None):\n",
    "    if score_keys is None:\n",
    "        score_keys = score_cols\n",
    "    if df_cols is None:\n",
    "        df_cols = score_cols\n",
    "    scores = np.empty([1, len(score_keys)])\n",
    "    for i, s in enumerate(score_keys):\n",
    "        scores[0][i] = np.mean(cv_results[s])\n",
    "    scores_df = pd.DataFrame(data=scores, columns=df_cols)\n",
    "    return scores_df\n",
    "\n",
    "def evaluate_embedding(path, train_df, test_df, target=\"posOutcome\", params=None\n",
    "                       ,n_jobs=-1):\n",
    "    emb_df = pd.read_csv(path, sep=\"\\t\", index_col=\"patient_ID\")\n",
    "    X_train_emb, y_train_emb  = emb_df.loc[train_df.index,:], train_df.loc[:,target]\n",
    "    X_test_emb, y_test_emb = emb_df.loc[test_df.index,:], test_df.loc[:,target]\n",
    "    if params is None:\n",
    "        rand_search_emb = param_tuning(X_train_emb, y_train_emb, jobs=n_jobs)\n",
    "        clf_params = rand_search_emb.best_params_\n",
    "    else:\n",
    "        clf_params = params\n",
    "    clf_emb = XGBClassifier(**clf_params)\n",
    "    cv_res = cross_validate(clf_emb, X_train_emb, y_train_emb, scoring=scoring, n_jobs=n_jobs, verbose=1, return_train_score=True, cv=st_cv)\n",
    "    cv_res_df = get_scores(cv_res)\n",
    "    clf_emb.fit(X_train_emb, y_train_emb)\n",
    "    test_scores_df = calc_scores(clf_emb, X_test_emb, y_test_emb)\n",
    "    if params is None:\n",
    "        return params, clf_emb, cv_res_df, test_scores_df\n",
    "    else:\n",
    "        return clf_emb, cv_res_df, test_scores_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "pos_outcome_df = pd.read_csv(\"datasets/combat15outcomes_latest.csv\", index_col=\"patient_ID\")\n",
    "pos_outcome_df = pos_outcome_df.dropna(axis=0, subset=[\"posOutcome\"])\n",
    "pos_outcome_df = pos_outcome_df[\"posOutcome\"]\n",
    "train_df = pd.read_csv(\"datasets/train.csv\", index_col=\"patient_ID\")\n",
    "test_df = pd.read_csv(\"datasets/test.csv\", index_col=\"patient_ID\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "params_moses_500 = {'subsample': 1.0,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 1,\n",
    " 'colsample_bytree': 0.6}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:11:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "clf_moses500, cv_scores_moses500, test_scores_moses500 = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_moses500_wopln_2021-01-28.csv\", train_df, test_df,\n",
    "    params=params_moses_500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.752695\ntest_precision_0          0.767297\ntest_recall_0             0.764848\ntest_precision_1          0.739075\ntest_recall_1             0.740541\ntest_auc                  0.816806\ndtype: float64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_moses500.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.764844\nrecall_0             0.783237\nprecision_0          0.765537\nrecall_1             0.745399\nprecision_1          0.764151\nauc                  0.821510\ndtype: float64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_moses500.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "mrmr50_params = {'subsample': 0.8,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 1.5,\n",
    " 'colsample_bytree': 0.8}\n",
    "\n",
    "clf_mrmr50, cv_scores_mrmr50_df, test_scores_mrmr50_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_mrmr_ft50_2021-01-29.csv\", train_df, test_df, params=mrmr50_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: \n",
      "test_balanced_accuracy    0.741585\n",
      "test_precision_0          0.745276\n",
      "test_recall_0             0.781818\n",
      "test_precision_1          0.742950\n",
      "test_recall_1             0.701351\n",
      "test_auc                  0.795192\n",
      "dtype: float64\n",
      "\n",
      "Test Score:\n",
      "balanced_accuracy    0.725696\n",
      "recall_0             0.731707\n",
      "precision_0          0.762712\n",
      "recall_1             0.722772\n",
      "precision_1          0.688679\n",
      "auc                  0.777396\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Score: \\n{0}\\n\".format(cv_scores_mrmr50_df.mean()))\n",
    "print(\"Test Score:\\n{0}\\n\".format(test_scores_mrmr50_df.mean()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[18:40:28] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:40:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 26 minutes and 32.78 seconds.\n",
      "Best Score: 80.599%\n",
      "{'subsample': 1.0, 'n_estimators': 600, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.02, 'gamma': 2, 'colsample_bytree': 0.6}\n",
      "[18:47:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 23.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-30-8687158faf16>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmrmr50_cl_params\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv_mrmr50_cl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_scores_mrmr50_cl_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_mrmr_ft50_wopln_2021-01-29.csv\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmrmr50_cl_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "mrmr50_cl_params, clf_mrmr50_cl, cv_mrmr50_cl, test_scores_mrmr50_cl_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_mrmr_ft50_wopln_2021-01-29.csv\", train_df, test_df)\n",
    "print(mrmr50_cl_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_mrmr50_cl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-1b17bba57d29>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"CV Score: \\n{0}\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcv_mrmr50_cl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Test Score:\\n{0}\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_scores_mrmr50_cl_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cv_mrmr50_cl' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"CV Score: \\n{0}\\n\".format(cv_mrmr50_cl.mean()))\n",
    "print(\"Test Score:\\n{0}\\n\".format(test_scores_mrmr50_cl_df.mean()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_score_comparison(test_scores_mrmr50_df, test_scores_mrmr50_cl_df,\n",
    "                       header_1=\"MRMR 50 Emb w/o CL\",\n",
    "                       header_2=\"MRMR 50 Emb w CL\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[19:25:43] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:25:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 26 minutes and 18.88 seconds.\n",
      "Best Score: 79.109%\n",
      "{'subsample': 0.8, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 5, 'colsample_bytree': 0.6}\n",
      "[19:32:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 23.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.6min finished\n"
     ]
    }
   ],
   "source": [
    "mrmr50_pln_params, clf_mrmr50_pln, cv_mrmr50_pln_df, test_scores_mrmr50_pln_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata_allgo-pw/property_vector_mrmr_ft50_all_2021-02-05.csv\", train_df, test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: \n",
      "test_balanced_accuracy    0.739816\n",
      "test_precision_0          0.740782\n",
      "test_recall_0             0.789091\n",
      "test_precision_1          0.745805\n",
      "test_recall_1             0.690541\n",
      "test_auc                  0.791089\n",
      "dtype: float64\n",
      "\n",
      "Test Score:\n",
      "balanced_accuracy    0.727561\n",
      "recall_0             0.725849\n",
      "precision_0          0.785311\n",
      "recall_1             0.737024\n",
      "precision_1          0.669811\n",
      "auc                  0.782619\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Score: \\n{0}\\n\".format(cv_mrmr50_pln_df.mean()))\n",
    "print(\"Test Score:\\n{0}\\n\".format(test_scores_mrmr50_pln_df.mean()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50 Emb w/o CL\t\tMRMR 50 Emb w All\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t72.570%\t\t\t72.756%\n",
      "\n",
      "precision_0:\t\t76.271%\t\t\t78.531%\n",
      "\n",
      "recall_0:\t\t73.171%\t\t\t72.585%\n",
      "\n",
      "precision_1:\t\t68.868%\t\t\t66.981%\n",
      "\n",
      "recall_1:\t\t72.277%\t\t\t73.702%\n",
      "\n",
      "auc:\t\t\t77.740%\t\t\t78.262%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_mrmr50_df, test_scores_mrmr50_pln_df,\n",
    "                       header_1=\"MRMR 50 Emb w/o CL\",\n",
    "                       header_2=\"MRMR 50 Emb w All\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[15:14:09] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:14:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 26 minutes and 42.03 seconds.\n",
      "Best Score: 77.957%\n",
      "{'subsample': 0.6, 'n_estimators': 300, 'min_child_weight': 4, 'max_depth': 4, 'learning_rate': 0.02, 'gamma': 5, 'colsample_bytree': 0.6}\n",
      "[15:16:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 25.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-394eabe5a77b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m                   \u001B[0;34m'gamma'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m                   'colsample_bytree': 0.6}\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mclf_moses83\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv_moses83\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_scores_moses83\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"datasets/embedding-vectors/genexpr_only/property_vector_moses_ft83_2021-01-30.csv\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "moses83_params = {'subsample': 0.8,\n",
    "                  'n_estimators': 300,\n",
    "                  'min_child_weight': 5,\n",
    "                  'max_depth': 5,\n",
    "                  'learning_rate': 0.03,\n",
    "                  'gamma': 2,\n",
    "                  'colsample_bytree': 0.6}\n",
    "clf_moses83, cv_moses83, test_scores_moses83 = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_moses_ft83_2021-01-30.csv\", train_df, test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_moses83' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-3799c3e0c04c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcv_moses83\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cv_moses83' is not defined"
     ]
    }
   ],
   "source": [
    "cv_moses83.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.716880\nrecall_0             0.694737\nprecision_0          0.781065\nrecall_1             0.746575\nprecision_1          0.652695\nauc                  0.766609\ndtype: float64"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_moses83.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50\t\tMOSES 83\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t71.847%\t\t\t71.688%\n",
      "\n",
      "precision_0:\t\t76.627%\t\t\t78.107%\n",
      "\n",
      "recall_0:\t\t70.190%\t\t\t69.474%\n",
      "\n",
      "precision_1:\t\t67.066%\t\t\t65.269%\n",
      "\n",
      "recall_1:\t\t73.927%\t\t\t74.658%\n",
      "\n",
      "auc:\t\t\t79.223%\t\t\t76.661%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test score comparison\n",
    "print_score_comparison(test_scores_mrmr50_df, test_scores_moses83,\n",
    "                       header_1=\"MRMR 50\", header_2=\"MOSES 83\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "moses83_cl_params, cv_moses83_cl, test_scores_moses83_cl_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_moses_ft83-wopln_2021-01-30.csv\", pos_outcome_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.732873\ntest_precision_0          0.732185\ntest_recall_0             0.809721\ntest_precision_1          0.749274\ntest_recall_1             0.656025\ntest_auc                  0.809083\ndtype: float64"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_moses83_cl.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.733152\nrecall_0             0.703325\nprecision_0          0.813609\nrecall_1             0.775801\nprecision_1          0.652695\nauc                  0.815124\ndtype: float64"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_moses83_cl_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMOSES 83 w/o CL\t\tMOSES 83 w CL\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t71.688%\t\t\t73.315%\n",
      "\n",
      "precision_0:\t\t78.107%\t\t\t81.361%\n",
      "\n",
      "recall_0:\t\t69.474%\t\t\t70.332%\n",
      "\n",
      "precision_1:\t\t65.269%\t\t\t65.269%\n",
      "\n",
      "recall_1:\t\t74.658%\t\t\t77.580%\n",
      "\n",
      "auc:\t\t\t76.661%\t\t\t81.512%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_moses83, test_scores_moses83_cl_df,\n",
    "                       header_1=\"MOSES 83 w/o CL\",\n",
    "                       header_2=\"MOSES 83 w CL\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[13:56:13] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:56:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 25 minutes and 33.28 seconds.\n",
      "Best Score: 79.597%\n",
      "{'subsample': 1.0, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.6}\n",
      "[13:59:32] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:59:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 23.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "mrmr100_params, cv_mrmr100, test_scores_mrmr100_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_mrmr_ft100_2021-01-29.csv\", pos_outcome_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.721821\ntest_precision_0          0.736879\ntest_recall_0             0.758594\ntest_precision_1          0.710231\ntest_recall_1             0.685048\ntest_auc                  0.795970\ndtype: float64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mrmr100.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.736376\nrecall_0             0.721763\nprecision_0          0.775148\nrecall_1             0.754045\nprecision_1          0.697605\nauc                  0.799344\ndtype: float64"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr100_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "mrmr100_cl_params, cv_mrmr100_cl, test_scores_mrmr100_cl_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_mrmr_ft100_wopln_2021-01-29.csv\", pos_outcome_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.714536\ntest_precision_0          0.721492\ntest_recall_0             0.779973\ntest_precision_1          0.719288\ntest_recall_1             0.649100\ntest_auc                  0.799172\ndtype: float64"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mrmr100_cl.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.725826\nrecall_0             0.703704\nprecision_0          0.786982\nrecall_1             0.755102\nprecision_1          0.664671\nauc                  0.806984\ndtype: float64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr100_cl_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 100 Emb w/o CL\t\tMRMR 100 Emb w CL\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t73.638%\t\t\t72.583%\n",
      "\n",
      "precision_0:\t\t77.515%\t\t\t78.698%\n",
      "\n",
      "recall_0:\t\t72.176%\t\t\t70.370%\n",
      "\n",
      "precision_1:\t\t69.760%\t\t\t66.467%\n",
      "\n",
      "recall_1:\t\t75.405%\t\t\t75.510%\n",
      "\n",
      "auc:\t\t\t79.934%\t\t\t80.698%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_mrmr100_df, test_scores_mrmr100_cl_df,\n",
    "                       header_1=\"MRMR 100 Emb w/o CL\",\n",
    "                       header_2=\"MRMR 100 Emb w CL\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[12:31:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:31:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 26 minutes and 35.45 seconds.\n",
      "Best Score: 79.358%\n",
      "{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 2, 'colsample_bytree': 0.6}\n",
      "[12:33:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:33:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 25.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   52.7s finished\n"
     ]
    }
   ],
   "source": [
    "params_mrmr50_nn, clf_mrmr50_nn, cv_scores_mrmr50_nn_df, test_scores_mrmr50_nn_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_mrmr_ft50_notnormalized_2021-02-04.csv\", pos_outcome_df, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.748330\n1    0.754550\n2    0.797809\n3    0.750667\n4    0.698851\n5    0.793583\ndtype: float64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_mrmr50_nn_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.728803\nrecall_0             0.706349\nprecision_0          0.789941\nrecall_1             0.758503\nprecision_1          0.667665\nauc                  0.779958\ndtype: float64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr50_nn_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50 Norm\t\tMRMR 50 Not Norm\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t74.566%\t\t\t74.833%\n",
      "\n",
      "precision_0:\t\t74.920%\t\t\t75.455%\n",
      "\n",
      "recall_0:\t\t80.493%\t\t\t79.781%\n",
      "\n",
      "precision_1:\t\t75.367%\t\t\t75.067%\n",
      "\n",
      "recall_1:\t\t68.639%\t\t\t69.885%\n",
      "\n",
      "auc:\t\t\t79.792%\t\t\t79.358%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison_cv(cv_scores_mrmr50_df, cv_scores_mrmr50_nn_df, header_1=\"MRMR 50 Norm\", header_2=\"MRMR 50 Not Norm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50 Norm\t\tMRMR 50 Not Norm\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t71.847%\t\t\t72.880%\n",
      "\n",
      "precision_0:\t\t76.627%\t\t\t78.994%\n",
      "\n",
      "recall_0:\t\t70.190%\t\t\t70.635%\n",
      "\n",
      "precision_1:\t\t67.066%\t\t\t66.766%\n",
      "\n",
      "recall_1:\t\t73.927%\t\t\t75.850%\n",
      "\n",
      "auc:\t\t\t79.223%\t\t\t77.996%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_mrmr50_df, test_scores_mrmr50_nn_df, header_1=\"MRMR 50 Norm\", header_2=\"MRMR 50 Not Norm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_scores_moses83' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-3f51a984aac8>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_scores_moses83\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'test_scores_moses83' is not defined"
     ]
    }
   ],
   "source": [
    "test_scores_moses83.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}