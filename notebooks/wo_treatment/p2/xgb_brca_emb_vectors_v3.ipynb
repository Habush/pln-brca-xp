{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, recall_score, balanced_accuracy_score, precision_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300, 400, 500, 600, 700],\n",
    "              'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n",
    "\n",
    "seed = 42\n",
    "st_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "def calc_scores(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    recall_0, recall_1 = recall_score(y_test, y_pred, pos_label=0), recall_score(y_test, y_pred, pos_label=1)\n",
    "    precision_0, precision_1 =  precision_score(y_test, y_pred, pos_label=0), precision_score(y_test, y_pred, pos_label=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    arr = np.array([[acc, precision_0, recall_0, precision_1, recall_1,auc_score]])\n",
    "    return pd.DataFrame(data=arr, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "\n",
    "def recall_0(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "def precision_0(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "scoring = {\"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "           \"recall_0\": make_scorer(recall_0), \"precision_0\": make_scorer(precision_0),\n",
    "           \"recall_1\": make_scorer(recall_score), \"precision_1\": make_scorer(precision_score), \"auc\": \"roc_auc\" }\n",
    "\n",
    "#cross_validation\n",
    "\n",
    "def print_score_comparison(raw_score, emb_score, target_feature=\"posOutcome\",\n",
    "                           header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"balanced_accuracy\"].mean(), emb_score[\"balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_0\"].mean(), emb_score[\"precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_0\"].mean(), emb_score[\"recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_1\"].mean(), emb_score[\"precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_1\"].mean(), emb_score[\"recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"auc\"].mean(), emb_score[\"auc\"].mean()))\n",
    "\n",
    "def print_score_comparison_cv(raw_score, emb_score, target_feature=\"posOutcome\",header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_balanced_accuracy\"].mean(), emb_score[\"test_balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_precision_0\"].mean(), emb_score[\"test_precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_recall_0\"].mean(), emb_score[\"test_recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_precision_1\"].mean(), emb_score[\"test_precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_recall_1\"].mean(), emb_score[\"test_recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"test_auc\"].mean(), emb_score[\"test_auc\"].mean()))\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def param_tuning(X, y, n_folds=5, param_comb=25, scoring='roc_auc', jobs=12):\n",
    "    xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    rand_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring=scoring, n_jobs=jobs,\n",
    "                                   cv=skf.split(X, y), verbose=3, random_state=42)\n",
    "\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    rand_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    print(\"Best Score: {:.3%}\".format(rand_search.best_score_))\n",
    "    print(rand_search.best_params_)\n",
    "    return rand_search\n",
    "\n",
    "score_cols = [\"test_balanced_accuracy\",\"test_precision_0\", \"test_recall_0\",\n",
    "               \"test_precision_1\",\"test_recall_1\", \"test_auc\"]\n",
    "\n",
    "def get_scores(cv_results, score_keys=None, df_cols=None):\n",
    "    if score_keys is None:\n",
    "        score_keys = score_cols\n",
    "    if df_cols is None:\n",
    "        df_cols = score_cols\n",
    "    scores = np.empty([1, len(score_keys)])\n",
    "    for i, s in enumerate(score_keys):\n",
    "        scores[0][i] = np.mean(cv_results[s])\n",
    "    scores_df = pd.DataFrame(data=scores, columns=df_cols)\n",
    "    return scores_df\n",
    "\n",
    "def evaluate_embedding(path, outcome_df, target=\"posOutcome\", merge_col=\"patient_ID\", params=None\n",
    "                       ,n_jobs=-1):\n",
    "    emb_df = pd.read_csv(path, sep=\"\\t\")\n",
    "    emb_outcome_df = pd.merge(outcome_df, emb_df, on=merge_col)\n",
    "    X_emb, y_emb = emb_outcome_df[emb_outcome_df.columns.difference([merge_col, target])], emb_outcome_df[target]\n",
    "    X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(X_emb, y_emb, test_size=0.3, random_state=seed)\n",
    "    if params is None:\n",
    "        rand_search_emb = param_tuning(X_train_emb, y_train_emb, jobs=n_jobs)\n",
    "        params = rand_search_emb.best_params_\n",
    "        clf_emb = rand_search_emb.best_estimator_\n",
    "    else:\n",
    "        clf_emb = XGBClassifier(**params)\n",
    "    cv_res = cross_validate(clf_emb, X_train_emb, y_train_emb, scoring=scoring, n_jobs=n_jobs, verbose=1, return_train_score=True,\n",
    "                            cv=st_cv)\n",
    "    cv_res_df = get_scores(cv_res)\n",
    "    clf_emb.fit(X_train_emb, y_train_emb)\n",
    "    test_scores_df = calc_scores(clf_emb, X_test_emb, y_test_emb)\n",
    "\n",
    "    return params, clf_emb, cv_res_df, test_scores_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1        10       100      1000      1001      1002  \\\n1803 -0.141096  0.025587 -0.052658 -0.003273  0.023713 -0.000369 -0.017225   \n2021  0.521562 -0.068304 -0.062999  0.014450  0.019302  0.030928 -0.028432   \n1949  0.444903 -0.047255 -0.009275  0.002878 -0.011309 -0.003531 -0.015948   \n1591 -0.144351 -0.115069  0.142886 -0.050261 -0.003571  0.009988 -0.003947   \n1746 -0.190454  0.018854  0.007170 -0.040255 -0.030323 -0.001451  0.006090   \n\n          1003      1004      1005  ...       990       991       992  \\\n1803  0.010393  0.010978 -0.002139  ... -0.013333  0.001245 -0.007404   \n2021  0.016746  0.011054  0.003320  ... -0.004796 -0.000094  0.021299   \n1949 -0.013611 -0.012096  0.001568  ... -0.002538  0.024432 -0.000844   \n1591  0.004796  0.001001  0.020687  ... -0.002948  0.005899 -0.000290   \n1746  0.008806  0.001865  0.007181  ...  0.003491  0.025046  0.012089   \n\n           993       994       995       996       997       998       999  \n1803  0.005843 -0.000109 -0.006222 -0.027249  0.004551  0.006404 -0.022996  \n2021 -0.000849  0.021312  0.011025 -0.002000 -0.000835  0.003087  0.009384  \n1949  0.005191 -0.006366  0.017310  0.001961  0.006773  0.006698  0.016200  \n1591  0.008037  0.011734 -0.007610  0.007086 -0.003716 -0.005912  0.001909  \n1746 -0.030416 -0.001304 -0.001814  0.012315  0.010432  0.003401  0.009570  \n\n[5 rows x 2236 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>10</th>\n      <th>100</th>\n      <th>1000</th>\n      <th>1001</th>\n      <th>1002</th>\n      <th>1003</th>\n      <th>1004</th>\n      <th>1005</th>\n      <th>...</th>\n      <th>990</th>\n      <th>991</th>\n      <th>992</th>\n      <th>993</th>\n      <th>994</th>\n      <th>995</th>\n      <th>996</th>\n      <th>997</th>\n      <th>998</th>\n      <th>999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1803</th>\n      <td>-0.141096</td>\n      <td>0.025587</td>\n      <td>-0.052658</td>\n      <td>-0.003273</td>\n      <td>0.023713</td>\n      <td>-0.000369</td>\n      <td>-0.017225</td>\n      <td>0.010393</td>\n      <td>0.010978</td>\n      <td>-0.002139</td>\n      <td>...</td>\n      <td>-0.013333</td>\n      <td>0.001245</td>\n      <td>-0.007404</td>\n      <td>0.005843</td>\n      <td>-0.000109</td>\n      <td>-0.006222</td>\n      <td>-0.027249</td>\n      <td>0.004551</td>\n      <td>0.006404</td>\n      <td>-0.022996</td>\n    </tr>\n    <tr>\n      <th>2021</th>\n      <td>0.521562</td>\n      <td>-0.068304</td>\n      <td>-0.062999</td>\n      <td>0.014450</td>\n      <td>0.019302</td>\n      <td>0.030928</td>\n      <td>-0.028432</td>\n      <td>0.016746</td>\n      <td>0.011054</td>\n      <td>0.003320</td>\n      <td>...</td>\n      <td>-0.004796</td>\n      <td>-0.000094</td>\n      <td>0.021299</td>\n      <td>-0.000849</td>\n      <td>0.021312</td>\n      <td>0.011025</td>\n      <td>-0.002000</td>\n      <td>-0.000835</td>\n      <td>0.003087</td>\n      <td>0.009384</td>\n    </tr>\n    <tr>\n      <th>1949</th>\n      <td>0.444903</td>\n      <td>-0.047255</td>\n      <td>-0.009275</td>\n      <td>0.002878</td>\n      <td>-0.011309</td>\n      <td>-0.003531</td>\n      <td>-0.015948</td>\n      <td>-0.013611</td>\n      <td>-0.012096</td>\n      <td>0.001568</td>\n      <td>...</td>\n      <td>-0.002538</td>\n      <td>0.024432</td>\n      <td>-0.000844</td>\n      <td>0.005191</td>\n      <td>-0.006366</td>\n      <td>0.017310</td>\n      <td>0.001961</td>\n      <td>0.006773</td>\n      <td>0.006698</td>\n      <td>0.016200</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>-0.144351</td>\n      <td>-0.115069</td>\n      <td>0.142886</td>\n      <td>-0.050261</td>\n      <td>-0.003571</td>\n      <td>0.009988</td>\n      <td>-0.003947</td>\n      <td>0.004796</td>\n      <td>0.001001</td>\n      <td>0.020687</td>\n      <td>...</td>\n      <td>-0.002948</td>\n      <td>0.005899</td>\n      <td>-0.000290</td>\n      <td>0.008037</td>\n      <td>0.011734</td>\n      <td>-0.007610</td>\n      <td>0.007086</td>\n      <td>-0.003716</td>\n      <td>-0.005912</td>\n      <td>0.001909</td>\n    </tr>\n    <tr>\n      <th>1746</th>\n      <td>-0.190454</td>\n      <td>0.018854</td>\n      <td>0.007170</td>\n      <td>-0.040255</td>\n      <td>-0.030323</td>\n      <td>-0.001451</td>\n      <td>0.006090</td>\n      <td>0.008806</td>\n      <td>0.001865</td>\n      <td>0.007181</td>\n      <td>...</td>\n      <td>0.003491</td>\n      <td>0.025046</td>\n      <td>0.012089</td>\n      <td>-0.030416</td>\n      <td>-0.001304</td>\n      <td>-0.001814</td>\n      <td>0.012315</td>\n      <td>0.010432</td>\n      <td>0.003401</td>\n      <td>0.009570</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2236 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_outcome_df = pd.read_csv(\"datasets/combat15outcomes_latest.csv\")\n",
    "pos_outcome_df = pos_outcome_df[[\"patient_ID\", \"posOutcome\"]].dropna(axis=0, subset=[\"posOutcome\"])\n",
    "moses500_emb_df = pd.read_csv(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_moses500_wopln_2021-01-28.csv\", sep=\"\\t\")\n",
    "moses500_emb_df = moses500_emb_df.loc[:,~moses500_emb_df.columns.str.contains(\"^Unnamed\")]\n",
    "moses500_emb_outcome_df = pd.merge(pos_outcome_df, moses500_emb_df, on=\"patient_ID\")\n",
    "\n",
    "X_moses500_emb, y_500_outcome = moses500_emb_outcome_df[moses500_emb_outcome_df.columns.difference([\"patient_ID\",\n",
    "                                                                                                    \"posOutcome\"])], \\\n",
    "                                moses500_emb_outcome_df[\"posOutcome\"]\n",
    "\n",
    "X_train_moses500, X_test_moses500, y_train_moses500, y_test_moses500 = train_test_split(X_moses500_emb, y_500_outcome, test_size=0.3, random_state=seed)\n",
    "\n",
    "X_train_moses500.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[12:13:29] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:13:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 21 minutes and 46.7 seconds.\n",
      "Best Score: 82.559%\n",
      "{'subsample': 1.0, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=12)]: Done 125 out of 125 | elapsed: 20.5min finished\n"
     ]
    }
   ],
   "source": [
    "rand_search_moses500 = param_tuning(X_train_moses500, y_500_outcome)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "params_moses_500 = {'subsample': 1.0,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.01,\n",
    " 'gamma': 1,\n",
    " 'colsample_bytree': 0.6}\n",
    "\n",
    "clf_moses500 = XGBClassifier(**params_moses_500, n_jobs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   52.3s finished\n"
     ]
    }
   ],
   "source": [
    "cv_res_moses500 = cross_validate(clf_moses500, X_train_moses500, y_train_moses500, scoring=scoring,\n",
    "                                 n_jobs=-1, verbose=1, return_train_score=True, cv=st_cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.748339\n1    0.769034\n2    0.763307\n3    0.730289\n4    0.733372\n5    0.819359\ndtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_moses500_df = get_scores(cv_res_moses500, score_cols)\n",
    "cv_scores_moses500_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "balanced_accuracy    0.755837\nrecall_0             0.748571\nprecision_0          0.775148\nrecall_1             0.763975\nprecision_1          0.736527\nauc                  0.826276\ndtype: float64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_moses500.fit(X_train_moses500, y_train_moses500)\n",
    "test_scores_moses500 = calc_scores(clf_moses500,X_test_moses500, y_test_moses500)\n",
    "\n",
    "test_scores_moses500_df = pd.DataFrame(data=test_scores_moses500, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "test_scores_moses500_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1        10       100      1000      1001      1002  \\\n1803 -0.074989 -0.034986  0.016726 -0.029518  0.008582  0.005779 -0.000579   \n2021 -0.461253  0.310014 -0.150956 -0.041953 -0.006985  0.007958  0.004016   \n1949 -0.229845 -0.022110  0.042118  0.005673 -0.007579  0.002075 -0.005237   \n1591 -0.305333 -0.097317 -0.052690  0.012518 -0.008363 -0.003001  0.008997   \n1746  0.029845 -0.185375  0.141574  0.055656 -0.003347 -0.017563  0.016647   \n\n          1003      1004      1005  ...       990       991       992  \\\n1803 -0.002969  0.001462  0.015135  ...  0.007104  0.002937  0.002284   \n2021  0.003632  0.005419 -0.001957  ... -0.001212 -0.012179  0.001410   \n1949  0.006646  0.007098  0.001961  ... -0.007089 -0.005877  0.002784   \n1591 -0.002156  0.002506  0.000815  ... -0.004456  0.001293 -0.003830   \n1746  0.014553  0.010957 -0.000302  ... -0.004145  0.000090 -0.004986   \n\n           993       994       995       996       997       998       999  \n1803  0.003757 -0.003861 -0.002634  0.004086 -0.001413  0.000586 -0.002029  \n2021 -0.006575 -0.007483 -0.004757  0.004736 -0.005549  0.008913 -0.001590  \n1949  0.000884  0.007778  0.012091  0.009944  0.016688  0.002074  0.011915  \n1591  0.000903  0.011116 -0.007334 -0.004435  0.005998 -0.006971 -0.006417  \n1746 -0.010449  0.014984 -0.010606  0.002446 -0.002113  0.035375 -0.005707  \n\n[5 rows x 2236 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>10</th>\n      <th>100</th>\n      <th>1000</th>\n      <th>1001</th>\n      <th>1002</th>\n      <th>1003</th>\n      <th>1004</th>\n      <th>1005</th>\n      <th>...</th>\n      <th>990</th>\n      <th>991</th>\n      <th>992</th>\n      <th>993</th>\n      <th>994</th>\n      <th>995</th>\n      <th>996</th>\n      <th>997</th>\n      <th>998</th>\n      <th>999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1803</th>\n      <td>-0.074989</td>\n      <td>-0.034986</td>\n      <td>0.016726</td>\n      <td>-0.029518</td>\n      <td>0.008582</td>\n      <td>0.005779</td>\n      <td>-0.000579</td>\n      <td>-0.002969</td>\n      <td>0.001462</td>\n      <td>0.015135</td>\n      <td>...</td>\n      <td>0.007104</td>\n      <td>0.002937</td>\n      <td>0.002284</td>\n      <td>0.003757</td>\n      <td>-0.003861</td>\n      <td>-0.002634</td>\n      <td>0.004086</td>\n      <td>-0.001413</td>\n      <td>0.000586</td>\n      <td>-0.002029</td>\n    </tr>\n    <tr>\n      <th>2021</th>\n      <td>-0.461253</td>\n      <td>0.310014</td>\n      <td>-0.150956</td>\n      <td>-0.041953</td>\n      <td>-0.006985</td>\n      <td>0.007958</td>\n      <td>0.004016</td>\n      <td>0.003632</td>\n      <td>0.005419</td>\n      <td>-0.001957</td>\n      <td>...</td>\n      <td>-0.001212</td>\n      <td>-0.012179</td>\n      <td>0.001410</td>\n      <td>-0.006575</td>\n      <td>-0.007483</td>\n      <td>-0.004757</td>\n      <td>0.004736</td>\n      <td>-0.005549</td>\n      <td>0.008913</td>\n      <td>-0.001590</td>\n    </tr>\n    <tr>\n      <th>1949</th>\n      <td>-0.229845</td>\n      <td>-0.022110</td>\n      <td>0.042118</td>\n      <td>0.005673</td>\n      <td>-0.007579</td>\n      <td>0.002075</td>\n      <td>-0.005237</td>\n      <td>0.006646</td>\n      <td>0.007098</td>\n      <td>0.001961</td>\n      <td>...</td>\n      <td>-0.007089</td>\n      <td>-0.005877</td>\n      <td>0.002784</td>\n      <td>0.000884</td>\n      <td>0.007778</td>\n      <td>0.012091</td>\n      <td>0.009944</td>\n      <td>0.016688</td>\n      <td>0.002074</td>\n      <td>0.011915</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>-0.305333</td>\n      <td>-0.097317</td>\n      <td>-0.052690</td>\n      <td>0.012518</td>\n      <td>-0.008363</td>\n      <td>-0.003001</td>\n      <td>0.008997</td>\n      <td>-0.002156</td>\n      <td>0.002506</td>\n      <td>0.000815</td>\n      <td>...</td>\n      <td>-0.004456</td>\n      <td>0.001293</td>\n      <td>-0.003830</td>\n      <td>0.000903</td>\n      <td>0.011116</td>\n      <td>-0.007334</td>\n      <td>-0.004435</td>\n      <td>0.005998</td>\n      <td>-0.006971</td>\n      <td>-0.006417</td>\n    </tr>\n    <tr>\n      <th>1746</th>\n      <td>0.029845</td>\n      <td>-0.185375</td>\n      <td>0.141574</td>\n      <td>0.055656</td>\n      <td>-0.003347</td>\n      <td>-0.017563</td>\n      <td>0.016647</td>\n      <td>0.014553</td>\n      <td>0.010957</td>\n      <td>-0.000302</td>\n      <td>...</td>\n      <td>-0.004145</td>\n      <td>0.000090</td>\n      <td>-0.004986</td>\n      <td>-0.010449</td>\n      <td>0.014984</td>\n      <td>-0.010606</td>\n      <td>0.002446</td>\n      <td>-0.002113</td>\n      <td>0.035375</td>\n      <td>-0.005707</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2236 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand_search_mrmr50 = param_tuning(X_train_mrmr50, y_train_mrmr50, jobs=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:51:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "mrmr50_params = {'subsample': 0.8,\n",
    " 'n_estimators': 400,\n",
    " 'min_child_weight': 3,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.03,\n",
    " 'gamma': 1.5,\n",
    " 'colsample_bytree': 0.8}\n",
    "\n",
    "mrmr50_params, clf_mrmr50, cv_scores_mrmr50_df, test_scores_mrmr50_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_mrmr_ft50_2021-01-29.csv\", pos_outcome_df, params=mrmr50_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.745660\n1    0.749200\n2    0.804931\n3    0.753668\n4    0.686389\n5    0.797917\ndtype: float64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_mrmr50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.718465\nrecall_0             0.701897\nprecision_0          0.766272\nrecall_1             0.739274\nprecision_1          0.670659\nauc                  0.792226\ndtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[14:57:33] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:57:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 26 minutes and 41.99 seconds.\n",
      "Best Score: 78.738%\n",
      "{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 2, 'colsample_bytree': 0.6}\n",
      "[14:59:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:59:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 2, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 25.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   52.8s finished\n"
     ]
    }
   ],
   "source": [
    "moses83_params, clf_moses83, cv_moses83, test_scores_moses83 = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_moses_ft83_2021-01-30.csv\", pos_outcome_df)\n",
    "print(moses83_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.718882\ntest_precision_0          0.724353\ntest_recall_0             0.785926\ntest_precision_1          0.724941\ntest_recall_1             0.651839\ntest_auc                  0.787383\ndtype: float64"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_moses83.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.716880\nrecall_0             0.694737\nprecision_0          0.781065\nrecall_1             0.746575\nprecision_1          0.652695\nauc                  0.766609\ndtype: float64"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_moses83.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50\t\tMOSES 83\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t71.847%\t\t\t71.688%\n",
      "\n",
      "precision_0:\t\t76.627%\t\t\t78.107%\n",
      "\n",
      "recall_0:\t\t70.190%\t\t\t69.474%\n",
      "\n",
      "precision_1:\t\t67.066%\t\t\t65.269%\n",
      "\n",
      "recall_1:\t\t73.927%\t\t\t74.658%\n",
      "\n",
      "auc:\t\t\t79.223%\t\t\t76.661%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test score comparison\n",
    "print_score_comparison(test_scores_mrmr50_df, test_scores_moses83,\n",
    "                       header_1=\"MRMR 50\", header_2=\"MOSES 83\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "mrmr50_cl_params, cv_mrmr50_cl, test_scores_mrmr50_cl_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_mrmr_ft50_wopln_2021-01-29.csv\", pos_outcome_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.726911\ntest_precision_0          0.730322\ntest_recall_0             0.797816\ntest_precision_1          0.738372\ntest_recall_1             0.656006\ntest_auc                  0.798681\ndtype: float64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mrmr50_cl.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.736128\nrecall_0             0.705882\nprecision_0          0.816568\nrecall_1             0.779359\nprecision_1          0.655689\nauc                  0.813831\ndtype: float64"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr50_cl_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50 Emb w/o CL\t\tMRMR 50 Emb w CL\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t71.847%\t\t\t73.613%\n",
      "\n",
      "precision_0:\t\t76.627%\t\t\t81.657%\n",
      "\n",
      "recall_0:\t\t70.190%\t\t\t70.588%\n",
      "\n",
      "precision_1:\t\t67.066%\t\t\t65.569%\n",
      "\n",
      "recall_1:\t\t73.927%\t\t\t77.936%\n",
      "\n",
      "auc:\t\t\t79.223%\t\t\t81.383%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_mrmr50_df, test_scores_mrmr50_cl_df,\n",
    "                       header_1=\"MRMR 50 Emb w/o CL\",\n",
    "                       header_2=\"MRMR 50 Emb w CL\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "moses83_cl_params, cv_moses83_cl, test_scores_moses83_cl_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_moses_ft83-wopln_2021-01-30.csv\", pos_outcome_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.732873\ntest_precision_0          0.732185\ntest_recall_0             0.809721\ntest_precision_1          0.749274\ntest_recall_1             0.656025\ntest_auc                  0.809083\ndtype: float64"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_moses83_cl.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.733152\nrecall_0             0.703325\nprecision_0          0.813609\nrecall_1             0.775801\nprecision_1          0.652695\nauc                  0.815124\ndtype: float64"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_moses83_cl_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMOSES 83 w/o CL\t\tMOSES 83 w CL\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t71.688%\t\t\t73.315%\n",
      "\n",
      "precision_0:\t\t78.107%\t\t\t81.361%\n",
      "\n",
      "recall_0:\t\t69.474%\t\t\t70.332%\n",
      "\n",
      "precision_1:\t\t65.269%\t\t\t65.269%\n",
      "\n",
      "recall_1:\t\t74.658%\t\t\t77.580%\n",
      "\n",
      "auc:\t\t\t76.661%\t\t\t81.512%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_moses83, test_scores_moses83_cl_df,\n",
    "                       header_1=\"MOSES 83 w/o CL\",\n",
    "                       header_2=\"MOSES 83 w CL\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[13:56:13] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:56:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 25 minutes and 33.28 seconds.\n",
      "Best Score: 79.597%\n",
      "{'subsample': 1.0, 'n_estimators': 400, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.6}\n",
      "[13:59:32] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:59:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 23.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "mrmr100_params, cv_mrmr100, test_scores_mrmr100_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_mrmr_ft100_2021-01-29.csv\", pos_outcome_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.721821\ntest_precision_0          0.736879\ntest_recall_0             0.758594\ntest_precision_1          0.710231\ntest_recall_1             0.685048\ntest_auc                  0.795970\ndtype: float64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mrmr100.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.736376\nrecall_0             0.721763\nprecision_0          0.775148\nrecall_1             0.754045\nprecision_1          0.697605\nauc                  0.799344\ndtype: float64"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr100_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "mrmr100_cl_params, cv_mrmr100_cl, test_scores_mrmr100_cl_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_clinicaldata/property_vector_mrmr_ft100_wopln_2021-01-29.csv\", pos_outcome_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "test_balanced_accuracy    0.714536\ntest_precision_0          0.721492\ntest_recall_0             0.779973\ntest_precision_1          0.719288\ntest_recall_1             0.649100\ntest_auc                  0.799172\ndtype: float64"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mrmr100_cl.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.725826\nrecall_0             0.703704\nprecision_0          0.786982\nrecall_1             0.755102\nprecision_1          0.664671\nauc                  0.806984\ndtype: float64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr100_cl_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 100 Emb w/o CL\t\tMRMR 100 Emb w CL\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t73.638%\t\t\t72.583%\n",
      "\n",
      "precision_0:\t\t77.515%\t\t\t78.698%\n",
      "\n",
      "recall_0:\t\t72.176%\t\t\t70.370%\n",
      "\n",
      "precision_1:\t\t69.760%\t\t\t66.467%\n",
      "\n",
      "recall_1:\t\t75.405%\t\t\t75.510%\n",
      "\n",
      "auc:\t\t\t79.934%\t\t\t80.698%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_mrmr100_df, test_scores_mrmr100_cl_df,\n",
    "                       header_1=\"MRMR 100 Emb w/o CL\",\n",
    "                       header_2=\"MRMR 100 Emb w CL\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[12:31:37] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:31:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 26 minutes and 35.45 seconds.\n",
      "Best Score: 79.358%\n",
      "{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 2, 'colsample_bytree': 0.6}\n",
      "[12:33:36] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:33:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed: 25.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   52.7s finished\n"
     ]
    }
   ],
   "source": [
    "params_mrmr50_nn, clf_mrmr50_nn, cv_scores_mrmr50_nn_df, test_scores_mrmr50_nn_df = evaluate_embedding(\"datasets/embedding-vectors/genexpr_only/property_vector_mrmr_ft50_notnormalized_2021-02-04.csv\", pos_outcome_df, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.748330\n1    0.754550\n2    0.797809\n3    0.750667\n4    0.698851\n5    0.793583\ndtype: float64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_mrmr50_nn_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.728803\nrecall_0             0.706349\nprecision_0          0.789941\nrecall_1             0.758503\nprecision_1          0.667665\nauc                  0.779958\ndtype: float64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_mrmr50_nn_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50 Norm\t\tMRMR 50 Not Norm\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t74.566%\t\t\t74.833%\n",
      "\n",
      "precision_0:\t\t74.920%\t\t\t75.455%\n",
      "\n",
      "recall_0:\t\t80.493%\t\t\t79.781%\n",
      "\n",
      "precision_1:\t\t75.367%\t\t\t75.067%\n",
      "\n",
      "recall_1:\t\t68.639%\t\t\t69.885%\n",
      "\n",
      "auc:\t\t\t79.792%\t\t\t79.358%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison_cv(cv_scores_mrmr50_df, cv_scores_mrmr50_nn_df, header_1=\"MRMR 50 Norm\", header_2=\"MRMR 50 Not Norm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tposOutcome\n",
      "\t\t\tMRMR 50 Norm\t\tMRMR 50 Not Norm\n",
      "\t\t-----------------------------------------------\n",
      "balanced_accuracy:\t71.847%\t\t\t72.880%\n",
      "\n",
      "precision_0:\t\t76.627%\t\t\t78.994%\n",
      "\n",
      "recall_0:\t\t70.190%\t\t\t70.635%\n",
      "\n",
      "precision_1:\t\t67.066%\t\t\t66.766%\n",
      "\n",
      "recall_1:\t\t73.927%\t\t\t75.850%\n",
      "\n",
      "auc:\t\t\t79.223%\t\t\t77.996%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score_comparison(test_scores_mrmr50_df, test_scores_mrmr50_nn_df, header_1=\"MRMR 50 Norm\", header_2=\"MRMR 50 Not Norm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.716880\nrecall_0             0.694737\nprecision_0          0.781065\nrecall_1             0.746575\nprecision_1          0.652695\nauc                  0.766609\ndtype: float64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_moses83.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}