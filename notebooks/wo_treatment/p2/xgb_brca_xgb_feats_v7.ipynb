{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from mlxtend.classifier import StackingCVClassifier, EnsembleVoteClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300, 400, 500, 600, 700],\n",
    "              'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.07],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'max_depth': [3, 4, 5, 6],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5]}\n",
    "\n",
    "seed = 42\n",
    "st_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "def calc_scores(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    recall_0, recall_1 = recall_score(y_test, y_pred, pos_label=0), recall_score(y_test, y_pred, pos_label=1)\n",
    "    precision_0, precision_1 =  precision_score(y_test, y_pred, pos_label=0), precision_score(y_test, y_pred, pos_label=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    arr = np.array([[acc, precision_0, recall_0, precision_1, recall_1,auc_score]])\n",
    "    return pd.DataFrame(data=arr, columns=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "\n",
    "def recall_0(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "def precision_0(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "scoring = {\"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "           \"recall_0\": make_scorer(recall_0), \"precision_0\": make_scorer(precision_0),\n",
    "           \"recall_1\": make_scorer(recall_score), \"precision_1\": make_scorer(precision_score), \"auc\": \"roc_auc\" }\n",
    "\n",
    "#cross_validation\n",
    "\n",
    "def print_score_comparison(raw_score, emb_score, target_feature=\"posOutcome\",\n",
    "                           header_1=\"Raw Score\", header_2=\"Embedding Score\"):\n",
    "    print(\"\\t\\t{0}\\n\\t\\t\\t{1}\\t\\t{2}\".format(target_feature, header_1, header_2))\n",
    "    print(\"\\t\\t-----------------------------------------------\")\n",
    "    print(\"balanced_accuracy:\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"balanced_accuracy\"].mean(), emb_score[\"balanced_accuracy\"].mean()))\n",
    "    print(\"precision_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_0\"].mean(), emb_score[\"precision_0\"].mean()))\n",
    "    print(\"recall_0:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_0\"].mean(), emb_score[\"recall_0\"].mean()))\n",
    "    print(\"precision_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"precision_1\"].mean(), emb_score[\"precision_1\"].mean()))\n",
    "    print(\"recall_1:\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"recall_1\"].mean(), emb_score[\"recall_1\"].mean()))\n",
    "    print(\"auc:\\t\\t\\t{0:.3%}\\t\\t\\t{1:.3%}\\n\".format(raw_score[\"auc\"].mean(), emb_score[\"auc\"].mean()))\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def param_tuning(X, y, n_folds=5, param_comb=25, scoring='roc_auc', jobs=12):\n",
    "    xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    rand_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring=scoring, n_jobs=jobs,\n",
    "                                   cv=skf.split(X, y), verbose=3, random_state=42)\n",
    "\n",
    "    start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "    rand_search.fit(X, y)\n",
    "    timer(start_time)\n",
    "    print(\"Best Score: {:.3%}\".format(rand_search.best_score_))\n",
    "    print(rand_search.best_params_)\n",
    "    return rand_search\n",
    "\n",
    "score_cols = [\"test_balanced_accuracy\",\"test_precision_0\", \"test_recall_0\",\n",
    "               \"test_precision_1\",\"test_recall_1\", \"test_auc\"]\n",
    "\n",
    "def get_scores(cv_results, score_keys=None, df_cols=None):\n",
    "    if score_keys is None:\n",
    "        score_keys = score_cols\n",
    "    if df_cols is None:\n",
    "        score_keys = score_cols\n",
    "    scores = np.empty([1, len(score_keys)])\n",
    "    for i, s in enumerate(score_keys):\n",
    "        scores[0][i] = np.mean(cv_results[s])\n",
    "    scores_df = pd.DataFrame(data=scores, columns=df_cols)\n",
    "    return scores_df\n",
    "\n",
    "def evaluate_embedding(path, outcome_df, target=\"posOutcome\", merge_col=\"patient_ID\", n_jobs=-1):\n",
    "    emb_df = pd.read_csv(path, sep=\"\\t\")\n",
    "    emb_outcome_df = pd.merge(outcome_df, emb_df, on=merge_col)\n",
    "    X_emb, y_emb = emb_outcome_df[emb_outcome_df.columns.difference([merge_col, target])], emb_outcome_df[target]\n",
    "    X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(X_emb, y_emb, test_size=0.3, random_state=seed)\n",
    "    rand_search_emb = param_tuning(X_train_emb, y_train_emb, jobs=n_jobs)\n",
    "    params = rand_search_emb.best_params_\n",
    "    clf_emb = rand_search_emb.best_estimator_\n",
    "    cv_res = cross_validate(clf_emb, X_train_emb, y_train_emb, scoring=scoring, n_jobs=n_jobs, verbose=1, return_train_score=True,\n",
    "                            cv=st_cv)\n",
    "    cv_res_df = get_scores(cv_res)\n",
    "    clf_emb.fit(X_train_emb, y_train_emb)\n",
    "    test_scores_df = calc_scores(clf_emb, X_test_emb, y_test_emb)\n",
    "\n",
    "    return params, cv_res_df, test_scores_df\n",
    "\n",
    "def load_features(path):\n",
    "    feats = []\n",
    "    with open(path, \"r\") as fp:\n",
    "        for line in fp.readlines():\n",
    "            feats.append(line.strip())\n",
    "\n",
    "    return feats\n",
    "def evaluate_ge(x_train, y_train, x_test, y_test, feats=None, jobs=-1,\n",
    "                scoring=scoring, rand_scoring=\"roc_auc\", target=\"posOutcome\"):\n",
    "    if feats is not None:\n",
    "        x_train = x_train[feats]\n",
    "        x_test = x_test[feats]\n",
    "    rand_search = param_tuning(x_train, y_train, scoring=rand_scoring, jobs=jobs)\n",
    "    params = rand_search.best_params_\n",
    "    clf = XGBClassifier(**params)\n",
    "    cv_res = cross_validate(clf, x_train, y_train,scoring=scoring, cv=st_cv, n_jobs=jobs)\n",
    "\n",
    "    cv_res_df = get_scores(cv_res, score_cols, df_cols=[\"balanced_accuracy\", \"recall_0\", \"precision_0\", \"recall_1\", \"precision_1\", \"auc\"])\n",
    "    clf.fit(x_train, y_train)\n",
    "    test_scores_df = calc_scores(clf, x_test, y_test)\n",
    "\n",
    "    return params, cv_res_df, test_scores_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1565, 8832)\n",
      "Test shape:(672, 8832)\n"
     ]
    }
   ],
   "source": [
    "fts_500 = load_features(\"datasets/xgb500_genes.txt\")\n",
    "ge_outcome_df = pd.read_csv(\"datasets/train.csv\")\n",
    "ge_outcome_test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "X_train, y_train = ge_outcome_df[ge_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])], ge_outcome_df[\"posOutcome\"]\n",
    "\n",
    "X_test, y_test = ge_outcome_test_df[ge_outcome_df.columns.difference([\"patient_ID\", \"posOutcome\"])], ge_outcome_test_df[\"posOutcome\"]\n",
    "\n",
    "print(\"Train shape: {0}\\nTest shape:{1}\".format(X_train.shape, X_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[15:11:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 4 minutes and 54.99 seconds.\n",
      "Best Score: 91.218%\n",
      "{'subsample': 0.6, 'n_estimators': 700, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0.5, 'colsample_bytree': 0.8}\n",
      "[15:13:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  4.4min finished\n"
     ]
    }
   ],
   "source": [
    "params_500, cv_res_500_df, test_scores_500_df = evaluate_ge(X_train, y_train, X_test, y_test, feats=fts_500, jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.828247\nrecall_0             0.838241\nprecision_0          0.837576\nrecall_1             0.820057\nprecision_1          0.818919\nauc                  0.912179\ndtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_500_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.761060\nrecall_0             0.772472\nprecision_0          0.776836\nrecall_1             0.750000\nprecision_1          0.745283\nauc                  0.851189\ndtype: float64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_500_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.8, gamma=0.5, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.03, max_delta_step=0, max_depth=5,\n              min_child_weight=5, missing=nan, monotone_constraints='()',\n              n_estimators=700, n_jobs=16, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.6,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_500 = XGBClassifier(**params_500)\n",
    "\n",
    "X_train_500 = X_train[fts_500]\n",
    "clf_500.fit(X_train_500, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "clf_500.save_model(\"datasets/models/clf_xgb500.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[16:00:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:00:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 34.1 seconds.\n",
      "Best Score: 86.563%\n",
      "{'subsample': 0.8, 'n_estimators': 400, 'min_child_weight': 2, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0.5, 'colsample_bytree': 0.6}\n",
      "[16:01:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   32.0s finished\n"
     ]
    }
   ],
   "source": [
    "fts_50 = fts_500[:50]\n",
    "params_50, cv_res_50_df, test_scores_50_df = evaluate_ge(X_train, y_train,\n",
    "                    X_test, y_test, feats=fts_50, jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.790680\nrecall_0             0.804539\nprecision_0          0.797576\nrecall_1             0.777142\nprecision_1          0.783784\nauc                  0.865635\ndtype: float64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.763431\nrecall_0             0.782609\nprecision_0          0.762712\nrecall_1             0.743119\nprecision_1          0.764151\nauc                  0.821625\ndtype: float64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_50_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[16:03:43] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:03:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 1 minutes and 1.99 seconds.\n",
      "Best Score: 88.437%\n",
      "{'subsample': 0.6, 'n_estimators': 700, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0.5, 'colsample_bytree': 0.8}\n",
      "[16:05:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   55.6s finished\n"
     ]
    }
   ],
   "source": [
    "fts_100 = fts_500[:100]\n",
    "params_100, cv_res_100_df, test_scores_100_df = evaluate_ge(X_train, y_train, X_test, y_test, feats=fts_100, jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.805176\nrecall_0             0.816272\nprecision_0          0.815758\nrecall_1             0.796119\nprecision_1          0.794595\nauc                  0.884365\ndtype: float64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_100_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.774571\nrecall_0             0.785915\nprecision_0          0.788136\nrecall_1             0.763407\nprecision_1          0.761006\nauc                  0.839711\ndtype: float64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_100_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[16:08:00] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:08:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Time taken: 0 hours 1 minutes and 31.33 seconds.\n",
      "Best Score: 89.984%\n",
      "{'subsample': 0.6, 'n_estimators': 700, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0.5, 'colsample_bytree': 0.8}\n",
      "[16:09:44] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "fts_150 = fts_500[:150]\n",
    "params_150, cv_res_150_df, test_scores_150_df = evaluate_ge(X_train, y_train, X_test, y_test, feats=fts_150, jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.817993\nrecall_0             0.828473\nprecision_0          0.827879\nrecall_1             0.809163\nprecision_1          0.808108\nauc                  0.899836\ndtype: float64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res_150_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "balanced_accuracy    0.764204\nrecall_0             0.776836\nprecision_0          0.776836\nrecall_1             0.751572\nprecision_1          0.751572\nauc                  0.846232\ndtype: float64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_150_df.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}